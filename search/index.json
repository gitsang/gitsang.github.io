[{"content":" 1. git 用户密码的保存和删除 1 2 3 4 5 # 保存密码 git config --global credential.helper store # 清除密码 git config --system --unset credential.helper 1 git remote set-url remotename https://username:password@github.com/gitname/repo_name.git 2. git reset 2.1 撤销 commit (soft) 1 2 3 4 5 6 7 8 # 撤销上一条 commit git reset --soft HEAD^ # 撤销上n条 commit git reset --soft HEAD^n # 撤销 commit 到某个 commit-version git reset --soft \u0026lt;commit-version\u0026gt; soft reset 仅仅撤销提交不回滚代码\n2.2 撤销 commit 和 add (mixed) 1 git reset --mixed HEAD^ 2.3 修改 commit 内容 (amend)1 1 git commit --amend 2.4 回滚代码 (hard) 1 git reset --hard \u0026lt;commit-version\u0026gt; hard reset 会将代码强制回滚\n如果需要强制提交到远端\n1 git push -f origin master 强制 push 会导致当前 commit 之后的所有提交永久性丢失\n3. 查看 commit-version 1 2 3 4 5 # 查看远端的 commit log git log # 查看本地的 commit log git reflog 如果你的队友 push -f 了代码，而你又不幸 pull 了代码，可以通过 reflog 找回你之前的本地提交\n4. 代码入栈2 pop 之后可能需要解决冲突\n1 2 3 4 5 6 7 8 9 10 # 当前代码入栈，并恢复到线上的 commit git stash # 修改代码并提交 git add --all git commit -m \u0026#34;fix\u0026#34; git push # 代码出栈 git stash pop 5. 代码入栈并拉取新分支3 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # 当前代码入栈，并恢复到线上的 commit git stash # 新建分支 git branch master-dev-fix # 切换分支 git checkout master-dev-fix # 也可以新建并切换分支 #git checkout -b master-dev-fix # 修改代码并提交 git add --all git commit -m \u0026#34;fix\u0026#34; # 合并到 master git checkout master git merge master-dev-fix # push 到线上 git push # 恢复代码 git stash pop 6. 自动转换换行符 1 2 3 4 5 6 7 8 # 提交时转换为LF，检出时转换为CRLF git config --global core.autocrlf true # 提交时转换为LF，检出时不转换 git config --global core.autocrlf input # 提交检出均不转换 git config --global core.autocrlf false 7. 使用字符串而不是 ascii 码输出 1 git config --global core.quotepath false 8. 修改远程仓库地址 1 git remote set-url origin https://giturl.git 9. 合并提交4 1 2 git rebase -i HEAD~3 # set merge commit to squash 10. 参考 git 删除远程分支上的某次提交\u0026#160;\u0026#x21a9;\u0026#xfe0e;\ngit使用情景1：正在写代码，突然线上出现了bug\u0026#160;\u0026#x21a9;\u0026#xfe0e;\ngit使用情景2：commit之后，想撤销commit\u0026#160;\u0026#x21a9;\u0026#xfe0e;\ngit合并历史提交\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2025-05-12T10:46:23+08:00","permalink":"https://gitsang.github.io/p/git-command-quick-search/","title":"Git Command Quick Search"},{"content":" 1. Method 1 2 3 4 5 6 systemctl stop [servicename] systemctl disable [servicename] rm /your/service/locations/[servicename] rm /your/service/locations/[servicename] # and symlinks that might be related systemctl daemon-reload systemctl reset-failed Systemd uses unit (file to define services) to remove a service the unit have to be removed\u0026hellip; here is a list of unit locations :1\n1 2 3 4 5 6 /etc/systemd/system/ (and sub directories) /usr/local/etc/systemd/system/ (and sub directories) ~/.config/systemd/user/ (and sub directories) /usr/lib/systemd/ (and sub directories) /usr/local/lib/systemd/ (and sub directories) /etc/init.d/ (Converted old service system) You can easily find location in loaded property using systemctl status [service]\n1 2 3 4 5 $ systemctl status bluetooth.service bluetooth.service - Bluetooth service Loaded: loaded (/lib/systemd/system/bluetooth.service; disabled; vendor preset: enabled) Active: inactive (dead) Docs: man:bluetoothd(8) Or using systemctl cat [service]\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # systemctl cat frps.service # /lib/systemd/system/frps.service [Unit] Description=Frp Server Service After=network.target [Service] Type=simple User=nobody Restart=on-failure RestartSec=5s ExecStart=/usr/bin/frps -c /etc/frp/frps.ini [Install] WantedBy=multi-user.target 1.1 About \u0026ldquo;reset-failed\u0026rdquo; Option From the systemd man page:\nreset-failed [PATTERN\u0026hellip;]\nReset the \u0026ldquo;failed\u0026rdquo; state of the specified units, or if no unit name is passed, reset the state of all units. When a unit fails in some way (i.e. process exiting with non-zero error code, terminating abnormally or timing out), it will automatically enter the \u0026ldquo;failed\u0026rdquo; state and its exit code and status is recorded for introspection by the administrator until the service is restarted or reset with this command.\n2. Reference How to remove systemd services\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2025-05-12T10:36:53+08:00","permalink":"https://gitsang.github.io/p/how-to-remove-systemd-service/","title":"Removing Systemd Services Safely"},{"content":" 1. 什么是闭包 所谓的闭包，其实就是存储了函数及其关联环境的一个实体，使其在脱离上下文时照常运行。\n从字面上理解，闭包就是将函数封闭、打包（中华文化博大精深，闭包这两个字明显比 Closure 更加贴切）\n封闭指的是：封闭外部状态，即内部环境无法访问到外部状态，或者说外部状态无法对内部产生影响\n打包指的是：为了能够脱离外部环境而存在，要将需要用到的外部环境打包到自己的内部空间\n我认为许多人在理解闭包时，仅仅理解到了闭包能够扩展变量的作用域这一层面，而忽略了闭包的封闭性（或者说是隔离性），\n2. 如何获得闭包 通俗地说，获得闭包的方式就是将函数作为值返回\n3. 闭包和对象 / 函数的区别 首先应该明确的是：闭包既非对象，也不是函数或作用域\nA closure is the combination of a function bundled together (enclosed) with references to its surrounding state (the lexical environment).1\n闭包是捆绑在一起（封闭）的函数与对其周围状态（词法环境）的引用的组合。\n闭包应该是一个组合，在中英文 wiki 中分别被解释成了“结构体”和“记录”，但都不应该简单地将其理解为对象或者函数。\n闭包与对象和函数的联系应该是：闭包相当于一个带状态的函数，闭包相当于只有一个函数的对象。2\n并且实际上对象系统能够基于闭包实现。3\n4. 参考 Closures - JavaScript | MDN\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n闭包和对象的关系 - Todd Wei - 博客园\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nRe: FP, OO and relations. Does anyone trump the others?. 29 December 1999 [2008-12-23]\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2025-05-09T19:43:07+08:00","permalink":"https://gitsang.github.io/p/closure/","title":"Understanding Closures in Programming"},{"content":" 非 LVM 分区实现动态扩容，适用于系统分区扩容，无需格式化磁盘，无需重新挂载磁盘\n1. 扩容步骤 以 /dev/sda2 扩容为例，假设 /dev/sda 空间足够（或已通过虚拟化管理平台增加容量）\n使用 fdisk -l 命令可看到 /dev/sda 磁盘总容量 200GiB，/dev/sda2 分区容量 100GiB\n1 2 3 4 5 6 7 8 9 10 11 Disk /dev/sda: 200 GiB, 214748364800 bytes, 419430400 sectors Disk model: QEMU HARDDISK Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: gpt Disk identifier: 1459CE9A-A8E1-4934-8EC6-17C7BA97E9E0 Device Start End Sectors Size Type /dev/sda1 2048 4095 2048 1M BIOS boot /dev/sda2 4096 419430366 209711087 100G Linux filesystem 现将 /dev/sda2 分区扩容到 200GiB\n1.1 重新分区 1 fdisk /dev/sda 输入 p 查看分区情况，确认 /dev/sda2 所在的位置和大小。 输入 d 删除分区 /dev/sda2。 输入 n 创建一个新的分区。 选择主分区或扩展分区（根据你的需要）。 按照提示输入分区编号（如果有多个分区）。 按照提示输入新的起始扇区（通常是默认值）。 按照提示输入新的结束扇区，确保分区大小为200G。 如果出现提示是否保留文件索引，选择 保留 输入 w 保存更改并退出。 再次输入 fdisk -l 应该能看到 /dev/sda2 已扩容成功\n1 2 3 4 5 6 7 8 9 10 11 Disk /dev/sda: 200 GiB, 214748364800 bytes, 419430400 sectors Disk model: QEMU HARDDISK Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: gpt Disk identifier: 1459CE9A-A8E1-4934-8EC6-17C7BA97E9E0 Device Start End Sectors Size Type /dev/sda1 2048 4095 2048 1M BIOS boot /dev/sda2 4096 419430366 419426271 200G Linux filesystem 1.2 扩展文件系统 输入 df -h 命令查看文件系统大小\n1 2 3 Filesystem Size Used Avail Use% Mounted on tmpfs 6.3G 1.6M 6.3G 1% /run /dev/sda2 99G 81G 18G 81% / 可以看到 /dev/sda2 文件系统空间仍未改变\n对于 ext4 系统，可以使用 resize2fs /dev/sda2 命令扩展文件系统\n再次输入 df -h 命令，可以看到 /dev/sda2 文件系统空间完成扩容\n1 2 3 4 5 6 Filesystem Size Used Avail Use% Mounted on tmpfs 6.3G 1.6M 6.3G 1% /run /dev/sda2 197G 81G 108G 43% / tmpfs 32G 0 32G 0% /dev/shm tmpfs 5.0M 0 5.0M 0% /run/lock tmpfs 6.3G 4.0K 6.3G 1% /run/user/1000 ","date":"2025-05-09T19:17:37+08:00","permalink":"https://gitsang.github.io/p/lvm/","title":"Dynamic Partition Expansion Without LVM"},{"content":" 1. 背景 背景：\n假设只有一个二级域名 domain.com，有多套环境的情况下，可能需要分配不同的三级子域名 sub.domain.com，每个环境可能需要再配置四级子域名 sub.sub.domain.com 如果使用一个 AK 拥有所有域名的 DNS 权限，可能不太安全（即使互相信任，也无法避免误操作导致影响其他环境） 需求：\n每套环境需要拥有自己的一套 AK，并能自己管理自己的域名，互不冲突 2. 操作步骤 2.1 添加子域名 阿里云的 RAM 访问控制中，不允许使用通配等方式配置域名资源（因为操作是针对 AUTHORITY SECTION 的），因此必须先拆分出子域名。\n首先在 域名解析 页面添加子域名（本文以 env1.domain.com 为例）\n添加域名需要 TXT 记录验证\n按照提示要求在你的主域名添加对应的 TXT 主机记录后点击验证即可添加成功。\n2.2 创建子域名的 RAM 权限策略 其策略类似如下（需要把 ${your-sub-domain} 改为刚才创建的子域名，如本文的 env1.domain.com），此处虽然可以使用通配，但名称必须是域名解析中列出的域名值。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 { \u0026#34;Version\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Action\u0026#34;: \u0026#34;alidns:*\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;acs:alidns:::domain/${your-sub-domain}\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34; }, { \u0026#34;Action\u0026#34;: [\u0026#34;alidns:Describe*\u0026#34;], \u0026#34;Resource\u0026#34;: \u0026#34;acs:alidns:::*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34; } ] } 这里配置了两个策略：\n第一个策略是允许 acs:alidns:::domain/${your-sub-domain} 资源的所有 alidns:* 操作 第二个策略是允许所有 acs:alidns:::* 资源的 Describe alidns:Describe* 操作（此处可能还需要 Describe 其他的资源，阿里云文档和客服并没有给出明确的答复） 2.3 子账号赋权和 AK 申请 新建一个 RAM 用户，需要勾选 OpenAPI 调用访问\n之后进入用户详情创建 AK\n进入权限管理为用户赋予刚才创建的策略，或者你也可以为用户组赋权后将用户加入用户组（推荐）\n2.4 使用 AK 之后根据使用的不同的 ACME 或 DDNS 服务等的文档配置 AK 即可\n","date":"2025-05-09T19:17:31+08:00","permalink":"https://gitsang.github.io/p/ram/","title":"RAM Permissions and Domain Management in Alibaba Cloud"},{"content":" 1. 背景 Windows 创建的虚拟机只能通过 NAT 上网（桥接需要过认证），但需要桥接到内网供外部访问。\n此场景使用的两张网卡会同时被设置为默认网关，出口流量有概率从桥接网卡出口导致无法访问。\n2. 路由表基础操作 2.1 查看路由策略 1 2 3 4 5 [root@localhost ~]# ip rule 0: from all lookup local 32766: from all lookup main 32767: from all lookup default 2.2 查看路由表 1 2 3 4 5 [root@localhost ~]# ip route list default via 172.21.208.1 dev eth0 proto dhcp metric 101 10.60.20.0/24 dev eth1 proto kernel scope link src 10.60.20.12 metric 100 172.21.208.0/20 dev eth0 proto kernel scope link src 172.21.219.71 metric 101 2.3 新增默认路由 1 [root@localhost ~]# ip route add default via 10.60.20.254 dev eth1 2.4 删除默认路由 1 [root@localhost ~]# ip route del default via 10.60.20.254 dev eth1 3. 多网口出口配置 一般配置多网卡时，两张网卡都会被配置为默认路由，使用 ip route list 查看能看到类似如下配置\n1 2 3 4 5 6 [root@localhost ~]# ip route list default via 10.60.20.254 dev eth1 proto dhcp metric 100 default via 172.21.208.1 dev eth0 proto dhcp metric 101 10.60.20.0/24 dev eth1 proto kernel scope link src 10.60.20.12 metric 100 172.21.208.0/20 dev eth0 proto kernel scope link src 172.21.219.71 metric 101 对于 default via 10.60.20.254 dev eth1 proto dhcp metric 100\ndefault 表示默认路由 via 10.60.20.254 表示数据包将发往 10.60.20.254 这个目标 IP 地址 dev eth1 指定数据包将从 eth1 接口发送 proto dhcp 表示该路由规则是通过 DHCP 协议动态分配的 metric 100 表示优先级度量值（越小优先级越高） 对于 10.60.20.0/24 dev eth1 proto kernel scope link src 10.60.20.12 metric 100\n这是一个具体的子网路由规则，用于指定数据包如何到达 10.60.20.0/24 子网。 10.60.20.0/24 表示目标子网地址范围 dev eth1 指定数据包将从 eth1 接口发送 proto kernel 表示该路由规则由内核自动生成 scope link 表示这是一个本地链接，即目标 IP 地址与本机直接相连 src 10.60.20.12 表示源 IP 地址，即从 10.60.20.12 发送到目标子网 metric 100 表示优先级度量值（越小优先级越高） 如果不希望访问外网时通过 10.60.20.254 网关，只需将第一条路由删除即可，执行\n1 [root@localhost ~]# ip route del default via 10.60.20.254 dev eth1 验证除了 10.60.20.0/24 的地址，都会走 eth0 网卡\n1 2 3 4 5 6 7 8 9 10 11 [root@localhost ~]# ip route get 10.60.20.10 10.60.20.10 dev eth1 src 10.60.20.12 cache [root@localhost ~]# ip route get 1.1.1.1 1.1.1.1 via 172.21.208.1 dev eth0 src 172.21.219.71 cache [root@localhost ~]# ip route get 8.8.8.8 8.8.8.8 via 172.21.208.1 dev eth0 src 172.21.219.71 cache 4. 保存设置 以上路由会在重启后被清理，应使用 ip route save 保存信息\n1 sudo ip route save table main \u0026gt; /var/opt/route-main.rules 使用 ip route restore 恢复\n1 2 sudo ip route flush table main sudo ip route restore table main \u0026lt; /var/opt/route-main.rules 也可以将其写为 systemd 脚本，当网卡准备完成后执行\n","date":"2025-05-09T19:17:19+08:00","permalink":"https://gitsang.github.io/p/configuring-multi-nic-routing-in-windows-vms/","title":"Configuring Multi-NIC Routing in Windows VMs"},{"content":" 1. 概述 通常，非对称加密有较低的性能，如果对大文件直接使用非对称加密可能导致高负载和高耗时（过大的文件还有可能出现报错 RSA_padding_add_PKCS1_type_2: data too large for key size）。\n因此对于大文件的加密，一般使用密码短语（passphrase）进行加密，然后使用非对称加密来加密密码短语（passphrase）\n1.1 POC 1.1.1 生成随机待加密文件 1 dd if=/dev/urandom of=firmware bs=1M count=10 1.1.2 生成 RSA 密钥对 1 2 openssl genrsa -out private.pem 2048 openssl rsa -in private.pem -pubout -out public.pem 1.1.3 打包并加密文件 其中：\n密码短语使用 openssl 随机生成 文件加密使用 pbkdf2 算法，并对密码加盐处理 1 2 3 4 firmware=./firmware passphrase=$(openssl rand -base64 32) tar -czPf - ${firmware} | openssl enc -e -pbkdf2 -a -salt -k ${passphrase} | dd of=firmware.tar.gz.enc echo ${passphrase} | openssl rsautl -encrypt -pubin -pubin -inkey public.pem -out passphrase.enc 1.1.4 解密和解包 其中：\n密码短语通过私钥解密 文件通过与加密相同的 pbkdf2 算法解密 1 2 passphrase=$(openssl rsautl -decrypt -inkey private.pem -in passphrase.enc) dd if=firmware.tar.gz.enc | openssl enc -d -pbkdf2 -a -salt -d -k ${passphrase} | tar -zxPf - ","date":"2025-05-09T19:17:07+08:00","permalink":"https://gitsang.github.io/p/efficient-large-file-encryption-using-passphrase-and-rsa/","title":"Efficient Large File Encryption Using Passphrase and RSA"},{"content":" 1. 背景 我们一般会使用 fail2ban 来保护暴露到公网的提供密码登录的 ssh 连接等。\n但使用 frp 穿透后所有的从外网访问都会变成 127.0.0.1 进入的，原本能用 fail2ban 保护的如 ssh 服务将无法使用。\n因此 fail2ban 应该放到 frps 服务器上。但 frps 的日志并不会对失败进行辨别，无论你访问哪个服务，frp 日志只会有连接和断开两种日志。\n1.1 不完美的解决途径 正常情况下，我们不会频繁地连接和断开，只有被扫描时才容易出现。\n因此添加自定义 filter，并设置一段时间内连接超过阈值后进入监狱。\n编写文件 /etc/fail2ban/filter.d/frps.conf\n1 2 3 4 5 [Definition] failregex = ^.*get a user connection \\[\u0026lt;HOST\u0026gt;:[0-9]*\\] ^.*get a new work connection: \\[\u0026lt;HOST\u0026gt;:[0-9]*\\] ignoreregex = 编写文件 /etc/fail2ban/jail.local 添加\n1 2 3 4 5 6 7 8 9 10 11 [frp] enabled = true findtime = 10m maxretry = 100 bantime = 1d filter = frps logpath = /data/frp/log/frps.log protocol = all chain = all port = all action = iptables-allports[name=frp,protocol=tcp] 记得 fail2ban-client reload 重载服务和 fail2ban-client status frp 确认服务状态。\n如果你要添加自己的过滤规则可以使用 fail2ban-regex \u0026lt;LOG\u0026gt; \u0026lt;REGEX\u0026gt; [IGNOREREGEX] 进行验证，比如 fail2ban-regex /data/frp/log/frps.log /etc/fail2ban/filter.d/frps.conf （记得要用绝对路径）\n然后你可以把阈值改小一点，用多次 telnet 来验证是否能过成功封锁。 然后用 fail2ban-client set frp unbanip 12.36.14.241 来解除封锁。\n2. Outlook 不是很完美的方案，比如如果是 http 连接，很可能超过限制，实际使用需要做一些排除的匹配。\n也许能通过 tcpdump 抓包日志来进行过滤，或编写程序输出一个更清晰的日志。\n","date":"2025-05-09T19:16:59+08:00","permalink":"https://gitsang.github.io/p/fail2ban-frp/","title":"Enhancing Security with Fail2ban for FRP Servers"},{"content":"1. 概述 llm-ls 是 huggingface 开源的一个 lsp，可以支持对接大模型提供代码补全能力。\n项目地址：https://github.com/huggingface/llm-ls\n目前支持的 IDE 有：\nllm.nvim llm-vscode llm-intellij 在不进行额外调教的前提下（目前并未找到较好的调教参数），llm-ls 的补全效果与 codium 有明显差距。\n2. 安装 2.1 Neovim 2.1.1 使用 vim-plug 1 2 3 4 5 6 7 call plug#begin() Plug \u0026#39;huggingface/llm.nvim\u0026#39; call plug#end() require(\u0026#39;llm\u0026#39;).setup({ -- cf Setup }) 示例配置请参考：https://github.com/huggingface/llm.nvim?tab=readme-ov-file#setup\n3. 配置 3.1 配置说明 对于 llm-ls，其配置可能有些复杂，并且针对不同的模型，可能需要不同的调教， 这是一个比较复杂的过程，可能需要经过长时间的实验，才能达到相对理想的效果。\n但这里有一些总结的经验，可能对你调教有些帮助：\n您应该将 temperature 降低到较小的值，以获得更规范的输出。 添加 suffix options 可能是一个魔法，但他在某些情况下可能真的有用，特别是在你经常看到补全代码输出分析而不是实际代码时。 启用 FIM 可能并不能帮助你更好的补全，甚至有可能起到反作用，及时你的模型声称支持 FIM，但如果没有特别说明其需要使用的 FIM 参数，建议不要启用 FIM。 stop options 能在一定程度上阻止补全出现代码块边界而不是代码，但它并不总是有用。如果你的 temperature 较高，这可能会有些帮助。 keepalive 参数可能会对性能较差的机器产生一些积极影响。 关于 temperature 和 top_p 参数，你可能需要知道：\n这两个参数都在控制输出的灵活性和创新型，但实际有那么些不同，我们可以用经典 DND 九宫格来抽象的表示这一关系：\ntop_p\\temperature 低温 中温 高温 低核采样 守序善良 中立善良 混沌善良 中核采样 守序中立 绝对中立 混沌中立 高核采样 守序邪恶 中立邪恶 混沌邪恶 通常在输出技术类文章时，倾向于使用低 Temperature 使其输出更符合规范的内容，可以适当提高 top_p 使其输出更具灵活性。 而在输出一些诗歌、散文时，则倾向于使用高 Temperature 使其输出更具创造力，可以适当降低 top_p 使其输出不至于失控（降低其输出不当言论的概率）。\n配置参考 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 backend = \u0026#34;ollama\u0026#34;, url = \u0026#34;http://localhost:11434\u0026#34;, model = \u0026#34;qwen2.5-coder:7b\u0026#34;, tokens_to_clear = { \u0026#34;\u0026lt;|endoftext|\u0026gt;\u0026#34; }, fim = { enabled = false, prefix = \u0026#34;\u0026lt;|fim_prefix|\u0026gt;\u0026#34;, middle = \u0026#34;\u0026lt;|fim_middle|\u0026gt;\u0026#34;, suffix = \u0026#34;\u0026lt;|fim_suffix|\u0026gt;\u0026#34;, }, request_body = { suffix = \u0026#34;\\n\u0026#34;, options = { temperature = 0.01, top_p = 0.2, num_predict = 4096, num_ctx = 8192, stop = { \u0026#34;\u0026lt;|endoftext|\u0026gt;\u0026#34;, \u0026#34;\u0026lt;|fim_prefix|\u0026gt;\u0026#34;, \u0026#34;\u0026lt;|fim_middle|\u0026gt;\u0026#34;, \u0026#34;\u0026lt;|fim_suffix|\u0026gt;\u0026#34;, \u0026#34;\u0026lt;|fim_pad|\u0026gt;\u0026#34;, \u0026#34;\u0026lt;|repo_name|\u0026gt;\u0026#34;, \u0026#34;\u0026lt;|file_sep|\u0026gt;\u0026#34;, \u0026#34;\u0026lt;|im_start|\u0026gt;\u0026#34;, \u0026#34;\u0026lt;|im_end|\u0026gt;\u0026#34;, \u0026#34;/src/\u0026#34;, \u0026#34;#- coding: utf-8\u0026#34;, \u0026#34;```\u0026#34;, }, }, keep_alive = 1800, }, debounce_ms = 150, accept_keymap = \u0026#34;\u0026lt;Tab\u0026gt;\u0026#34;, dismiss_keymap = \u0026#34;\u0026lt;S-Tab\u0026gt;\u0026#34;, tls_skip_verify_insecure = false, lsp = { bin_path = \u0026#34;/home/debian/.local/src/llm-ls/target/release/llm-ls\u0026#34;, host = nil, port = nil, cmd_env = { LLM_LOG_LEVEL = \u0026#34;DEBUG\u0026#34; }, version = \u0026#34;0.5.3\u0026#34;, }, tokenizer = nil, context_window = 8192, enable_suggestions_on_startup = true, enable_suggestions_on_files = \u0026#34;\\*\u0026#34;, disable_url_path_completion = false, 3.2 后端配置 3.2.1 Ollama ollama 在参数配置与 huggingface 有一些不同，主要是 request_body 参数使用 options 而不是 parameters\n1 2 3 backend = \u0026#34;ollama\u0026#34;, url = \u0026#34;http://localhost:11434\u0026#34;, model = \u0026#34;qwen2.5-coder:7b\u0026#34;, 3.2.2 OpenAI 与 Ollama 配置基本一致\n1 2 3 4 backend = \u0026#34;openai\u0026#34;, url = \u0026#34;https://api.siliconflow.cn/v1\u0026#34;, api_token = \u0026#34;sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\u0026#34;, model = \u0026#34;Qwen/Qwen2.5-Coder-7B-Instruct\u0026#34;, 4. 其他问题 llm-ls 二进制不可用：请尝试从 release 中下载静态编译版本，或 clone 项目代码从源码编译\n","date":"2025-02-27T10:22:52+08:00","permalink":"https://gitsang.github.io/p/llm-ls-autocomplete/","title":"基于 llm-ls 的 AI 自动补全"},{"content":"讨论 这里有关于 Neovim Autocomplete 和其他 AI 插件的讨论：https://github.com/neovim/neovim/discussions/28162\n这里有一个 continue-dev 支持 neovim 的 PR，但由于缺乏审查，已被关闭：https://github.com/continuedev/continue/pull/2098\n这是 continue-dev 中的讨论 Issue，https://github.com/continuedev/continue/issues/917\n插件列表 对话和修改 https://github.com/yetone/avante.nvim 目前 Star 数量最多的插件，但在非 Lazyvim 中界面展示并不美好，还有一些奇怪的渲染，比如强制对 Markdown 渲染让人有些恼火 https://github.com/olimorris/codecompanion.nvim 似乎必 Avante 更容易配置，且界面更加友好 https://github.com/Robitx/gp.nvim 讨论度比较高的插件 https://github.com/frankroeder/parrot.nvim 基于 gp.nvim 的 fork 自动补全 https://github.com/huggingface/llm.nvim ","date":"2025-02-25T09:28:45+08:00","permalink":"https://gitsang.github.io/p/ai-autocomplete-for-neovim/","title":"在 Neovim 中实现 AI 自动补全"},{"content":"Differences 这个问题似乎在社区中，并没有被广泛的讨论，大多数讨论都认为两个芯片组并无明显差 异1。比较详细的讨论是 Rediit 中的这篇讨论2\n一个常被提到的区别是，q35 原生支持 PCIE，而 i440fx 并不完全支持。因此通常在进行 GPU 直通时，可能会优先使用 q35（Reddit 中有人提到 i440fx 会将 PCIE 设备模拟成 PCI，但仍然以 PCIE 速度运行，所以可能也并不会有明显区别3）。\n另外，在 reddit 中，有人提到 i440fx 支持热插拔，所以据说可以将 GPU 删除以允许 VM 保存状态而不是暂停/关闭？这反过来允许 VM 在运行时使用完成快照。4\n在这个回复中，有人提到 q35 的限制5: Limited IO space can affect the number of devices used by a single Q35 machine（有限的 IO 空间可能会影响单个 Q35 机 器使用的设备数量），这个问题我似乎在某篇直通文章中见过有人提到当 GPU 和 USB 设 备超过一定数量时，会导致虚拟机无法启动，但记不起细节了。\n另一篇文章6则提到：很长一段时间以来，q35 不被建议用于 GPU 直通，因为某些部 分没有完全解决，这似乎与主流文章（至少是国内大部分文章）描述不一致，但文章中并 没有详细说明这些问题。我一直在使用 q35 进行 GPU 直通，而目前并没有遇到过 q35 带 来的问题。\nReference q35 vs i440fx | Proxmox Support Forum\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDifferences/benefits between i440fx and q35 chipsets? : r/VFIO\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.reddit.com/r/VFIO/comments/5ireij/comment/dbafh86/?utm_source=share\u0026utm_medium=web3x\u0026utm_name=web3xcss\u0026utm_term=1\u0026utm_content=share_button\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.reddit.com/r/VFIO/comments/5ireij/comment/dbagbbd/?utm_source=share\u0026utm_medium=web3x\u0026utm_name=web3xcss\u0026utm_term=1\u0026utm_content=share_button\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.reddit.com/r/VFIO/comments/5ireij/comment/dbb2e01/?utm_source=share\u0026utm_medium=web3x\u0026utm_name=web3xcss\u0026utm_term=1\u0026utm_content=share_button\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nVirtualized Windows 10 – i440FX vs Q35\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2025-02-08T11:15:25+08:00","permalink":"https://gitsang.github.io/p/i440fx-vs-q35/","title":"i440fx vs q35"},{"content":"Step by step 1. Move vm disks file to another storage Just move file or in UI use Hardware -\u0026gt; Disk -\u0026gt; Disk Action -\u0026gt; Move Storage\n2. Configure vm config file Config /etc/pve/nodes/{node_name}/qemu-server/{vm_number}.conf and change all old disk path to new disk path. (Especially the snapshot config)\n","date":"2025-02-07T15:04:52+08:00","permalink":"https://gitsang.github.io/p/pve-move-vm-disks-to-another-storage/","title":"PVE move vm disks to another storage"},{"content":" 1. Machine initialization 1.1 Disable swap Run sudo swapoff -a then configure /etc/fstab\n1.2 Configure kernel parameters 1 2 3 4 cat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/containerd.conf overlay br_netfilter EOF 1 2 sudo modprobe overlay sudo modprobe br_netfilter 1 2 3 4 5 cat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_forward = 1 net.bridge.bridge-nf-call-ip6tables = 1 EOF 1 sudo sysctl --system 1.3 Install containerd 1 2 sudo apt update sudo apt -y install containerd 1.4 Configure containerd Config file is in /etc/containerd/config.toml\nGenerate default containerd config file 1 containerd config default | sudo tee /etc/containerd/config.toml \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 Set cgroup driver to systemd. 1 2 3 [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.containerd.runtimes.runc.options] - SystemdCgroup = false + SystemdCgroup = true Change pause image 1 2 3 [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;] - sandbox_image = \u0026#34;registry.k8s.io/pause:3.6\u0026#34; + sandbox_image = \u0026#34;registry.k8s.io/pause:3.10\u0026#34; In China use registry.aliyuncs.com/google_containers/pause:3.10 instead.\nRestart containerd 1 2 sudo systemctl restart containerd sudo systemctl enable containerd 1.5 Install Kubernetes Tools Follow Installing kubeadm, kubelet and kubectl\nIn China follow https://developer.aliyun.com/mirror/kubernetes to use mirror.\nInstall prerequisite packages. 1 2 3 sudo apt update # apt-transport-https may be a dummy package; if so, you can skip that package sudo apt install -y apt-transport-https ca-certificates curl gpg Configure repository keyrings 1 2 export K8S_VERSION=v1.32 sudo mkdir -p -m 755 /etc/apt/keyrings 1 2 curl -fsSL \u0026#34;https://pkgs.k8s.io/core:/stable:/${K8S_VERSION}/deb/Release.key\u0026#34; | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg echo \u0026#34;deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/${K8S_VERSION}/deb/ /\u0026#34; | sudo tee /etc/apt/sources.list.d/kubernetes.list In China use:\n1 2 curl -fsSL \u0026#34;https://mirrors.aliyun.com/kubernetes-new/core/stable/${K8S_VERSION}/deb/Release.key\u0026#34; | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg echo \u0026#34;deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://mirrors.aliyun.com/kubernetes-new/core/stable/${K8S_VERSION}/deb/ /\u0026#34; | sudo tee /etc/apt/sources.list.d/kubernetes.list Install tools 1 2 3 sudo apt update sudo apt install -y kubelet kubeadm kubectl # sudo apt-mark hold kubelet kubeadm kubectl Enable service 1 sudo systemctl enable --now kubelet In this time journalctl -f -u kubelet should failure by error: failed to load Kubelet config file /var/lib/kubelet/config.yaml, it\u0026rsquo;s ok, we will fix it later.\n2. Install k8s cluster 2.1 Configure hostnames Configure hostname\n1 2 3 sudo hostnamectl set-hostname \u0026#34;k8s-master.local\u0026#34; // Run on master node sudo hostnamectl set-hostname \u0026#34;k8s-worker-01.local\u0026#34; // Run on 1st worker node sudo hostnamectl set-hostname \u0026#34;k8s-worker-02.local\u0026#34; // Run on 2nd worker node Configure /etc/hosts\n1 2 3 192.168.5.100 k8s-master.local k8s-master 192.168.5.101 k8s-worker-01.local k8s-worker-01 192.168.5.102 k8s-worker-02.local k8s-worker-02 2.2 Install k8s cluster with kubeadm (run on control panel node) Create kubelet.yaml\n1 2 3 4 5 6 7 8 9 10 11 apiVersion: kubeadm.k8s.io/v1beta4 kind: InitConfiguration --- apiVersion: kubeadm.k8s.io/v1beta4 kind: ClusterConfiguration kubernetesVersion: \u0026#34;1.32.0\u0026#34; # Replace with your desired version controlPlaneEndpoint: \u0026#34;k8s-master\u0026#34; # Replace with your desired control plane endpoint imageRepository: registry.k8s.io --- apiVersion: kubelet.config.k8s.io/v1beta1 kind: KubeletConfiguration In China use imageRepository: registry.aliyuncs.com/google_containers.\nInstall control panel\n1 sudo kubeadm init --config kubelet.yaml Use sudo kubeadm reset if you want to reset k8s cluster.\nConfigure default kube config\n1 2 3 mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config 2.3 Join k8s cluster with kubeadm (run on worker nodes) 1 2 sudo kubeadm join k8s-master:6443 --token 21nm87.x1lgd4jf0lqiiiau \\ --discovery-token-ca-cert-hash sha256:28b503f1f2a2592678724c482776f04b445c5f99d76915552f14e68a24b78009 2.4 Check k8s cluster status (run on control panel node) 1 sudo kubectl get nodes 3. Setup Pod Network 3.1 Install Calico (run on control panel node) Install Calico\n1 sudo kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.29.2/manifests/calico.yaml In China:\n1 2 curl -sSLO https://raw.githubusercontent.com/projectcalico/calico/v3.29.2/manifests/calico.yaml sed -i \u0026#39;s/docker.io/dockerhub.icu/g\u0026#39; calico.yaml Verify\n1 sudo kubectl get pods -n kube-system When finished, you should see the calico-node pod running by sudo kubectl get pods -n kube-system and see all nodes ready by sudo kubectl get nodes.\n4. Test 1 2 3 sudo kubectl create deployment nginx-app --image=nginx --replicas 2 sudo kubectl expose deployment nginx-app --name=nginx-web-svc --type NodePort --port 80 --target-port 80 sudo kubectl describe svc nginx-web-svc Curl using either of worker node\u0026rsquo;s hostname\n1 curl http://k8s-worker-01:32283 5. Reference How to Install Kubernetes Cluster on Debian 12 | 11 - Linuxtechi Docker hub mirror Kubernetes mirrors - aliyun ","date":"2025-02-07T14:01:24+08:00","permalink":"https://gitsang.github.io/p/install-k8s-cluster-on-debian/","title":"Install k8s cluster on debian"},{"content":" 1. sysctl 配置 在某些情况下，IPv6 并不会自动配置，需要手动开启 sysctl 选项\n编辑 /etc/sysctl.conf 文件，并在末尾添加以下内容，输入 sysctl -p 立即生效配置\n此选项将开启 IPv6 功能，通常情况下，只需要配置此选项即可开启 IPv6\n1 2 net.ipv6.conf.default.disable_ipv6 = 0 net.ipv6.conf.all.disable_ipv6 = 0 此选项将允许数据包在 Interface 之间转发，当你的网络接口是使用桥接时，通常需要开启此选项\n1 2 net.ipv6.conf.default.forwarding = 1 net.ipv6.conf.all.forwarding = 1 此选项将允许接收路由器通告，如果上面两个选项配置后仍然无法获取 IPv6 地址，可以尝试开启以下选项\n1 2 net.ipv6.conf.all.accept_ra = 1 net.ipv6.conf.default.accept_ra = 1 此选项用于开启 SLAAC (Stateless Address Autoconfiguration)，一般默认是开着的\n1 2 net.ipv6.conf.all.autoconf = 1 net.ipv6.conf.default.autoconf = 1 2. 网络接口配置 编辑 /etc/network/interfaces\n1 iface vmbr0 inet6 auto 当 inet6 配置为 auto 时将使用 SLAAC 自动配置\n","date":"2024-12-04T10:43:07+08:00","permalink":"https://gitsang.github.io/p/enable-ipv6-slaac/","title":"开启 IPv6 自动配置"},{"content":" 1. 核心规则回顾 go 指令\n表示模块的 最低语言版本兼容性（代码必须能在该版本运行）。 影响：语言特性、标准库行为、模块解析规则等。 toolchain 指令\n建议使用的工具链版本（编译器/链接器），但 不强制（除非显式配置或版本不满足要求）。 影响：编译器优化、构建速度、生成的二进制质量等。 工具链选择优先级（Go 1.21+）：\n如果当前 Go 版本 ≥ toolchain 版本 → 直接使用当前版本。 如果当前 Go 版本 \u0026lt; toolchain 版本 → 尝试下载或切换到指定工具链（需满足 GOTOOLCHAIN 配置）。 2. 场景分类与分析 2.1 项目与依赖的 go 版本相同，toolchain 不同 示例：\n1 2 3 4 5 6 7 // 你的项目 go 1.22.0 toolchain go1.22.6 // 显式指定 // 依赖包 go 1.22.0 toolchain go1.23.1 行为：\n你的项目用 go1.22.6 编译，依赖包的 toolchain go1.23.1 会被忽略（因为 1.22.6 \u0026lt; 1.23.1 但未强制切换）。 风险：依赖包可能依赖 1.23.1 的优化，但实际未生效。 2.2 项目的 go 版本 \u0026gt; 依赖的 go 版本 示例：\n1 2 3 4 5 6 // 你的项目 go 1.23.0 // 依赖包 go 1.21.0 toolchain go1.22.0 行为：\n依赖包的 toolchain go1.22.0 会被忽略（因为你的工具链 1.23.0 \u0026gt; 1.22.0）。 优势：高版本 Go 通常兼容低版本模块。 2.3 项目的 go 版本 \u0026lt; 依赖的 go 版本（危险！） 示例：\n1 2 3 4 5 6 // 你的项目 go 1.21.0 // 依赖包 go 1.22.0 toolchain go1.23.1 行为：\n编译报错！因为你的项目要求 Go 1.21.0，但依赖包需要 ≥1.22.0。 解决方案：升级项目的 go 版本或降低依赖包版本。 2.4 依赖包未指定 toolchain 示例：\n1 2 3 4 5 6 // 你的项目 go 1.22.0 toolchain go1.22.6 // 依赖包 go 1.22.0 // 无 toolchain 行为：\n依赖包默认使用与 go 指令相同的工具链（即假设 toolchain go1.22.0）。 你的项目仍用 go1.22.6 编译（因为 1.22.6 \u0026gt; 1.22.0）。 2.5 显式强制工具链切换（通过 GOTOOLCHAIN） 环境变量： 1 export GOTOOLCHAIN=go1.23.1+auto # 自动下载缺失版本 行为： 即使当前版本是 go1.22.6，也会强制切换到 go1.23.1 编译。 适用场景：需要严格匹配依赖包的工具链建议时。 3. 特殊场景与边界情况 3.1 依赖包的 toolchain 版本 \u0026lt; 项目的 go 版本 示例：\n1 2 3 4 5 6 7 // 你的项目 go 1.23.0 toolchain go1.23.1 // 依赖包 go 1.22.0 toolchain go1.22.0 行为：\n依赖包的 toolchain go1.22.0 会被忽略（因为 1.23.1 \u0026gt; 1.22.0）。 仍用 go1.23.1 编译。 3.2 跨主版本兼容性问题（如 Go1 → Go2） 规则： Go 1.x 无法编译依赖 Go 2.x 的模块（未来可能需要显式升级）。 目前 Go 2 尚未发布，但设计上会通过 go.mod 的 go 指令隔离。 3.3 工具链自动下载（Go 1.21+） 条件： 当前 Go 版本 \u0026lt; 依赖包的 toolchain 版本。 GOTOOLCHAIN 设置为 auto 或 latest。 行为： 自动下载并切换到指定工具链（如 go1.23.1）。 4. 决策流程图 1 2 3 4 5 6 7 8 9 10 11 12 开始编译 │ ├─ 检查项目的 go 和 toolchain 版本 │ ├─ 若 toolchain 指定且当前版本不满足 → 尝试切换或下载 │ └─ 否则使用当前版本 │ ├─ 检查所有依赖包的 go 和 toolchain 版本 │ ├─ 若依赖包的 go 版本 \u0026gt; 项目的 go 版本 → 报错 │ ├─ 若依赖包的 toolchain 版本 \u0026gt; 当前版本 → 根据 GOTOOLCHAIN 决定是否切换 │ └─ 否则忽略依赖包的 toolchain │ └─ 使用最终确定的工具链版本编译 5. 最佳实践建议 保持 go 版本与依赖包一致\n避免因版本差异导致隐式问题（如 go 1.22.0 的项目依赖 go 1.21.0 的包是安全的，反之则危险）。 谨慎使用 toolchain 指令\n仅在需要特定工具链优化或修复时使用，避免过度约束。 利用 GOTOOLCHAIN 控制环境\n在 CI/CD 中设置 GOTOOLCHAIN=latest+auto 确保一致性。 定期检查依赖包的版本声明\n使用 go list -m all 查看依赖树，确保无版本冲突。 6. 总结 能编译成功的组合：项目的 go 版本 ≥ 依赖包的 go 版本。 工具链的影响：仅当依赖包的 toolchain \u0026gt; 当前版本且配置允许时才会切换。 最危险场景：项目的 go 版本 \u0026lt; 依赖包的 go 版本（直接报错）。 ","date":"2024-05-08T15:16:00+08:00","permalink":"https://gitsang.github.io/p/go-module-and-toolchain/","title":"Go Module 管理和 Toolchain 配置"},{"content":" 使用 iptables -L 可能会看到类似如下的配置\n1 2 3 4 Chain INPUT (policy ACCEPT) target prot opt source destination ACCEPT all -- anywhere anywhere ctstate RELATED,ESTABLISHED ACCEPT all -- anywhere anywhere 第二条规则看上去像是允许了任意来源和目标的流量，但实际验证的效果却是后续的防火墙规则仍然在工作。\n这是因为，第二条规则实际上仅针对本地回环 (lo) 接口，当使用 iptables -L 查看时进行了省略，使用 iptables-save 可以得到完整的防火墙规则如下\n1 2 -A INPUT -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT -A INPUT -i lo -j ACCEPT ","date":"2024-05-07T11:11:00+08:00","permalink":"https://gitsang.github.io/p/iptables-local-loopback-ambiguous-config/","title":"Iptables 本地回环接口容易造成误解的配置"},{"content":" 1. 背景 当 docker 使用端口映射时， docker daemon 会创建 DOCKER 链绕过 firewalld 建立 iptables 规则，可能使 firewall 规则失效。\n可以通过修改 DOCKER-USER 链来管理 docker 的防火墙规则或禁用 firewalld 直接配置 iptables（不推荐）\n1.1 停止 docker 不要在 Docker 运行时 Reload firewalld，否则会导致 Docker 链被删除\n1 systemctl stop docker 1.2 清除并重建自定义规则链 1 2 3 firewall-cmd --permanent --direct --remove-chain ipv4 filter DOCKER-USER firewall-cmd --permanent --direct --remove-rules ipv4 filter DOCKER-USER firewall-cmd --permanent --direct --add-chain ipv4 filter DOCKER-USER 1.3 允许 Docker 容器出站流量返回 使用 conntrack 模块匹配 RELATED, ESTABLISHED 两种状态的连接\n1 2 3 4 5 6 # 允许出站流量返回，因为建立连接 ESTABLISHED 的数据包已经通过了防火墙的出站规则。 # 此规则优先级为 1 # 没有完全理解这个逻辑，但是加了这条容器内就可以联网了 firewall-cmd --permanent --direct --add-rule ipv4 filter DOCKER-USER 1 \\ -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT \\ -m comment --comment \u0026#39;Allow containers to connect to the outside world\u0026#39; 1.4 配置白名单 1 2 3 4 # 允许来自 IP 段的所有流量 firewall-cmd --permanent --direct --add-rule ipv4 filter DOCKER-USER 1 \\ -s 10.60.22.0/24 -j ACCEPT \\ -m comment --comment \u0026#39;Allow IP 10.60.22.0/24 to access\u0026#39; 1.5 配置默认阻止 1 2 3 # 阻止其他的流量 firewall-cmd --permanent --direct --add-rule ipv4 filter DOCKER-USER 10 \\ -j REJECT -m comment --comment \u0026#39;reject all other traffic to DOCKER-USER\u0026#39; 1.6 Reload 防火墙 1 2 firewall-cmd --reload firewall-cmd --get-active-zones 1.7 重启 docker 1 systemctl start docker ","date":"2024-05-07T11:09:00+08:00","permalink":"https://gitsang.github.io/p/firewall-rule-for-docker-port-mapping/","title":"Docker 端口映射防火墙规则配置"},{"content":" 1. 白名单配置方法 以仅信任来自 10.60.22.0/24, 10.60.23.0/24 ip 端的连接为例\n1.1 配置信任来源 1 2 3 # 添加 IP 地址范围到 \u0026#34;trusted\u0026#34; 的区域 firewall-cmd --permanent --zone=trusted --add-source=10.60.22.0/24 firewall-cmd --permanent --zone=trusted --add-source=10.60.23.0/24 1.2 配置默认拒绝 1 2 3 4 # 将默认的防火墙区域设置为 \u0026#34;drop\u0026#34; firewall-cmd --set-default-zone=drop # 将网络接口 eth0 分配给 \u0026#34;drop\u0026#34; 区域 firewall-cmd --permanent --zone=drop --change-interface=eth0 1.3 Reload 防火墙 1 2 firewall-cmd --reload firewall-cmd --get-active-zones get-active-zones 应该会得到类似如下配置\n1 2 3 4 drop interfaces: eth0 trusted sources: 10.60.22.0/24 10.60.23.0/24 ","date":"2024-05-07T11:09:00+08:00","permalink":"https://gitsang.github.io/p/firewalld-white-list-configuration/","title":"Firewalld 白名单配置方法"},{"content":" 1. Prerequisite 1.1 CentOS 1 2 3 yum install zlib-devel yum install asciidoc yum install xmlto 1.2 Debian 1 2 3 apt-get install zlib1g-dev apt-get install asciidoc apt-get install xmlto 2. Install You can get it via the kernel.org site, at https://www.kernel.org/pub/software/scm/git, or the mirror on the GitHub website, at https://github.com/git/git/tags.\n1 2 3 4 5 6 7 wget https://github.com/git/git/archive/refs/tags/v2.40.1.tar.gz tar -zxf v2.40.1.tar.gz cd v2.40.1 make configure ./configure --prefix=/usr make all doc info sudo make install install-doc install-html install-info 3. Reference Getting-Started-Installing-Git ","date":"2023-05-08T11:31:00+08:00","permalink":"https://gitsang.github.io/p/install-git-from-source-code/","title":"Install Git from Source Code"},{"content":" 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # create swap file dd if=/dev/zero of=/.swap bs=1048576 count=4096 # format swap mkswap /.swap # start swap swapon /.swap # check free -h # onboot echo \u0026#34;/.swap swap swap defaults 0 0\u0026#34; \u0026gt;\u0026gt; /etc/fstab ","date":"2021-04-13T11:38:00+08:00","permalink":"https://gitsang.github.io/p/using-swap/","title":"Using Swap"},{"content":"Backgroud Mount samba directly in wsl like linux is difficult\n1 2 3 4 Password for root@//filesystem.domain/root: mount error: cifs filesystem not supported by the system mount error(19): No such device Refer to the mount.cifs(8) manual page (e.g. man mount.cifs) Solution But is easily mount net disk in windows file manager. So if your windows share is already mapped to a drive in the Windows host, it can be even simpler.\nSuppose you already mounted the share on Z:. In that case the following will work:1\n1 2 sudo mkdir /mnt/z sudo mount -t drvfs \u0026#39;Z:\u0026#39; /mnt/z Reference Mounting a windows share in Windows Subsystem for Linux - Stack Overflow\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2021-03-19T11:03:00+08:00","permalink":"https://gitsang.github.io/p/how-to-mount-windows-network-disk-in-wsl/","title":"How to mount Windows network disk in WSL"},{"content":"filerun 的操作用户 filerun 在 linux 上操作的用户是 www-data，因此，若是通过 filerun 创建文件，那该文件的所有者和所有组应该都为 www-data。\n（www-data 实际上并不属于 filerun，只是因为 filerun 是通过 apache2 或 nginx 搭建的，而 apache2 和 nginx 的默认用户是 www-data，实际上几乎所有的网络服务的用户都是 www-data，（当然也有些例外）。）\n当然我们可以不去关注这么多，只需要知道 filerun 创建的文件是 www-data 所有的就行。\nfilerun 无法访问某个目录 filerun 无法删除某个文件 用户组授权 www-data 访问 将文件无脑地给 www-data 赋权固然方便，但不幸的是大多数情况下，我们并不\n","date":"2021-02-25T12:28:45Z","permalink":"https://gitsang.github.io/p/filerun-%E6%9D%83%E9%99%90%E9%97%AE%E9%A2%98/","title":"filerun 权限问题"},{"content":"1. thrift 基本使用 1.1 创建 thrift 文件 1 2 3 4 5 6 # worker.thrift namespace cpp freebird service WorkerManager { void ping() } 1.2 生成 cpp 代码 1 thrift -r --gen cpp worker.thrift 在当前目录创建 gen-cpp 目录，里面包含了所有生成的 C++ 代码。\nworker_constants.cpp\nworker_constants.h WorkerManager.cpp WorkerManager.h WorkerManager_server.skeleton.cpp worker_types.cpp worker_types.h\nWorkerManager_server.skeleton.cpp 就是 C++ 服务端的 main 函数入口文件\n1.3 编写 Client1 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 /* Client.cpp */ #include \u0026lt;iostream\u0026gt; #include \u0026lt;thrift/protocol/TBinaryProtocol.h\u0026gt; #include \u0026lt;thrift/transport/TSocket.h\u0026gt; #include \u0026lt;thrift/transport/TTransportUtils.h\u0026gt; #include \u0026#34;WorkerManager.h\u0026#34; using namespace std; using namespace apache::thrift; using namespace apache::thrift::protocol; using namespace apache::thrift::transport; using namespace freebird; int main() { boost::shared_ptr\u0026lt;TTransport\u0026gt; socket(new TSocket(\u0026#34;localhost\u0026#34;, 9090)); boost::shared_ptr\u0026lt;TTransport\u0026gt; transport(new TBufferedTransport(socket)); boost::shared_ptr\u0026lt;TProtocol\u0026gt; protocol(new TBinaryProtocol(transport)); WorkerManagerClient client(protocol); try { transport-\u0026gt;open(); client.ping(); cout \u0026lt;\u0026lt; \u0026#34;ping()\u0026#34; \u0026lt;\u0026lt; endl; transport-\u0026gt;close(); } catch (TException\u0026amp; tx) { cout \u0026lt;\u0026lt; \u0026#34;ERROR: \u0026#34; \u0026lt;\u0026lt; tx.what() \u0026lt;\u0026lt; endl; } } 1.4 编译 1 2 3 4 5 6 7 # make.sh # server g++ -g -Wall -I./ -I/usr/local/include/thrift WorkerManager.cpp worker_types.cpp worker_constants.cpp WorkerManager_server.skeleton.cpp -L/usr/local/lib/*.so -lthrift -std=c++11 -o server # client g++ -g -Wall -I./ -I/usr/local/include/thrift WorkerManager.cpp worker_types.cpp worker_constants.cpp Client.cpp -L/usr/local/lib/*.so -lthrift -std=c++11 -o client 1.5 运行 1 ./server 1 ./client 2. 错误汇总 2.1 stdcxx 和 boost 冲突 1 2 3 /tmp/ccX2bX8q.o: In function `main\u0026#39;: /root/workspace/thrift/test3/gen-cpp/WorkerManager_server.skeleton.cpp:41: undefined reference to `apache::thrift::server::TSimpleServer::TSimpleServer(boost::shared_ptr\u0026lt;apache::thrift::TProcessor\u0026gt; const\u0026amp;, boost::shared_ptr\u0026lt;apache::thrift::transport::TServerTransport\u0026gt; const\u0026amp;, boost::shared_ptr\u0026lt;apache::thrift::transport::TTransportFactory\u0026gt; const\u0026amp;, boost::shared_ptr\u0026lt;apache::thrift::protocol::TProtocolFactory\u0026gt; const\u0026amp;)\u0026#39; collect2: error: ld returned 1 exit status 由于链接的 thrift 为 stdcxx 编译版，而代码中又使用了 boost （使用了 boost 编译版的 thrift 进行代码生成），因此报错。2\n编译时添加 -std=c++11 即可，或将代码中使用 boost 的代码改为 stdcxx 亦可，或使用 stdcxx 编译版的 thrift 重新生成代码。\n参考 用 C++编写 thrift 第一个例子 - csfreebird\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nUbuntu thrift 服务编译 未找到 TSimpleServer 的引用 - Templar101\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2020-05-14T14:53:28+08:00","permalink":"https://gitsang.github.io/p/thrift-quick-start-for-cpp/","title":"Thrift C++ 快速入门"},{"content":" 1. 使用场景 机器代号 操作系统 机器位置 IP 账户名 ssh/sshd 端口 OuterNet CentOS 7 公网 50.100.50.100 OuterUser 22 LocalNet CentOs 7 内网(局域网) 10.200.100.10 LocalUser 22 想要通过公网上的机器 OuterNet 访问内网机器 LocalNet\n并能够使用 OuterNet 机器的 10022 端口访问 LocalNet 机器的 22 端口\n相当于\n1 [OuterUser@OuterNet] $ ssh -p 10022 LocalUser@127.0.0.1 替代在内网时候\n1 $ ssh LocalUser@10.200.100.10 1.1 建立简单的 ssh 反向隧道 在 LocalNet 机器上执行以下命令建立隧道 1 [LocalUser@LocalNet] $ ssh -p 22 -qngfNTR 10022:localhost:22 OuterUser@50.100.50.100 或（以下参数似乎比较稳定）1\n1 [root@LocalNet] $ ssh -fN -R :55555:localhost:22 50.100.50.100 在 OuterNet 上连接 LocalNet 1 [OuterUser@OuterNet] $ ssh -p 10022 LocalUser@127.0.0.1 1.2 维持隧道 安装 autossh 1 [LocalUser@LocalNet] $ sudo yum install autossh 内网建立隧道 1 [LocalUser@LocalNet] $ autossh -p 22 -M 7777 -NR 10022:localhost:22 OuterUser@50.100.50.100 在 OuterNet 上连接 LocalNet 1 [OuterUser@OuterNet] $ ssh -p 10022 LocalUser@127.0.0.1 1.3 监听 0.0.0.0 如果需要监听 0.0.0.0 需要在服务端，即公网机器上开启 GatewayPorts\n在 /etc/ssh/sshd_config 中把 GatewayPorts 设为 yes\n2. 参考 ssh 端口转发：ssh 隧道\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2020-03-14T14:53:28+08:00","permalink":"https://gitsang.github.io/p/build-ssh-tunnel/","title":"Build SSH Tunnel"},{"content":" 1. 虚函数 1.1 简述 所谓虚函数是指：在类中希望被重写(override)的虚构的函数。也就是说 C++ 可以在派生类(derived class)中通过重写基类(based class)的虚函数来实现对基类虚函数的覆盖(override)\n1.2 常见用法 最常见的用法就是：声明基类的指针，指向任意一个子类对象，调用相应虚函数，就调用了子类重写的函数。由于编写基类时候并不能确定将被调用的是那个派生类的函数，因此被称为“虚”函数。\n如果不使用虚函数，则使用基类指针时，将总是被限制在基类函数本身，无论如何都无法调用到子类重写的函数。\n1.3 代码示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 #include \u0026lt;iostream\u0026gt; class Base { public: Base() { } public: void print() { std::cout \u0026lt;\u0026lt; \u0026#34;Base\u0026#34; \u0026lt;\u0026lt; std::endl; } virtual void vprint() { std::cout \u0026lt;\u0026lt; \u0026#34;vBase\u0026#34; \u0026lt;\u0026lt; std::endl; } }; class Derived : public Base { public: Derived() { } public: void print(){ std::cout \u0026lt;\u0026lt; \u0026#34;Derived\u0026#34; \u0026lt;\u0026lt; std::endl; } void vprint() { std::cout \u0026lt;\u0026lt; \u0026#34;vDerived\u0026#34; \u0026lt;\u0026lt; std::endl; } }; int main() { Base *p1 = new Base(); p1-\u0026gt;print(); p1-\u0026gt;vprint(); Derived *p2 = new Derived(); p2-\u0026gt;print(); p2-\u0026gt;vprint(); Base *p3 = new Derived(); p3-\u0026gt;print(); p3-\u0026gt;vprint(); return 0; } 代码中定义了一个基类 Base，并定义了一个函数 print() 和一个虚函数 vprint()，派生类 Derived 继承自 Base，并重写了 print 和 vprint 两个函数。\nmain 中分别 new 了 Base 和 Derived 对象，并调用自身的函数，这结果是很好预知的，一定是\n1 2 3 4 Base vBase Derived vDerived 之后定义了 基类指针 p3 并将其指向派生类，输出结果是：\n1 2 Base vDerived 这里就可以注意到基类指针调用函数 print() 时，实际上调用的是基类自身的 print()，即使这个指针已经指向了其派生类 Derived。\n1.4 结果解释 这是由于 C++ 在编译时，内部成员函数一般都是静态加载的，编译器对于非虚函数他的调用地址是写死的，会将其定义类的函数地址写到调用语句上，这就是静态联编。只有在编译器遇到虚函数时才会将调用修改为寄存器间接寻址，即为动态联编。\n因此，p3 虽然指向了派生类，但编译时仍然会给调用写上一个 Base::print() 的地址，即使编译器此时知道 p3 指向的并不是 Base，这是由编译逻辑决定的。\n虽然你也可以不用虚函数，而是直接定义一个派生类的对象来调用派生类的方法，但这样就已经不是一个接口了，这就不是多态了。\n1.5 总结 其实你也不必知道这么多的细节，你只要知道如果你想要仅仅暴露一个基类接口来实现多态，那么只需要为基类函数加上 virtual 标识符，然后用派生类重写该函数，最后将基类指针指向派生类就可以了。\n1.6 附录 使用 g++ 生成汇编代码 1 2 g++ -S -fverbose-asm -g t_virtual.cpp -o t_virtual.s as -alhnd t_virtual.s \u0026gt; t_virtual.as p3-\u0026gt;print() 的汇编 1 2 3 movq -40(%rbp), %rax movq %rax, %rdi call _ZN4Base5printEv # 地址标号直接寻址，跳转到 Base 类的 print p3-\u0026gt;vprint() 的汇编 1 2 3 4 5 6 movq -40(%rbp), %rax movq (%rax), %rax movq (%rax), %rax movq -40(%rbp), %rdx movq %rdx, %rdi call *%rax # 间接寻址 2. 参考 12345678\nC++构造/析构函数中的多态(二)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n浅谈 C++多态性\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nC++多态\u0026ndash;虚函数 virtual 及 override\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nC++学习:虚函数,纯虚函数,虚继承,虚析构函数\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nC++ Virtual 详解\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nC++中 virtual（虚函数）的用法\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n虚函数的深入理解\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n为什么不直接用子类引用指向子类对象，而用父类引用指向子类对象\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2019-10-09T14:53:28+08:00","permalink":"https://gitsang.github.io/p/virtual-on-cpp-object-oriented/","title":"C++ 面向对象中的虚（Virtual）"},{"content":"操作方法 默认情况下，curl 不会输出耗时信息，状态码等，若需要输出，需要使用 -w, --write-out FORMAT 选项配置 Write Out 格式。\n1 curl -w \u0026#34;\\n\\ntime_total: %{time_total}s\\n\u0026#34; https://www.example.com Write Out 中支持的变量请参考：\nhttps://everything.curl.dev/usingcurl/verbose/writeout#available-write-out-variables\n也可以使用文件\n1 curl -w \u0026#34;@curl-format.txt\u0026#34; https://www.example.com 一个简单的文件格式参考如下：\n1 2 3 4 5 6 7 8 9 \\n time_namelookup: %{time_namelookup}s\\n time_connect: %{time_connect}s\\n time_appconnect: %{time_appconnect}s\\n time_pretransfer: %{time_pretransfer}s\\n time_redirect: %{time_redirect}s\\n time_starttransfer: %{time_starttransfer}s\\n ----------\\n time_total: %{time_total}s\\n 用于 debug 的详细信息格式参考：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 \\n url_effective: %{url_effective}\\n ssl_verify_result: %{ssl_verify_result}\\n content_type: %{content_type}\\n filename_effective: %{filename_effective}\\n ftp_entry_path: %{ftp_entry_path}\\n http_code: %{http_code}\\n http_connect: %{http_connect}\\n local_ip: %{local_ip}\\n local_port: %{local_port}\\n num_connects: %{num_connects}\\n num_redirects: %{num_redirects}\\n redirect_url: %{redirect_url}\\n remote_ip: %{remote_ip}\\n remote_port: %{remote_port}\\n response_code: %{response_code}\\n size_download: %{size_download} bytes\\n size_header: %{size_header} bytes\\n size_request: %{size_request} bytes\\n size_upload: %{size_upload} bytes\\n speed_download: %{speed_download} bytes/s\\n speed_upload: %{speed_upload} bytes/s\\n time_appconnect: %{time_appconnect}s\\n time_connect: %{time_connect}s\\n time_namelookup: %{time_namelookup}s\\n time_pretransfer: %{time_pretransfer}s\\n time_redirect: %{time_redirect}s\\n time_starttransfer: %{time_starttransfer}s\\n time_total: %{time_total}s\\n ","date":"2019-10-09T14:53:28+08:00","image":"https://gitsang.github.io/p/curl-write-out-format/cover_hu_a94a35f7838e0ca6.jpg","permalink":"https://gitsang.github.io/p/curl-write-out-format/","title":"Curl 输出格式"},{"content":"《青春猪头少年不会梦到兔女郎学姐》终于完结了，这部2018年的10月番可以说总算是给了今年一个完美的句号。鸭志田一大概是学了两年的量子力学写出了这部作品吧，不过时隔多年再次见到鸭志田的作品，他的文笔可以说一下子从二流作家跻身一流行列了。\n对于这部高分作品，赞誉之词大概都已经被写完了，所以这次我就不写影评了，我们就来聊一聊《青春野郎》中的量子力学吧，UP只是一个学了一个学期量子力学和一个学期固体物理的学生，并且我们其实不是物理专业，我们是电子系的，所以肯定会有一些理解不到位，欢迎指出。\n不过量子的知识实在是太多了，这篇文章从开篇到完成写了两个多月，但是仍然无法面面俱到，本来想着是一期直接全部写完了，但是这些理论太多了，而且实际上相互联系，每个理论都是解释另一个理论的基础，所以，就只能以动漫为线索慢慢往下写了，其他的一些补充内容大概就放在第二期了。\n薛定谔的猫 首先要讲的就是学姐篇出现的第一个量子力学理论“薛定谔的猫“\n“薛定谔的猫”是由奥地利物理学家薛定谔于1935年提出的有关猫生死叠加的思想实验，实验试图从宏观尺度阐述微观尺度的量子叠加问题，以此求证观测介入时量子的存在形式。\n我们先回顾一下实验内容\n在一个盒子里有一只猫，以及少量放射性物质。之后，有50%的概率放射性物质将会衰变并释放出毒气杀死这只猫，同时有50%的概率放射性物质不会衰变而猫将活下来。\n若根据经典物理学，猫必然是死或生的一种状态。而在量子的世界里，若盒子一直关闭，整个系统就会一直保持不确定性，即猫处在既生又死的叠加状态。猫到底是生是死必须打开盒子后才能知道，也就是说，只有当其被观测时候，物质（猫）的状态才被确定。\n注意这里说的是“被确定“而不是”能被确定“，就是说，在观测的瞬间，叠加态就结束了（波函数坍缩），猫的生死也在这一瞬间被决定。\n而双叶所说的“观测理论”指的就是：微观物质通常以波的叠加混沌态存在；一旦观测后，它们立刻选择成为粒子。\n单粒子双缝干射实验 为了理解观测对粒子行为的影响，这里就不得不提到另外一个经典实验：单粒子双缝干射实验，可以说这个实验几乎是量子力学问题的精髓所在，大部分的量子理论都能通过这个实验得到解释。\n在中学我们就学过了双缝干射实验，即单缝中通过的粒子如同经典力学中的解释一样，会集中在缝的中心，而双缝中通过的例子却会形成了干射图样。\n对于干涉现象，一般的解释是：电子双缝干涉实验中，任何通过双缝的电子对屏幕图像的贡献是不分通过狭缝的时间先后的（任意两个电子之间都是有某种关联的），每一个粒子通过狭缝的行为都会对其他所有粒子的行为产生影响，因此每个粒子互相干涉而产生了干涉图样。\n为了解释一般双缝干涉实验中粒子的相互影响，我们先引进一个概念：量子纠缠（由于这个概念比较复杂，这里仅做科普性解释，就不开新的标题了）。\n在量子力学里，当几个粒子在彼此相互作用后，由于各个粒子所拥有的特性已综合成为整体性质，无法单独描述各个粒子的性质，只能描述整体系统的性质，则称这现象为量子纠缠。而这种纠缠是具有不可分性质的，即是说一旦纠缠，这几个粒子就必须作为一个系统，而不再可能对其中的子系统进行研究。这就解释了为什么每个粒子，即使是一个一个地通过双缝，他们仍然能形成干涉图样。\n但是粒子之间又是如何影响的呢？为了解释电子如何互相干涉形成干涉条纹，科学家又设计了一个单电子通过双缝的实验，我们以为这个粒子一定会出现在某个特定的地方，但奇怪的是，当只有一个电子通过双缝时，竟也出现了干涉条纹。当试图用摄像机去观测单粒子干涉原因时，另一个奇怪的现象出现了——干涉条纹消失了，不再观测时，条纹又再次出现。观测行为确确实实地影响着电子行为。\n不确定性原理 为什么观测行为影响了粒子行为呢？对此我们需要引进一个新的知识：海森堡不确定性原理\n所谓不确定性原理说的是：你不可能同时知道一个粒子的位置和它的速度，粒子位置的不确定性，必然大于或等于普朗克常数除4π\n其原因在于，测量一个粒子的位置和速度，其办法是将光照到这粒子上，一部分光波被此粒子散射开，由此指明它的位置。而人们不可能将粒子的位置确定到到光的两个波峰之间距离更小的程度，故必须用短波长的光来测量。但普朗克的量子假设，人们至少要用一个光量子。这量子会扰动粒子，并以一种不能预见的方式改变粒子的速度。\n简单来说，就是若要精确测量量子的位置，必然需要使用短波，此时量子的扰动变大，，而使得对速度的测量不准。相反若想精确测量量子的速度，必然使用长波，而使得对位置的测量不准确。\n海森堡写道：“在位置被测定的一瞬，即当光子正被电子偏转时，电子的动量发生一个不连续的变化，因此，在确知电子位置的瞬间，关于它的动量我们就只能知道相应于其不连续变化的大小的程度。于是，位置测定得越准确，动量的测定就越不准确，反之亦然。”\n不确定原理还涉及很多哲学问题，用海森堡的话说：“在因果律的陈述中，即‘若确切地知道现在，就能预见未来’，所得出的并不是结论，而是前提。我们不能知道现在的所有细节，是一种原则性的事情。”\n拉普拉斯妖 说到这里大家肯定想到了，拉普拉斯也提出了一个类似的假说，没错，那就是“拉普拉斯妖”。\n拉普拉斯妖（Démon de Laplace）是由法国数学家皮埃尔-西蒙·拉普拉斯于1814年提出的一种科学假设。此“恶魔”知道宇宙中每个原子确切的位置和动量，能够使用牛顿定律来展现宇宙事件的整个过程，过去以及未来。\n这个假说其实就是说，所谓的预言，其实就是现在细节的堆砌，由此说来，其实只要细心的观察，每个人都能够预见未来，就像是天气预报一样，只是推测而已。\n不过拉普拉斯以后，近代的量子力学诠释使得拉普拉斯妖的理论基础受到质疑。\n比如有人对拉普拉斯妖分析数据的能力提出一个极限。这个极限是由宇宙最大熵、光速、以及将信息传送通过一个普朗克长度所需要的时间得来的，约为10^120比特。在宇宙开始以来所经历过的时间以内不可能处理比这个量更多的数据。\n但存在极限就会存在假说，比如违反热力学第二定律的麦克斯韦妖，但要说的话又得很久了，就留到不知道是否存在的第二期来讲吧。还有四大神兽中的最后一个神兽芝诺的乌龟也留到第二期吧。\n青春猪头少年会梦到兔女郎学姐 那么青春猪头少年到底会不会梦到兔女郎学姐呢？（微观理论是否真的能用在宏观世界呢？）\n这里可能有人会说，“啊，这一点都不马克思，这是主观唯心主义论“。确实这有点像是贝克莱所说的“存在即被感知”，然而事实上，现在人类已经能在光子、原子、分子中实现薛定谔猫态，甚至已经开始尝试用病毒来制备薛定谔猫态。\n这也让我想到了刘慈欣在《三体》中写到的经由”球状闪电“变成量子态的人，其中的漏洞到底有多少我们不去讨论，但是人类确实已经越来越接近实现生命体的薛定谔的猫。\n“当我们不观测时，月亮是不存在的” 除此之外，在量子派中也流传着一个论调：“当我们不观察时，月亮是不存在的”\n即是说，如果我们转过头不去看月亮，那一大堆粒子就开始按照波函数弥散开去。于是，月亮的边缘开始显得模糊而不确定，它逐渐“融化”，变成概率波扩散到周围的空间里去。 但一个月亮完全弥散需要相当长的时间，但这个问题说明的是，不观察月亮时，它就从确定的状态变成无数不确定的叠加。不过实际上，量子力学定律将巨大质量物体的波函数限制在很小的区域中，所以即使月亮弥散开去，弥散的程度也不是人眼能看出来的。\n从不确定性原理来解释的话：月亮不观测时不是不存在，量子态在观测时由于观测力的相互作用而使波函数坍塌为确定值，微观粒子整体呈现规律性，宏观尺度下观测力几乎对其不影响。\n当然还有“平行世界“说、量子自杀等等的说法，量子的世界丰富多彩，肯定不是三言两语能够说完的，而且事实上，在量子的世界里”上帝掷不掷色子“到今天为止也还是众说纷纭，所以有兴趣的话一定去读一读量子相关的书籍。\n好了，那么双叶课堂的第一期也就到此为止了，虽然不知道第二期是什么时候，但是还是让我们下期再见吧。\n","date":"2019-01-05T23:43:00+08:00","permalink":"https://gitsang.github.io/p/%E7%AC%AC%E4%B8%80%E6%9C%9F-%E4%B8%A4%E5%A4%A7%E7%A5%9E%E5%85%BD%E5%92%8C%E6%B5%B7%E6%A3%AE%E5%A0%A1%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E5%8E%9F%E7%90%86/","title":"第一期 - 两大神兽和海森堡不确定性原理"},{"content":" 1. Step 1: Add EPEL and REMI Repository 1 2 sudo yum -y install https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm sudo yum -y install https://rpms.remirepo.net/enterprise/remi-release-7.rpm 2. Step 2: Install PHP 7.4 on CentOS 7 Enable PHP 7.4 Remi repository 1 2 sudo yum -y install yum-utils sudo yum-config-manager --enable remi-php74 Install 1 2 sudo yum update sudo yum install php php-cli Install additional packages: 1 sudo yum install php-xxx Example:\n1 sudo yum install php php-cli php-fpm php-mysqlnd php-zip php-devel php-gd php-mcrypt php-mbstring php-curl php-xml php-pear php-bcmath php-json Check Version 1 2 3 4 $ php -v PHP 7.4.0 (cli) (built: Nov 26 2019 20:13:36) ( NTS ) Copyright (c) The PHP Group Zend Engine v3.4.0, Copyright (c) Zend Technologies View enabled modules\n1 $ php --modules ","date":"2021-09-30T09:23:35+08:00","permalink":"https://gitsang.github.io/p/install-php74-on-centos7/","title":"Install PHP 7.4 on CentOS 7"},{"content":" 1. Config edit ~/.docker/config.json 1\n1 2 3 { \u0026#34;detachKeys\u0026#34;: \u0026#34;ctrl-q,q\u0026#34; } 2. Reference docker ：把Ctrl+p换成别的什么了\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2021-09-24T15:57:22+08:00","permalink":"https://gitsang.github.io/p/enable-ctrl-p-in-docker/","title":"Enable Ctrl+P in Docker"},{"content":" 1. Backgroud Mount samba directly in wsl like linux is difficult\n1 2 3 4 Password for root@//filesystem.domain/root: mount error: cifs filesystem not supported by the system mount error(19): No such device Refer to the mount.cifs(8) manual page (e.g. man mount.cifs) 2. Solution But is easily mount net disk in windows file manager. So if your windows share is already mapped to a drive in the Windows host, it can be even simpler.\nSuppose you already mounted the share on Z:. In that case the following will work:1\n1 2 sudo mkdir /mnt/z sudo mount -t drvfs \u0026#39;Z:\u0026#39; /mnt/z 3. Reference Mounting a windows share in Windows Subsystem for Linux - Stack Overflow\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2021-09-24T14:21:20+08:00","permalink":"https://gitsang.github.io/p/mount-windows-network-disk-to-wsl/","title":"Mount Windows Network Disk to WSL"},{"content":" 1. Problem 1 2 3 4 5 6 $ docker The command $ docker could not be found in this WSL 1 distro. We recommend to convert this distro to WSL 2 and activate the WSL integration in Docker Desktop settings. See https://docs.docker.com/docker-for-windows/wsl/ for details. 2. Solution Run in cmd.exe\n1 2 3 \u0026gt; wsl --list --verbose NAME STATE VERSION Ubuntu Running 1 Then to switch it with wsl --set-version \u0026lt;your proc\u0026gt; 21\n1 2 3 4 \u0026gt; wsl --set-version Ubuntu 2 Conversion in progress, this may take a few minutes... For information on key differences with WSL 2 please visit https://aka.ms/wsl2 Conversion complete. Also you need to go to the docker desktop settings, and enable integration with your distro in \u0026ldquo;Resources -\u0026gt; WSL Integration\u0026rdquo;.\n3. Reference Ubuntu WSL with docker could not be found - Stack Overflow\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2021-09-24T14:21:20+08:00","permalink":"https://gitsang.github.io/p/wsl-with-docker-could-not-be-found/","title":"WSL With Docker Could Not Be Found"},{"content":" 1. 背景 1 2 3 4 5 6 7 8 9 10 11 12 13 type AData struct { A string `json:\u0026#34;a\u0026#34;` } type BData struct { B string `json:\u0026#34;b\u0026#34;` } type Message struct { Name string `json:\u0026#34;name\u0026#34;` Id int `json:\u0026#34;id\u0026#34;` Data interface{} `json:\u0026#34;data\u0026#34;` } 对于 interface 类型的数据很容易实现序列化(不需要任何额外步骤)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 msgA := Message{ Name: \u0026#34;msg_a\u0026#34;, Id: 1, Data: AData{ A: \u0026#34;a_data\u0026#34;, }, } msgB := Message{ Name: \u0026#34;msg_b\u0026#34;, Id: 2, Data: BData{ B: \u0026#34;b_data\u0026#34;, }, } msgAJ, _ := json.Marshal(msgA) log.Info(\u0026#34;A\u0026#34;, zap.Reflect(\u0026#34;msgA\u0026#34;, msgA), zap.ByteString(\u0026#34;msgAJ\u0026#34;, msgAJ)) msgBJ, _ := json.Marshal(msgB) log.Info(\u0026#34;B\u0026#34;, zap.Reflect(\u0026#34;msgB\u0026#34;, msgB), zap.ByteString(\u0026#34;msgBJ\u0026#34;, msgBJ)) 但 interface 反序列化后会变成 map[string]interface 类型，想要转成 struct 只能使用 mapstructure 之类的库\n1 2 3 4 var msgX Message _ = json.Unmarshal(msgAJ, \u0026amp;msgX) log.Info(\u0026#34;X\u0026#34;, zap.Reflect(\u0026#34;msgX\u0026#34;, msgX), zap.Reflect(\u0026#34;msgX.Data.A\u0026#34;, msgX.Data.(AData).A)) // panic: interface conversion: interface {} is map[string]interface {}, not main.AData 此处是无法直接用 msgX.Data.A 来访问的，同样的 msgX.Data.(AData).A 也是不行的，因为这时候的 data 已经被反序列化成了 map[string]interface\n1.1 解决方法 1 解决方法也很简单，只要再反序列化时能够知道需要反序列化成的类型即可。\n在解析的时候定义临时 struct 继承 Message 并重新定义 Data 的类型。\n1 2 3 4 5 6 7 8 9 10 11 12 13 msgXA := struct { *Message Data AData `json:\u0026#34;data\u0026#34;` }{} _ = json.Unmarshal(msgAJ, \u0026amp;msgXA) log.Info(\u0026#34;XA\u0026#34;, zap.Reflect(\u0026#34;msgXA\u0026#34;, msgXA), zap.Reflect(\u0026#34;msgXA.Data.A\u0026#34;, msgXA.Data.A)) msgXB := struct { *Message Data BData `json:\u0026#34;data\u0026#34;` }{} _ = json.Unmarshal(msgBJ, \u0026amp;msgXB) log.Info(\u0026#34;XB\u0026#34;, zap.Reflect(\u0026#34;msgXB\u0026#34;, msgXB), zap.Reflect(\u0026#34;msgXB.Data.B\u0026#34;, msgXB.Data.B)) 1.2 解决方法 2 另一种思路是拆分 struct 每次序列化时将其合并，反序列化时再将其拆分12\n缺点是每次需要传送两个变量\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 type ShortMessage struct { Name string `json:\u0026#34;name\u0026#34;` Id int `json:\u0026#34;id\u0026#34;` } func TestJsonStructSplit(t *testing.T) { msgA := ShortMessage{ Name: \u0026#34;msg_a\u0026#34;, Id: 1, } dataA := AData{ A: \u0026#34;a_data\u0026#34;, } msgB := ShortMessage{ Name: \u0026#34;msg_b\u0026#34;, Id: 2, } dataB := BData{ B: \u0026#34;b_data\u0026#34;, } // marshal msgAJ, _ := json.Marshal(struct { *ShortMessage *AData }{\u0026amp;msgA, \u0026amp;dataA}) msgBJ, _ := json.Marshal(struct { *ShortMessage *BData }{\u0026amp;msgB, \u0026amp;dataB}) // unmarshal var msgXA ShortMessage var dataXA AData _ = json.Unmarshal(msgAJ, \u0026amp;struct { *ShortMessage *AData }{\u0026amp;msgXA, \u0026amp;dataXA}) var msgXB ShortMessage var dataXB BData _ = json.Unmarshal(msgBJ, \u0026amp;struct { *ShortMessage *BData }{\u0026amp;msgXB, \u0026amp;dataXB}) } 1.3 解决方法 3 只在反序列化时拆分12\n缺点是 Data 实际上被解析了两次（一次解析成了 map，另一次解析成了 struct），而且每次使用时候还必须进行类型转换\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 var msgXA Message var dataXA AData _ = json.Unmarshal(msgAJ, \u0026amp;struct { *Message *AData `json:\u0026#34;data\u0026#34;` }{\u0026amp;msgXA, \u0026amp;dataXA}) msgXA.Data = dataXA t.Log(\u0026#34;msgXA\u0026#34;, msgXA, \u0026#34;data\u0026#34;, msgXA.Data.(AData).A) var msgXB Message var dataXB BData _ = json.Unmarshal(msgBJ, \u0026amp;struct { *Message *BData `json:\u0026#34;data\u0026#34;` }{\u0026amp;msgXB, \u0026amp;dataXB}) msgXB.Data = dataXB t.Log(\u0026#34;msgXB\u0026#34;, msgXB, \u0026#34;data\u0026#34;, msgXB.Data.(BData).B) 2. 完整测试代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 package main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;testing\u0026#34; ) type AData struct { A string `json:\u0026#34;a\u0026#34;` } type BData struct { B string `json:\u0026#34;b\u0026#34;` } type Message struct { Name string `json:\u0026#34;name\u0026#34;` Id int `json:\u0026#34;id\u0026#34;` Data interface{} `json:\u0026#34;data\u0026#34;` } var msgA = Message{ Name: \u0026#34;msg_a\u0026#34;, Id: 1, Data: AData{ A: \u0026#34;a_data\u0026#34;, }, } var msgB = Message{ Name: \u0026#34;msg_b\u0026#34;, Id: 2, Data: BData{ B: \u0026#34;b_data\u0026#34;, }, } func TestJsonStruct(t *testing.T) { // marshal msgAJ, _ := json.Marshal(msgA) msgBJ, _ := json.Marshal(msgB) // unmarshal msgXA := struct { *Message Data AData `json:\u0026#34;data\u0026#34;` }{} _ = json.Unmarshal(msgAJ, \u0026amp;msgXA) t.Log(\u0026#34;msgXA\u0026#34;, msgXA, \u0026#34;data\u0026#34;, msgXA.Data.A) msgXB := struct { *Message Data BData `json:\u0026#34;data\u0026#34;` }{} _ = json.Unmarshal(msgBJ, \u0026amp;msgXB) t.Log(\u0026#34;msgXB\u0026#34;, msgXB, \u0026#34;data\u0026#34;, msgXB.Data.B) } type ShortMessage struct { Name string `json:\u0026#34;name\u0026#34;` Id int `json:\u0026#34;id\u0026#34;` } var msgAS = ShortMessage{ Name: \u0026#34;msg_as\u0026#34;, Id: 1, } var dataA = AData{ A: \u0026#34;a_data\u0026#34;, } var msgBS = ShortMessage{ Name: \u0026#34;msg_bs\u0026#34;, Id: 2, } var dataB = BData{ B: \u0026#34;b_data\u0026#34;, } func TestJsonStructSplit(t *testing.T) { // marshal msgAJ, _ := json.Marshal(struct { *ShortMessage *AData }{\u0026amp;msgAS, \u0026amp;dataA}) msgBJ, _ := json.Marshal(struct { *ShortMessage *BData }{\u0026amp;msgBS, \u0026amp;dataB}) // unmarshal var msgXA ShortMessage var dataXA AData _ = json.Unmarshal(msgAJ, \u0026amp;struct { *ShortMessage *AData }{\u0026amp;msgXA, \u0026amp;dataXA}) t.Log(\u0026#34;msgXA\u0026#34;, msgXA, \u0026#34;data\u0026#34;, dataXA.A) var msgXB ShortMessage var dataXB BData _ = json.Unmarshal(msgBJ, \u0026amp;struct { *ShortMessage *BData }{\u0026amp;msgXB, \u0026amp;dataXB}) t.Log(\u0026#34;msgXB\u0026#34;, msgXB, \u0026#34;data\u0026#34;, dataXB.B) } func TestJsonStructFull(t *testing.T) { // marshal msgAJ, _ := json.Marshal(msgA) msgBJ, _ := json.Marshal(msgB) // unmarshal var msgXA Message var dataXA AData _ = json.Unmarshal(msgAJ, \u0026amp;struct { *Message *AData `json:\u0026#34;data\u0026#34;` }{\u0026amp;msgXA, \u0026amp;dataXA}) msgXA.Data = dataXA t.Log(\u0026#34;msgXA\u0026#34;, msgXA, \u0026#34;data\u0026#34;, msgXA.Data.(AData).A) var msgXB Message var dataXB BData _ = json.Unmarshal(msgBJ, \u0026amp;struct { *Message *BData `json:\u0026#34;data\u0026#34;` }{\u0026amp;msgXB, \u0026amp;dataXB}) msgXB.Data = dataXB t.Log(\u0026#34;msgXB\u0026#34;, msgXB, \u0026#34;data\u0026#34;, msgXB.Data.(BData).B) } 3. 参考 Golang 中使用 JSON 的一些小技巧\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJSON and struct composition in Go\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2021-09-24T13:55:01+08:00","permalink":"https://gitsang.github.io/p/deserialization-of-interface-struct/","title":"interface struct 的 json 反序列化"},{"content":"1. 背景 1.1 我们什么时候需要使用代理 假设你在家里或公司拥有一个服务器，或一个服务器集群，但这些服务器都是仅在内网开放的，此时你想要在家或公司之外访问内部的网络，有两种方法，一种是将内网的服务开放到公网，第二种就是使用代理。\n这里说的代理是泛指，大致包括代理服务器，跳板机，远程连接等。他们最基本的原理就是，使用一个能同时连接公网和内网的机器作为中介，这台机器可以是物理机或者虚拟机，可以是服务器集群内的某一台机器，或者是服务器的某个端口。这个中介同时连接公网和内网，将公网的请求转发到内网，将内网的响应转发到公网。\n通俗的解释就是，你想要拿到某人家中的某物，但你自己进不去房子，于是你贿赂他们家的小孩让他帮你拿出来，这个小孩就是中介（或者叫代理）。\n2. 使用 v2ray 2.1 Windows 系统 2.1.2 V2rayN Windows 下有许多 v2ray 的 ui 界面，比较出名的是 v2rayN，下面仅以此软件作为说明，其他软件大同小异。\n2.1.2.1 下载 v2rayN 如果是第一次使用 v2ray，你需要从 github 上下载一个 v2rayN-core，如果下载较慢也可以从此处下载\n如果报毒需要先关闭相关杀毒软件，或白名单放行。\n2.1.2.2 配置 v2rayN 下载并解压软件后，进入文件夹内，右键 v2rayN.exe 以管理员身份运行。\n点击 服务器 -\u0026gt; 添加服务器 以添加服务器配置，或在页面上直接 ctrl+v 从剪贴板导入\n右击任务栏右下角 V2RayN 图标 -\u0026gt; 服务器 -\u0026gt; 选择刚才添加的线路 点击 设置 -\u0026gt; 参数设置 在 基础设置 中配置监听端口，一般不需要修改 在 v2rayN设置 中勾选 允许来自局域网的连接。这个选项会将 v2ray 的 http/socks 端口暴露，请一定只在局域网内勾选此选项，选项勾选后，与该机器连接在同一个网段上（连接同一个wifi的）的其他机器就可以使用这台机器的代理了 全部配置完成后，点击 重启服务，看到日志输出类似 V2Ray x.x.x started 就说明启动成功了，这时候可以在页面的下方看到 socks5 和 http 的两个地址，这两个地址就是本地代理的地址，你可以直接将其配置在浏览器上。 2.1.2.3 windows 10 配置全局代理 如果你是 windows 10 用户，你可以在设置中搜索 代理，然后配置代理服务器为刚才 v2rayN 上的 http 地址即可完成本机的代理。\n2.1.2.4 浏览器代理 如果你只是想要代理上网，不希望其他应用都走代理，那么可以只在浏览器中进行代理的设置。\n不过遗憾的是主流的 chrome 和 edge 都没有相关设置的入口，所以需要依赖于浏览器插件。\nchromium 内核的浏览器可以使用 SwitchyOmega，你可以先使用 windows 设置中的代理为浏览器下载好代理插件，或者通过使用安装包的方式安装插件（新版本的 chrome 似乎已经禁止大部分插件通过安装包的方式安装，因为试验过的方法最后都失败了，所以此处仅作参考），然后再关闭 windows 设置中的代理使用插件代理。\n安装好 SwitchyOmega 后，点击插件图标 -\u0026gt; 选项 进入设置界面，点击 新建情景模式 取任意名称，新建一个 代理服务器 配置协议为 HTTP 代理服务器为 127.0.0.1 端口为 1080 （根据之前 v2ray 给出的配置填写） 配置完点击保存后，切换到刚刚配置的代理服务器上则完成代理 2.1.2.5 局域网代理 使用局域网代理需要开启 允许来自局域网的连接，设置后，将需要使用代理的机器与 v2ray 运行的机器连入相同的网段（连入同一个 wifi）然后在连接选项中添加代理服务器。\n以手机为例\n","date":"2021-01-21T12:43:30+08:00","permalink":"https://gitsang.github.io/p/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8%E4%BB%A3%E7%90%86/","title":"如何使用代理"},{"content":"说明 站点和文章还在维护中，在这里你可能会看到\n格式混乱的 markdown 双重标题 404 页面 图裂 我其实并不懂什么 HTML/CSS，这个是 hugo 一键生成的，所以如果有 BUG 我可能也不知道怎么修。\n图床估计已经废了，大概率所有图片都会裂。\n这是个中文站点，首页全是英文只是为了装逼一下，大概率不会有理解压力。\n有问题可以联系我或者直接评论区评论（如果你看得到评论区的话），我都会尽力回复。\n总之虽然没什么人看，但是请务必忍住想要打作者的冲动。\n关于页面布局和文章存放位置 Docs 页面主要是技术文档，学习笔记之类的\nBlog 主要是一些随笔，散文什么的\nHome 页面放的是一些个人技术栈，主要是觉得太空旷了，不知道放些啥，就随便放点东西上去\n其他博文 有时候为了能快速整理，博客会先在其他平台发布，但这里应该会是最全的：\nhttps://www.cnblogs.com/sangria/\nhttps://blog.csdn.net/u013499216\nModified History 2021-08-03T13:51:43+08:00\n更新 Readme 2021-03-24T15:43:20+08:00\n更新 Readme 更新首页技术栈 2021-03-18T03:51:24+01:00\n评论系统已经开放 如果你只是觉得好玩，可以在此页面下随意评论，但不要在其他页面下发表无意义评论（需要登录 github） 当然，请遵守法律法规 ","date":"2021-01-20T14:40:00+08:00","permalink":"https://gitsang.github.io/p/readme/","title":"Readme"},{"content":"1. 事务及两阶段提交 1.1 事务的 HelloWorld 级理解 许多文档或文章中都会使用那个张三给李四转钱的例子来解释事务及其存在的必要。(即 A 账户-100，B 账户+100 这两件事，应该同时成功或失败，不能一半成功一半失败)\n而要解决这个问题就引入了两阶段提交，第一阶段向 A 和 B 发送 prepare，让 A 和 B 准备好扣钱和加钱，即冻结这部分钱，然后当 A 和 B 都检查完毕没有问题并返回准备完成后，执行第二阶段，发送 commit 让 A 和 B 执行操作。\n这看起来通俗易懂，但似乎很容易地就发现了，这么做似乎还是会出现一个成功一个失败的问题啊。没错，确实如此，比如 commit 万一其中一个没收到，所以还有很多工作要做。\n但你需要知道的是，实际上，到此为止两阶段提交已经\u0026quot;结束\u0026quot;了。接下来的问题其实已经不是两阶段提交需要解决的了。也就是 “两阶段提交能处理业务异常的失败，处理不了系统异常的失败”\n因此，接下来我们也不会探讨如何解决这些问题，但我们还是需要知道有哪些问题需要解决以及由谁解决。也就是我们需要什么样的系统才能满足两阶段提交。\n1.2 两阶段提交的系统稳定性探索 很显然到目前为止，两阶段提交已经为我们解决了很多的问题，比如 A 账户余额不足，B 账户不存在等，这些业务逻辑上的错误我们已经能够避免了。但系统的网络并不总是通畅的，系统也不是永远能稳定运行的。比如网络波动，比如宕机都会影响到执行的结果。遗憾的是，两阶段提交并不能解决这些问题。\n“好在”我们需要的“仅仅”是保证最终一致，那么如果发送 commit 失败，我就能够通过不断重试最终让 commit 成功，或者是所有机器都宕机了，那这些机器就要保证在重启后能够互相协商，并且准备阶段需要把状态落盘进行持久化等等，甚至你还要考虑要是连硬盘都坏了呢。\n这可以考虑到很深很深，但意外总会发生，我们只能尽可能减小他发生错误的概率，不过这些都不是两阶段提交的内容了。而我们在实现事务消息的时候也只需要根据实际情况做出相对合理的应对就行了，比如对于普通的业务我只需要保证只要硬盘不出问题我的系统就是稳定的，就足够了。\n(这里还暂时不引入协调者这个概念，因为协调者和客户端的行为十分相似，即使不引入，也能够支撑讨论，引入后反而增加理解难度)\n1.3 关于超时的讨论 很显然，我们无法保证系统的完全稳定，即使我们已经做好了充足的应对，但仍然需要考虑到如果系统真的出现了故障时，应该做些什么，或者不能做些什么。\n我们需要知道，整个两阶段提交中，实际上只有两个地方会产生阻塞，第一是 client 向 A/B 发送 prepare 后需要等待 A/B 的相应，第二个地方是 A/B 向客户端相应 prepare 后需要等待客户端的 commit。\nQ1: Client 等待 A/B 返回 prepare 结果时，如果长时间得不到某一个的相应，是否能够发起 rollback ？ 可以，这实际上是非常保守的做法，以牺牲耗时和数据为代价，保证了系统的一致，也许 A/B 都已经做好了准备，但 Client 已经做好了最坏的打算，于是终止了一切。\n实际上你也可以让 Client 进行一些探测来确定 A/B 的状态，再做决定，或者简单点地多等几秒。\nQ2: A/B 准备完成，等待 Client 发送 commit 时，如果长时间收不到 commit，是否能单方面地 rollback/commit 或向 Client 发送终止？ 只有当对 prepare 的响应是失败时才可以 rollback，实际上如果已经失败，那他甚至无需等待 Client 的回复就能直接 rollback，因为 Client 没有任何的理由能够发送 commit，无论如何 Client 都会发送 rollback，因此最终结果是统一的。\n但如果对 prepare 的相应是成功，这时候无法知道 Client 会返回什么，Client 的返回结果取决于另一方。解决方法就是向另一方求证，或者是发起一轮终止协议操作，或者，多等几秒。而最坏的结果就是，网络中断了，任何请求都无法发出，那么只能继续等待，直到收到相应，或终止协议，或者 Client 的 rollback\nRocketMQ 的事务消息 理解了事务之后，似乎事务消息就不难理解了，然而，看看 rocketmq 官方文档的这张图\n再看看他的描述\n生产者将半消息发送到 MQ Server。 发送返回成功后，执行本地事务。 根据本地事务的执行结果，将 commit 或 rollback 消息发送到 MQ Server。 如果在本地事务执行过程中缺少 commit/rollback 消息或生产者处于等待状态，MQ Server 将向同一组中的每个生产者发送检查消息，以获取事务状态。 生产者根据本地事务状态回复 commit/rollback 消息。 commit 的消息将传递给 consumer，但是 rollback 的消息将被 MQ Server 丢弃 Emmm, 好像懂了，但是和之前事务的描述好像哪里有些不一样？\n是的，事务消息和事务确实有着许多的区别，不过我们换一种方式，认为事务消息保证的则是本地事务和发消息这两个操作的同时成功和失败，是不是就和事务保证两个操作的同时成功和失败对应上了呢。\n需要注意的是，这里的保证的是本地事务和发消息这两个操作，而不是保证本地事务和消费消息，消费消息是否能成功那就是另外的问题了。这个误会消除后也许许多问题都有答案了。\n那么我们可以完全不看这张图和描述，总结的来说，RocketMQ 的事务消息，实际上就是，客户端通过二阶段提交，来保证本地事务和发消息给 MQ Server 操作业务逻辑上同时成功或失败。而其中 MQ Server 需要通过将消息修改 Topic 存入队列，回查事务状态，等一系列操作来解决系统错误导致的问题，来保证最终一致。\n也许这样仍然不能解决你的一些疑问，下面同样用 Q\u0026amp;A 的方式，也许就能理清其中的关系。\nQ1: 如果把发送普通消息和本地执行逻辑放在一个事务里面，如果执行事务成功就发送普通消息，如果失败就回滚好像也是可以，那么这种事务消息相对其有什么优势或者好处呢？ 优势是多一道最终一致的保障，我只要发送了 commit 那 MQ Server 就必须保证这条消息能够提交，发送了 rollback 那 MQ Server 就必须保证这条消息不会提交，为了实现这个要求，broker 需要将消息落盘，需要不能确定消息是否要提交的时候回查，需要阻塞住这个事务，就是为了最终这条消息一定能被提交或废弃（最终一致）\n先执行本地事务，成功就发送，不成功就回滚，这只考虑了本地事务的成功失败，没有考虑发送消息的成功失败，那不如就来看看不使用事务消息要保证最终一致还需要做什么。\n发送消息成功了，那很好什么都不需要做了。如果发消息失败了，你要考虑是为什么失败，比如超时，那就要查 MQ 这条消息到底进去了没有（回查），有的话你再当作成功，没有的话你要重发。\n并且你要保证修改完数据库后如果生产者挂掉，重启后他还需要知道“曾经有一条消息，数据库已经改了，但是还没发出去”，你就需要持久化这条消息（落盘）\n然后你还要保证你成功之前其他人不会去改这条数据，不然可能产生时序问题（阻塞）\n最后你就会发现，你已经逆向实现了一套事务消息，那么，为什么要造轮子呢。（不过实际上，在没有事务消息功能的消息中间件中，这就是其中的一种实现事务的方式）\nQ2: 如果 MQ Servier 已经收到消息了，回 ACK 超时了，发送方是不是会重试？重试的话消息不就重复了吗？ 如第二问所说，当然不能重试，应该先处理超时，确认 Server 到底是为什么没回复，如果无法确定，则当作失败，向 Server 发送 rollback（或者是其他终止请求防止事务阻塞），这是个客户端需要实现的内容。\nQ3: 发送方二次确认（Commit 或是 Rollback），MQ Server 收到则更新或回滚，这里消息不是入队列了嘛？还可以直接定位到消息然后更新消息的投递状态？如果还可以更新短信的状态，MQ 感觉就像数据库了。 消息确实入队了，但是 Topic 不对，会将 Topic 改为 TRANS 之类的，这个队列不可以被消费，如果要 Commit 则把 Topic 改回去，要 RollBack 就删掉。这里的消息是存到 CommitLog 里面的。且实际上，在其他不支持事务消息的 MQ 上，就是拿数据库来做状态存储介质的。\nQ4: 消息回查,MQ 定时回查业务系统的数据库提交状态，感觉像底层系统调用上层系统了，MQ 要回调很多层业务系统，这样有点怪？ 对的，所以需要消息发送方实现 listener 和定义回查（回调）函数，但不是回调很多业务层系统，只回调一个 listener 的 checkState，里面怎么实现是发送方的事情。\n如果要客户端去查 MQ 实际上也是可以的，但你一个事务消息，总不能让客户端来保证数据的一致吧。\nQ5: RocketMQ 的事务消息是否能够用来当作保证发送的多条消息的最终一致？ 答案是可以，但不建议滥用。\n虽然在表述中，似乎 RocketMQ 保证的是本地事务和发送消息的最终一致，但实际上这个行为是由客户端决定的，就是说你也可以无视本地事务，对多个消息的，发送多条 prepare，然后本地事务可以直接发送 UnknownState 等待 MQ Server 的回查，当所有的 prepare 消息都返回成功后，将状态改为 Commit，等回查时 MQ Server 检测到所有的消息都 commit 了，将他们放进消费队列，他们就同时成功了。当然，他们在后续业务上（即消费端上）是否还会一致就需要消费端来保证了。\n关于消费端的问题再多扯两句，如果是一系列的操作，对于生产端，他已经认为发送成功了，因此，为保证最终一致，如果丢消息了要从 MQ Server 重新拉，如果执行失败了要不断重试。但如果重试了很久它真的过不去了怎么办呢？回滚操作吗，是不是那是不是在此之前还要给这一系列操作上锁？回滚步骤很多怎么办，这可不像是 MQ 的回滚直接废弃消息就好。回滚之后呢，生产端的数据怎么回滚呢？\n要处理这些问题，你几乎又要实现一个新的事务，这就是一开始说的滥用事务。实际上，我认为如果你真的有这么强的业务需求，不如直接实现一个生产端到消费端的业务逻辑，如果非要用 MQ 那就只能改源码了。\n参考 正确理解二阶段提交（Two-Phase Commit）, CSDN, 萧萧冷 分布式事务解决方案-RocketMQ 实现可靠消息最终一致性, 知乎专栏, 战猿 The Design Of Transactional Message, RocketMQ Doc Transaction example, RocketMQ Doc 消息队列漫谈：如何使用消息队列实现分布式事务？, 知乎专栏, 阿茂 RocketMQ 事务消息学习及刨坑过程, 掘金, 1 黄鹰 rocketmq 事务消息入门介绍, 掘金, 匠心零度 其他 没有太多的时间进行校对，并且我也是在学习的阶段，可能有许多地方理解有错误或不妥之处，希望能帮忙指出，即使只是错别字或是语义的错误，对我来说也是莫大的帮助。\n","date":"2020-09-17T15:54:19+08:00","permalink":"https://gitsang.github.io/p/%E5%85%B3%E4%BA%8E-rocketmq-%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF%E5%92%8C%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4%E7%9A%84%E7%90%86%E8%A7%A3/","title":"关于 Rocketmq 事务消息和两阶段提交的理解"},{"content":" Golang 中 defer 几乎被当作 try catch final 使用，但事实上 defer 对返回值的修改和 final 仍然有些一些微妙的不同\n1. 问题的产生 先来看一段简短的代码\n1 2 3 4 5 6 7 8 9 10 11 12 // defer.go func deferTest() string { s := \u0026#34;init\u0026#34; defer func() { s = \u0026#34;defer\u0026#34; }() return s } func main() { fmt.Println(deferTest()) } 我们知道 defer 会在 return 之前以先进后出的顺序执行，但是 deferTest() 返回的是 init 还是 defer 呢。\n运行结果：\n1 2 \u0026gt; go run defer.go init 很显然，程序在 return 前会先执行 s = \u0026quot;defer\u0026quot; 然后再 return。\n但是打印的结果却是 init。\n是 defer 没有被执行吗？是 defer 晚于 return 执行吗？并不是，这里先不解释，稍微修改一下代码重新执行\n1 2 3 4 5 6 7 8 9 10 11 12 // defer.go func deferTest() (s string) { s = \u0026#34;init\u0026#34; defer func() { s = \u0026#34;defer\u0026#34; }() return s } func main() { fmt.Println(deferTest()) } 1 2 \u0026gt; go run defer.go defer 这个时候返回结果变成 defer 了，我们仅仅是给返回值加上了命名，defer 就将返回值改变了。\n2. 解释 实际上，return 前确实会先执行 defer 的内容，但是返回值却不是任何时候都会在 defer 时被改变的。\nreturn 的执行顺序应该是这样的：\n给 返回值 赋值\n调用 RET 指令，并传入 返回值\nRET 先检查是否存在 defer，存在则逆序执行 RET 携带 返回值 退出函数 这里的第一步，若是匿名返回值，那么在给 返回值 赋值时，将会先声明一个 返回值 (因为没有定义返回值的名称)\n1 返回值 := s 若是命名的返回值，则直接赋值（因为已经声明过了）\n1 s = s 这样，最后匿名返回值返回的是 返回值，而命名为 s 的返回值则返回 s 的值。\n这也是为什么命名返回值之后可以直接 return 的原因，因为执行 return s 其实也就只是约等于多执行了一条没有意义的 s = s 而已，和 return 是一样的。\n或者不严谨的说：golang 中 func function() returnType {} 的 returnType 其实并不像其他语言一样代表的是“返回值类型”，而是一个“匿名返回值”才对。\n","date":"2020-08-28T16:08:25+08:00","permalink":"https://gitsang.github.io/p/defer-and-return-in-golang/","title":"defer 和 return 的执行顺序陷阱"},{"content":"1. 前言 虽然 RocketMQ 提供了 C++ 语言的客户端，但仍需在 Java 环境下进行部署。\n本文开发环境：\nCentOS Linux release 7.5.1804 (Core) OpenJDK version 1.8.0_252 Apache Maven 3.0.5 (Red Hat 3.0.5-17) RocketMQ 4.7.0 Maven 和 JDK 的安装都很简单，只需要到官网下载对应 tar 包解压后添加到环境变量即可，因此不再赘述。本文 JDK 使用的是 OpenJDK。同时需要说明的是 OpenJDK 是免费开源的项目，而如果你使用 OracleJDK 则需要注意版权问题（当然个人开发可以免费试用）\n2. RocketMQ 的安装及配置 如果你在安装过程中遇到问题，请参考RocketMQ 官方文档\n2.1 RocketMQ 的安装 1 2 3 4 5 6 # 到以下网址获取 zip 包下载链接: # http://rocketmq.apache.org/dowloading/releases/ wget https://archive.apache.org/dist/rocketmq/4.7.0/rocketmq-all-4.7.0-source-release.zip unzip rocketmq-all-4.7.0-source-release.zip cd rocketmq-all-4.7.0/ mvn -Prelease-all -DskipTests clean install -U 执行成功后 RocketMQ 会被安装在当前目录的 distribution/target/rocketmq-4.7.0/rocketmq-4.7.0 目录下\n1 cd distribution/target/rocketmq-4.7.0/rocketmq-4.7.0 2.2 运行 RocketMQ 由 4 个部分组成，Producer，Consumer，Name Server，Broker\n需要分别将其启动\n默认情况下 Name Server 会启动在 9876 端口，同时 log 文件会被创建在家目录 ~ 下\nStart Name Server 1 2 nohup sh bin/mqnamesrv \u0026amp; tail -f ~/logs/rocketmqlogs/namesrv.log Start Broker 1 2 nohup sh bin/mqbroker -n localhost:9876 \u0026amp; tail -f ~/logs/rocketmqlogs/broker.log Send \u0026amp; Receive Message RocketMQ 提供了多种语言的 Producer 和 Consumer 接口，这里可以先按照官方文档使用 Java 版自带的测试工具进行验证。\n1 2 3 4 5 6 \u0026gt; export NAMESRV_ADDR=localhost:9876 \u0026gt; sh bin/tools.sh org.apache.rocketmq.example.quickstart.Producer SendResult [sendStatus=SEND_OK, msgId= ... \u0026gt; sh bin/tools.sh org.apache.rocketmq.example.quickstart.Consumer ConsumeMessageThread_%d Receive New Messages: [MessageExt... 如果 sendStatus 显示为 SEND_OK，Consumer 也能收到消息则说明部署成功了\nShutdown Servers 1 2 sh bin/mqshutdown broker sh bin/mqshutdown namesrv 如果你使用 Java 进行编程则可以继续参考官方文档的示例进行示例的编写，其他语言则需要参考对应语言的编程示例\n2.3 服务配置 如果你需要修改服务配置，如监听端口，服务端口，部署模式等，可以在安装目录的 conf 文件夹下进行修改，或根据其配置文件新建自己的配置，然后在运行时加上参数 -c \u0026lt;conf-file\u0026gt; 来加载你的配置。\n日志相关的配置再 conf 文件夹下以 logback 开头的文件下。\n如果需要修改运行参数，如分配内存大小等，则需要修改对应的启动脚本。Name Server 的启动脚本在 bin/runserver.sh，Broker 的启动脚本在 bin/runbroker.sh。\nRocketMQ 支持的集群模式配置，运行配置，日志配置等在安装目录下均有对应的参考配置。此处暂不细究，待到集群部署部分再进行详述。如果需要也可以参考 RocketMQ 开发指导之二——RocketMQ 部署 文章的内容\n3. 基于 Cpp-Client 编写 RocketMQ 的生产者和消费者 3.1 克隆项目 使用 Cpp 客户端需要先从 github 上克隆项目 https://github.com/apache/rocketmq-client-cpp\n1 git clone https://github.com/apache/rocketmq-client-cpp.git 3.2 编译和安装 rocketmq-client-cpp 以下内容翻译自 git 仓库 README\n在运行编译脚本 build.sh 之前，请确保已安装以下编译工具或库。\n编译工具： gcc-c++ 4.8.2：需要支持 C++ 11 的编译器 cmake 2.8.0：编译 jsoncpp 需要它 automake 1.11.1：编译 libevent 需要它 autoconf 2.65：编译 libevent 需要它 libtool 2.2.6：编译 libevent 需要它 库： bzip2-devel 1.0.6：boost 需要它 zlib-devel 该 build.sh 脚本将自动下载并建立依赖库包括了 libevent，json 和 boost。它将库保存在 rocketmq-client-cpp 文件夹下，然后为 rocketmq-client 构建静态库和共享库。如果依赖库构建失败，则可以尝试使用源 libevent 2.0.22，jsoncpp 0.10.7，boost 1.58.0 来手动编译\n如果您的主机无法通过互联网下载这三个库源文件，则可以将这三个库源文件（release-2.0.22-stable.zip 0.10.7.zip 和 boost_1_58_0.tar.gz）复制到 rocketmq-client-cpp 的根目录，然后 build.sh 将自动使用三个库源文件来构建 rocketmq-client-cpp\n使用以下命令进行编译\n1 sh build.sh 编译完成后的 librocketmq.a 和 librocketmq.so 都保存在 rocketmq-client-cpp/bin 中，如果需要编译新的文件可以参考以下示例：\n1 g++ -o consumer_example consumer_example.cpp -I/path/to/rocketmq-root-dir/include -L/path/to/rocketmq-root-dir/bin -lrocketmq -lpthread -lz -ldl -lrt -std=c++11 3.3 C++ 示例代码 3.3.1 Producer 示例代码 在 rocketmq-client-cpp 目录的 example 文件夹下就提供了 Producer 的示例代码。\nProducer 的代码可以简单概括为\ncreate producer set Name Server address start producer send message create message set message topic/tags/keys/body call interface to send message destroy message shut down producer destroy producer 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 #include \u0026lt;stdio.h\u0026gt; #include \u0026#34;CCommon.h\u0026#34; #include \u0026#34;CMessage.h\u0026#34; #include \u0026#34;CProducer.h\u0026#34; #include \u0026#34;CSendResult.h\u0026#34; void StartSendMessage(CProducer* producer) { int i = 0; char body[256]; CMessage* msg = CreateMessage(\u0026#34;T_TestTopic\u0026#34;); SetMessageTags(msg, \u0026#34;Test_Tag\u0026#34;); SetMessageKeys(msg, \u0026#34;Test_Keys\u0026#34;); CSendResult result; for (i = 0; i \u0026lt; 3; i++) { memset(body, 0, sizeof(body)); snprintf(body, sizeof(body), \u0026#34;new message body, index %d\u0026#34;, i); SetMessageBody(msg, body); int status = SendMessageSync(producer, msg, \u0026amp;result); if (status == OK) { printf(\u0026#34;send message[%d] result status:%d, msgId:%s\\n\u0026#34;, i, (int)result.sendStatus, result.msgId); } else { printf(\u0026#34;send message[%d] failed !\\n\u0026#34;, i); } usleep(1000); } DestroyMessage(msg); } int main(int argc, char* argv[]) { CProducer* producer = CreateProducer(\u0026#34;Group_producer\u0026#34;); SetProducerNameServerAddress(producer, \u0026#34;127.0.0.1:9876\u0026#34;); StartProducer(producer); printf(\u0026#34;Producer initialized. \\n\u0026#34;); StartSendMessage(producer); ShutdownProducer(producer); DestroyProducer(producer); printf(\u0026#34;Producer stopped !\\n\u0026#34;); return 0; } 3.3.2 PushConsumer 示例代码 example 提供的 PushConsumer 稍显复杂，以下提供一个简化版本的代码以供理解其基本逻辑。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026#34;CPushConsumer.h\u0026#34; #include \u0026#34;CMessageExt.h\u0026#34; int doConsumeMessage(struct CPushConsumer *consumer, CMessageExt *msgExt) { printf(\u0026#34;Topic:%s, Body:%s\\n\u0026#34;, GetMessageTopic(msgExt), GetMessageBody(msgExt)); return E_CONSUME_SUCCESS; } int main(int argc, char *argv[]) { CPushConsumer *consumer = CreatePushConsumer(\u0026#34;Group_Consumer_Test\u0026#34;); SetPushConsumerNameServerAddress(consumer, \u0026#34;127.0.0.1:9876\u0026#34;); Subscribe(consumer, \u0026#34;T_TestTopic\u0026#34;, \u0026#34;*\u0026#34;); RegisterMessageCallback(consumer, doConsumeMessage); StartPushConsumer(consumer); for (int i = 0; i \u0026lt; 6; i++) { sleep(10); } ShutdownPushConsumer(consumer); DestroyPushConsumer(consumer); return 0; } 3.3.3 编译运行 按照之前的示例编译即可\n1 2 g++ -o t_producer t_producer.cpp -I/root/package/rocketmq-client-cpp/include/ -L/root/package/rocketmq-client-cpp/bin -lrocketmq -lpthread -lz -ldl -lrt -std=c++11 g++ -o t_pushConsumer t_pushConsumer.cpp -I/root/package/rocketmq-client-cpp/include/ -L/root/package/rocketmq-client-cpp/bin -lrocketmq -lpthread -lz -ldl -lrt -std=c++11 运行\n1 2 3 4 5 # 第一个窗口 ./t_producer # 另一个窗口 ./t_pushConsumer producer 返回 result status:0 则发送成功\ncondumer 能收到消息则说明消费成功\n参考 https://blog.csdn.net/liitdar/article/details/87928544\nhttps://github.com/apache/rocketmq-client-cpp\nhttps://github.com/apache/rocketmq/tree/master/docs/cn\nhttp://rocketmq.apache.org/docs/quick-start/\n","date":"2020-05-27T10:58:12+08:00","permalink":"https://gitsang.github.io/p/rocketmq-%E9%83%A8%E7%BD%B2%E5%8F%8A%E7%BC%96%E7%A8%8B%E7%A4%BA%E4%BE%8B/","title":"RocketMQ 部署及编程示例"},{"content":"1. RocketMQ 概述 1.1 RocketMQ 是什么 RocketMQ 是阿里巴巴开源的分布式消息中间件，并于 2016 年捐赠给了 Apache 基金会。并且经历了双十一万亿级数据的洗礼，性能和可靠性都又足够的保障。\n1.2 为什么使用 RocketMQ 使用 Java 开发，还提供了不同语言 (C++/Go) 的 SDK，可以比较方便地从源码解决问题\nRocketMQ 原生支持分布式\nRocketMQ 能够保证严格地消息顺序\n堆积了亿级的消息后，依然保持写入低延迟\n2. RocketMQ 核心概念简述 2.1 角色 生产者（Producer） 发送消息的客户端角色，通常是产生数据的业务\n生产者组（Producer Group） 发送同类消息的 producer 组合标识，这些 producer 通常发送逻辑一致。\n对于普通消息，仅用作标识，无特别用处。主要用处是再发送事务消息时，如果某个 producer 崩溃，到达超时时间后，broker 能根据 group 查找组内的其他 producer 以确定这条消息是 commit 还是 rollback。\n消费者（Consumer） 消费消息的客户端角色。通常是后台处理异步消费的系统。\n消费者从 brokers 中拉取消息，并且将消息传递给业务系统。从用户应用的角度看，提供了两种类型的消费者：pullconsumer 和 pushconsumer\n消费者组（Consumer Group） 消费同类消息的 consumer 组合标识，这些 consumer 通常消费逻辑一致。在消息消费方面达到负载均衡和容错。\n注： rocketmq 要求同一个 consumer group 的消费者必须要拥有相同的注册信息，即必须要听一样的 topic (并且 tag 也一样)。\n2.2 概念术语 消息（Message） 消息就是被传递的信息。消息必须要有一个主题。消息还可以有可选的标记及键值对。\n消息队列（Message Queue） 消息的物理管理单位，每个 topic，每个 broker 都会有若干个 queue\n主题（Topic） 主题用于标识一类消息，是消息的逻辑管理单元。\n标记（Tag） 类似于子主题，业务通过 topic + tag 订阅到想要的消息\n2.3 服务组件 代理人（Broker） 是处理消息存储，转发等工作的服务器\nbroker 以 group 区分，每个 group 有一个 master 和若干 slave\nbroker 向所有的 nameserver 结点建立长连接，注册 topic 信息\n名称服务器（Name Server） 用于向客户端提供路由信息，客户端依靠 Name Server 获取对应 topic 的路由信息，从而决定连接哪些 Broker。\nFilter Server RocketMQ 可以允许消费者上传一个 Java 类给 Filter Server 进行过滤。\n2.4 消息模式（Message Model） 集群模式（Clustering） RocketMQ 有多种 Broker 集群部署模式，常见的包括：单 Master 模式、多 Master 模式、多 Master 多 Slave 模式（异步复制）、多 Master 多 Slave 模式（同步双写）等。\n每种模式都有各自的有缺点:\n单 Master：损耗小，部署简单，但是风险极大，一般不会使用\n多 Master：单个 Broker 挂掉对整体服务没影响，但挂掉的 Master 中的消息在恢复前不可订阅，消息实时性受到影响\n多 Master 多 Slave（异步复制）：主备异步复制，会有 ms 级别的延迟，Master 挂掉可能导致 ms 级别的数据丢失（未同步到 slave）\n多 Master 多 Slave（同步双写）：主备同步复制，能保证主从数据最终一致，可用性高，但性能稍低\n下图为多 Master 多 Slave 结构\n在 Clustering 模式下，同一个 Consumer Group 里的每个 Consumer 消费订阅消息的一部分内容，从而达到负载均衡的目的。\n广播模式（Broadcasting） 在 Broadcasting 模式下，同一个 Consumer Group 里的每个 Consumer 都消费订阅的全部消息。\n2.5 消息顺序（Message Order） 当使用 DefaultMQPushConsumer 时，可以按顺序或同时使用消息。\n顺序（Orderly） 按顺序消费消息意味着是按照生产者发送的顺序进行消费。如果使用全局顺序场景，必须确保使用该 topic 的只有一个消息队列。\n顺序消费还分为普通顺序和严格顺序，普通顺序在 Broker 宕机情况下会出现短暂的顺序不一致，严格顺序则牺牲系统可用性，集群中只要一个不可用会导致整个集群不可用。\n注意：如果指定了是有序消费，那么最大并发量是消费者组订阅的消息队列的数量。\n并发（Concurrently） 如果指定了并发消费消息，最大的并发量是为每个使用者客户端指定的线程池的数量。\n注意：消息的顺序在此模式下是不能保证的。\n参考 https://juejin.im/post/5d89e0cef265da03d9257900\nhttps://developer.51cto.com/art/201902/591997.htm\nhttps://www.jianshu.com/p/3afd610a8f7d\nhttps://blog.csdn.net/liitdar/article/details/87928598?utm_medium=distribute.pc_relevant.none-task-blog-baidujs-3\nhttps://blog.csdn.net/hu_zhiting/article/details/99703877\nhttps://zhuanlan.zhihu.com/p/25069846\nhttp://jm.taobao.org/2017/01/12/rocketmq-quick-start-in-10-minutes/\n","date":"2020-05-26T09:33:46+08:00","permalink":"https://gitsang.github.io/p/rocketmq-%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E5%8F%8A%E6%9C%AF%E8%AF%AD/","title":"RocketMQ 核心概念及术语"},{"content":"1. MQ 的优缺点及对比 1.1 什么是 MQ 消息队列（Message Queue）是一种进程间通信或同一进程的不同线程间的通信方式，简单来说就是用来存储通信消息的队列。\n1.2 为什么使用 MQ 解耦、异步、削峰\n1.2.1 解耦 传统模式的系统中，假设 A 系统需要将生产的数据发送给 B、C，那么只需要直接调用 B、C 提供的接口。但如果之后有新的系统 D 也需要这份数据，那 A 就必须修改代码调用 D 的接口，以后每添加一个需要 A 数据的系统，或是某个系统不需要接入 A 了，A 都需要修改代码，且当下游系统宕机还会对 A 也产生影响。\n因此需要 MQ 中间件实现系统的解耦。A 只需要将数据发送到 MQ 里，其他系统如果需要可以对数据进行订阅，不需要了就取消订阅。这样 A 只需要编写消息生产的代码，A 也不再需要考虑其他系统的异常情况。\n1.2.2 异步 假设 A 系统向 B 发送一条消息需要 5ms，但 B 解析完成这条消息需要 200ms，传统模式中，A 调用 B 完成一条消息发送到返回，需要 205ms。在这个过程 A 系统浪费掉了 200ms 的时间。\n使用消息队列后，A 系统只需要一股脑地将数据丢进消息队列，然后返回即可。这样只需要消耗向 MQ 传输数据的时间，让 B 慢慢地异步处理这些消息就行。这样能让 A 系统迅速完成工作，同时也不会长时间地占用连接。\n1.2.3 削峰 假设 A 系统稳定情况下，每秒能够处理几百个请求，正常地使用都是 OK 的。但是如果突然出现每秒几千的请求，可能系统就直接被打死了，按照传统的模式解决这种问题的方法只能是增加机器分担请求。\n如果使用 MQ 则可以按照系统可承受的并发量慢慢拉取消息，而超过系统处理量的消息就积压在 MQ 中，等高峰期过去后再慢慢消费。\n1.3 使用 MQ 的缺点 1.3.1 可用性/可靠性下降 加入 MQ 后就需要考虑 MQ 挂掉后怎么办，无疑为整个系统增加了隐患。且还需要保证消息如何不重复生产，不重复消费，传输过程是否可能丢失等等\n1.3.2 系统复杂度增加 加入 MQ 后还需要考虑数据一致性问题，数据的时序性问题等等。\n1.4 常见 MQ 对比 参考 https://blog.csdn.net/yssycz/article/details/80133084\nhttps://juejin.im/post/5b32044ef265da59654c3027\n","date":"2020-05-22T15:44:34+08:00","permalink":"https://gitsang.github.io/p/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%AE%80%E4%BB%8B/","title":"消息队列简介"},{"content":"搭建ELK日志系统 1. elk 简介 官网介绍:\n“ELK”是三个开源项目的首字母缩写，这三个项目分别是：Elasticsearch、Logstash 和 Kibana。\nElasticsearch 是一个搜索和分析引擎。Logstash 是服务器端数据处理管道，能够同时从多个来源采集数据，转换数据，然后将数据发送到诸如 Elasticsearch 等“存储库”中。Kibana 则可以让用户在 Elasticsearch 中使用图形和图表对数据进行可视化。\nElastic Stack 是 ELK Stack 的更新换代产品。\n2. 搭建过程简述 本次搭建我们采用 docker 安装 sebp/elk 的方式，一键部署 elk 系统，这比每个系统单独部署会省去许多不必要的麻烦。\n这样的搭建方式我们仅仅需要安装运行 elk 和 filebeats 就可以完成了\n搭建完成后通过 ip:5601 就可以访问到日志展示的页面了\n3. 开始搭建 3.1 环境搭建 首先需要为你的系统安装 docker 环境，对于没接触过 docker 的同学，你可以将其简单理解为虚拟机（当然 docker 和虚拟机有本质的区别，有兴趣的可以自行搜索），docker 的安装很简单，对于 Linux / MacOS 几乎都只需要一条命令就可以安装完成了，而 Windows 则比较特殊，exe 安装包使用下一步安装法也很容易安装完成，但实际上 windows 平台某些版本是无法安装成功的，比如家庭版 windows，不过对于服务器，应该很少有人用 windows 搭建的吧。\n当然官方也提供了十分简介友好的快速入门教程 https://www.docker.com/get-started 包括了安装、使用和一些进阶操作，即使是英语苦手，也能轻松地入门，十分推荐大家去看一眼。\n这里就仅以 CentOS 7.8 为例进行安装\n1 2 3 4 5 6 # 更新包管理工具 yum update # 安装 docker yum install docker # 启动 docker service docker start 到这步为止，docker 就算安装完成了\n3.2 拉取 elk 镜像并运行 docker 拥有非常完善地 hub，你可以在 https://hub.docker.com/ 找到各类的镜像。\n我们在其中搜索 sebp/elk 就可以找到我们想要的镜像了，同样，如果你想要对每个服务单独安装，你也可以搜索 elasticsearch kibana logstash 查看。\n在 Overview 标签中，我们复制 Docker Pull Command docker pull sebp/elk 到系统中运行，即可完成镜像的拉取（国内的服务器可能会有些慢），如果你想要安装其他版本的 elk，也可以点击 Tags 标签获取其他版本的拉取方式。\n等待拉取结束后，运行\n1 2 3 docker run --name elk -it -d \\ -p 5601:5601 -p 5044:5044 -p 9200:9200 -p 9300:9300 \\ sebp/elk 其中：\n\u0026ndash;name 用于指定 docker 名称 -d 表示在后台运行 (detach) -it 用于保持 STDIN 开启和开启终端登录 (是为了使能够进入容器进行操作且退出时容器不会自动关闭) -p 表示端口的映射关系，如 -p 5601:5601 就表示将 docker 的 5601 端口映射到主机的 5601 端口 第一次运行可以不加 -d 参数，这样做能够方便你看到出现了哪些错误。\n等待一段时间后通过浏览器输入 ip:5601 如果能够登录到 kibana 界面，那么 elk 就算是搭建成功了（对于性能不太好的机器 kibana 的加载可能会比较慢，耐心等待即可）\n如果你出现 vm.max_map_count 不足的错误，可以参考这篇文章增加配置\n3.3 安装 filebeats filebeats 作为 Elastic Stack 的新成员，主要负责日志的收集工作。\n你可以在 https://www.elastic.co/cn/beats/filebeat 找到 filebeats 对应各系统的安装包进行安装。\n同样以 CentOS 为例，下载并解压 filebeat\n1 2 wget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.7.0-linux-x86_64.tar.gz tar zxvf https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.7.0-linux-x86_64.tar.gz 然后修改以下 filebeat 的配置，让 filebeat 知道我们需要采集的是哪个日志文件，用 vim (或其他文本编辑器) 打开配置文件\n1 2 cd filebeat-7.7.0-linux-x86_64 vim filebeat.yml 修改 filebeat.inputs: output.**: 下的几个参数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 filebeat.inputs: - type: log enable: true # 这个一定要设置为 true 否则不会应用下面的参数 paths: - /path/to/your/logfile # 这里填写你的 log 文件路径 # elasticsearch 和 logstash 只能二者选其一，不使用的需要将其注释掉 # 这里先以直接发送到 elasticsearch 为例 # 因为如果使用 logstash 还需要进行额外的设置 output.elasticsearch: hosts: [\u0026#34;localhost:9200\u0026#34;] #output.logstash: #hosts: [\u0026#34;localhost:5044\u0026#34;] 设置完成后保存退出，然后运行\n1 ./filebeat -e -c filebeat.yml -d \u0026#34;publish\u0026#34; 然后到 ip:5601/app/infra#/logs 下如果能够查看到你的日志文件就说明成功了\n就可以终止 filebeats 然后在后台运行\n1 nohup ./filebeat -e -c filebeat.yml -d \u0026#34;publish\u0026#34; \u0026gt; filebeat.log 2\u0026gt;\u0026amp;1 \u0026amp; 4. 对于性能不足的服务器进行的优化 如果使用上述方式，会消耗大约 2G 的内存，对于一些小型服务器，可能不足以支撑（比如我的 1C2G）\n这时候就需要对 elk docker 进行一些限制了\n4.1 分配 swap 1 2 3 4 5 6 7 8 9 10 # 设置 swap 文件 dd if=/dev/zero of=/.swap bs=1048576 count=4096 # 创建(格式化) swap mkswap /.swap # 启动 swap swapon /.swap # 查看 swap 使用情况 # free -h # 设置开机自启 echo \u0026#34;/.swap swap swap defaults 0 0\u0026#34; \u0026gt;\u0026gt; /etc/fstab 4.2 docker run 参数调优 1 2 3 4 5 6 7 8 docker run --name elk -it -d \\ -p 5601:5601 -p 5044:5044 -p 9200:9200 -p 9300:9300 \\ -e ELASTICSEARCH_START=1 \\ -e KIBANA_START=1 \\ -e LOGSTASH_START=0 \\ -e ES_HEAP_SIZE=\u0026#34;256m\u0026#34; \\ -m 512M --memory-swap=2048M \\ sebp/elk 由于 filebeats 将数据直接发送到了 elasticsearch 所以 logstash 就不需要运行了，可以通过这只环境变量 LOGSTASH_START=0 禁止其运行， ES_HEAP_SIZE=\u0026quot;256m\u0026quot; 限制 elasticsearch 堆栈使用大小，-m 512M --memory-swap=2048M 从 docker 层面限制 elk 容器能够使用的最大物理内存和 swap\n对于其他的参数及环境变量的配置可以通过 https://elk-docker.readthedocs.io/ 了解，文档中对各个参数的用途都有详细的说明\n4.3 其他调优方式 如果你有多台服务器，你也可以将 elk 部署到其他的性能较好的服务器上，然后通过 filebeats 指定对应的 ip 向其发送信息。这样也能最大程度地减少服务器负担。特别是对于多个服务器都需要采集数据的情况下，在每一台机器都部署一个 elk 完全没有必要。\n5. 单独拉取每个系统镜像 仅作参考，如果你需要单独部署每个服务（或者你就是不想使用 sebp/elk），你可以参考以下方法\n其实就是单独拉取镜像然后部署，修改配置\n1 2 3 4 5 6 7 8 9 docker pull elasticsearch:7.7.0 docker run -d --name elasticsearch \\ --restart=always \\ -p 9200:9200 -p 9300:9300 \\ -e ES_JAVA_OPTS=\u0026#34;-Xms128m -Xmx128m\u0026#34; \\ -e \u0026#34;discovery.type=single-node\u0026#34; \\ -m 128M --memory-swap=256M \\ docker.io/elasticsearch:7.7.0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 docker pull kibana:7.7.0 docker run -d --name kibana \\ --restart=always \\ -p 5601:5601 \\ -m 256M --memory-swap=512M \\ docker.io/kibana:7.7.0 docker exec -it kibana bash vi config/kibana.yml # 修改 elasticsearch.hosts exit docker restart kibana 参考 swap: https://www.jianshu.com/p/36a81d5ec54e https://blog.csdn.net/yabingshi_tech/article/details/77323617\ndocker 限制内存 https://www.hangge.com/blog/cache/detail_2413.html\nelk curl http://www.ruanyifeng.com/blog/2017/08/elasticsearch.html\nmcbbs https://www.mcbbs.net/thread-863367-1-1.html\nvm.max_map_count 不足 https://www.jianshu.com/p/04f4d7b4a1d3\nelk-docker 安装 https://wsgzao.github.io/post/elk/\n","date":"2020-05-16T22:29:30+08:00","permalink":"https://gitsang.github.io/p/%E6%90%AD%E5%BB%BAelk%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/","title":"搭建ELK日志系统"},{"content":"PostgreSQL 下载安装 在官网页面1能够找到不同系统和不同软件版本的安装方式 https://www.postgresql.org/download\n本文以 CentOS 7 为例，安装 PostgreSQL-12.2 版本，其余版本的安装根据官网操作即可\n根据提示选择 RetHat 安装，选择安装版本，安装平台，系统架构，会自动出现 RPM 安装说明\nInstall the repository RPM: 1 yum install https://download.postgresql.org/pub/repos/yum/reporpms/EL-7-x86_64/pgdg-redhat-repo-latest.noarch.rpm Install the client packages: 1 yum install postgresql12 Optionally install the server packages: 1 yum install postgresql12-server Optionally initialize the database and enable automatic start: 1 2 3 /usr/pgsql-12/bin/postgresql-12-setup initdb systemctl enable postgresql-12 systemctl start postgresql-12 至此已经安装完成并启动了 pg，一般按照官网途径进行安装不会出现太大问题，如果使用的是非官方的途径或源码安装失败可以尝试卸载后使用官方方式重新安装\n安装过程中可能会询问安装用户、密码、位置、端口等信息，为了避免不必要的麻烦一般使用默认值即可\nPostgreSQL 基本使用 安装成功后会建立一个 pg 超级用户 postgres 默认密码为 postgres，通过命令\n1 2 [root@host] # su - postgres Password: 可登录 postgres 账户\n登录后可按照以下步骤来创建数据库\n1 2 3 4 5 6 [postgres@host] $ createdb testdb [postgres@host] $ psql testdb psql (12.2, server 11.1) Type \u0026#34;help\u0026#34; for help. postgres=# 至此数据库就创建成功了\n根据提示，使用 psql 时候可以使用 help 命令查看帮助，对于一个特定的命令语法使用下面的命令\n1 postgres=# help \u0026lt;command_name\u0026gt; 然后就可以直接输入 SQl 语句进行数据库操作（需要注意的是 SQL 语句要以分号结尾）\n查看 PostgreSQL 服务 通过以下命令可以查看 PostgreSQL 的运行情况，以及端口信息等\n1 2 3 ps aux | grep postgres netstat -npl | grep postgres netstat -a | grep PGSQL 参考 PostgreSQL: Download\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2020-05-14T14:53:28+08:00","permalink":"https://gitsang.github.io/p/1-postgresql-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/","title":"[1] PostgreSQL 快速入门"},{"content":"连接 pg 通过以下命令可访问远程机器上的 pg\n1 # psql -U postgres -h 10.200.110.110 -p 5432 连接被拒绝的解决方案 连接被拒 1 大多数情况下 pg 会禁止远程接入，通过以上命令，或其他方式接入 pg 可能被拒绝访问，出现如下错误123\n1 psql: error: could not connect to server: FATAL: Ident authentication failed for user \u0026#34;postgres\u0026#34; 或其他类似的错误\n1 Connection to 10.200.110.110:5432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections. 解决方法 编辑安装 pg 机器上的 /var/lib/pgsql/data/postgresql.conf 文件，修改\n1 #listen_addresses = \u0026#39;localhost\u0026#39; 成\n1 listen_addresses = \u0026#39;*\u0026#39; 修改完成后通过命令重启 pg 即可\n1 [postgres@host] $ pg_ctl restart 连接被拒绝 2 上述方法可能依然无法解决连接被拒绝的问题，是由于在客户端访问PostgreSQL数据库时，PostgreSQL会读取文件pg_hba.conf判断是否信任该主机，故所有需要连接PostgreSQL Server的主机都应当在pg_hba.conf中添加对其信任，即使是Server主机也不例外\n1 2 3 psql: could not connect to server: Connection refused Is the server running on host \u0026#34;my host name\u0026#34; (IP) and accepting TCP/IP connections on port 5432? 解决方法 编辑安装 pg 机器上的 /var/lib/pgsql/data/pg_hba.conf 文件，在末尾添加如下：\n1 host all all \u0026lt;host_ip\u0026gt;/32 trust host_ip 填写连接机器的 ip，或直接填入 0.0.0.0/0\ntrust 可以更改为 password 通过密码连接\n修改完成后通过命令重启 pg 即可\n1 [postgres@host] $ pg_ctl restart 重启失败 通过 pg_ctl 重启 pg 可能出现失败。\n1 2 pg_ctl: no database directory specified and environment variable PGDATA unset Try \u0026#34;pg_ctl --help\u0026#34; for more information. 解决方法 从报错信息可以看出是没有配置环境变量 PGDATA\n编辑 postgres(或其他数据库管理员) 用户的用户配置文件4\n1 [postgres@host ~] $ vim ~/.bash_profile 按照实际路径在用户配置文件中添加 PGDATA 变量。默认该路径在数据库软件安装路径下的data目录。\n1 export PGDATA=/var/lib/pgsql/data 然后重新接在配置文件\n1 [postgres@host ~] $ source ~/.bash_profile 找不到 pg_ctl 命令 1 -bash: pg_ctl: command not found 解决方法 原因是 pg 的 bin 目录不在 PATH 环境变量下\n可以修改配置文件，添加 bin 路径到 PATH 下5\n1 PATH=$PATH:$HOME/bin:/usr/pgsql-12/bin/ 这里我直接在 postgres 用户的 ~/.bash_profile 下添加了一个 PATH，这样登录 postgres 才会添加这个 bin 路径\n参考 PostgreSQL一些简单问题以及解决办法 - CSDN\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPostgreSQL问题解决\u0026ndash;连接失败 - CSDN\u0026#160;\u0026#x21a9;\u0026#xfe0e;\npsql: FATAL: Ident authentication failed for user “postgres” - stackoverflow\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n使用pg_ctl启动数据库时报错 - CSDN\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n初识Postgresql和Sqoop - oschina\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2020-05-14T14:53:28+08:00","permalink":"https://gitsang.github.io/p/2-%E5%BB%BA%E7%AB%8B-postgresql-%E8%BF%9E%E6%8E%A5%E5%8F%8A%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/","title":"[2] 建立 PostgreSQL 连接及常见错误解决方法"},{"content":"创建多个 postgres 实例 postgres 可以通过指定不同的 data 目录以启动多个实例。1\n首先登录 postgres 用户\n1 sudo -su postgres 然后运行此命令初始化 data 目录\n1 /usr/lib/postgresql/9.5/bin/pg_ctl init -D /var/lib/postgresql/9.5/main_2 会在 main_2 目录里生成 pg_hba.conf 和 postgres.conf\n需要在 postgres.conf 指定端口和 hba_path，（可以 copy 之前的 conf 文件 /etc/postgresql/9.5/main/postgresql.conf）\n将 conf 文件修改为\n1 2 3 4 5 data_directory = \u0026#39;/var/lib/postgresql/9.5/main_2\u0026#39; hba_file = \u0026#39;/var/lib/postgresql/9.5/main_2/pg_hba.conf\u0026#39; ident_file = \u0026#39;/var/lib/postgresql/9.5/main_2/pg_ident.conf\u0026#39; external_pid_file = \u0026#39;/var/run/postgresql/9.5-main-2.pid\u0026#39; port = 5433 运行命令，启动 postgres\n1 /usr/lib/postgresql/9.5/bin/pg_ctl -D /var/lib/postgresql/9.5/main_2 -l /var/log/postgresql/pg_5433.log start 参考 Postgresql笔记（一）安装/配置/启动/运行多个实例\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2020-05-14T14:53:28+08:00","permalink":"https://gitsang.github.io/p/3-postgresql-%E5%88%9B%E5%BB%BA%E5%A4%9A%E4%B8%AA%E5%AE%9E%E4%BE%8B/","title":"[3] PostgreSQL 创建多个实例"},{"content":"Comment 为 pg 数据库的表和列添加注释 添加表注释 1 COMMENT ON TABLE \u0026#34;public\u0026#34;.t1 IS \u0026#39;表注释内容\u0026#39;; 查看注释 1 select description from pg_description join pg_class on pg_description.objoid = pg_class.oid where relname = \u0026#39;t1\u0026#39;; 注释存储在 pg_description 表的 description 字段中，用来查找的每张表的 objoid 存储在 pg_class 中。\n添加列注释 1 2 create table t1(id int primary key, cc char(10)); comment on column t1.id is \u0026#39;列注释内容\u0026#39;; Postgres 查重复数据 1 select * from pg_public_tree_node ou where (select count(*) from pg_public_tree_node inr where inr.id = ou.id) \u0026gt; 1; ","date":"2020-05-14T14:53:28+08:00","permalink":"https://gitsang.github.io/p/4-postgresql-%E8%AF%AD%E6%B3%95%E9%9B%B6%E6%95%A3%E6%80%BB%E7%BB%93/","title":"[4] PostgreSQL 语法零散总结"},{"content":" 1. Linux常用命令 1.1 终端命令格式 1 command [-option] [parameter] command 命令名 [-option] 选项，用于控制命令，可省略 [patameter] 参数，可以是零到多个 终端常用快捷键\n'ctrl' + '+' 放大终端字体 'ctrl' + '-' 缩小终端字体 tab 可自动补全指令 上/下光标可切换历史命令 ctrl + c 退出选择 1.2 常用终端命令及常用选项 1.2.1 文件和目录命令 命令语法 作用 选项 解释 clear 清屏 清屏 ls [-opt] 查看当前文件夹内容 -a 显示所有文件及目录 (包括开头为.的隐藏档) -l 以列表方式显示文件详细信息 -h 配合-l使用，以人性化方式显示文件大小 -R 若目录下有文件，则以下之文件亦皆依序列出 pwd 显示工作目录路径 cd [dirName] 切换目录 touch [-opt] name 触摸（创建）文件 mkdir [-opt] dirName 创建目录 -p 递归创建目录 tree [-opt] [dirName] 显示目录树状图结构 -d 只显示目录 cd name 切换目录 cd 命令参数\ncd 切换到当前用户的主目录(/home/user) cd ~ 切换到当前用户的主目录(/home/user) cd . 当前目录 cd .. 上级目录 cd - 在最近两次工作目录来回切换 1.2.2 拷贝、移动、删除命令 命令语法 作用 选项 解释 rm [-opt] name 删除文件 -f 强制删除，忽视不存在文件 -r 递归删除目录 mv [-opt] source dest 移动（重命名）文件/目录 -i 覆盖文件前提示 cp [-opt] source dest 复制文件 -f 直接覆盖文件 -i 覆盖文件前提示 -r 递归复制目录及所有子目录/文件 1.2.3 文件内容命令 命令语法 作用 选项 解释 cat fileName 查看文件内容 -b 对非空行标号 -n 对所有行标号 more fileName 分屏显示文件内容 grep [-opt] [param] 文本搜索工具 -n 显示匹配行及行号 echo param 终端显参数指定文字 \u0026gt; 和 \u0026gt;\u0026gt; 重定向 \u0026gt; 输出（覆盖所有内容） \u0026gt;\u0026gt; 追加（追加到文件末尾） 1.2.4 文件名通配符 * 任意个数个字符 ? 任意一个字符 [] 可匹配字符组中的一个 [abc] 匹配a、b、c中的任意一个 [a-f] 匹配 a 到 f 范围内的任意一个 1.3 查阅帮助 命令的查阅一般有以下两种方式\n1 command --help 1 man command man是 manual 的缩写，为Linux提供的内置手册\nman操作键及功能说明：\n操作键 功能 Space 显示下一屏 Enter 滚动一行 b 回滚一屏 f 显示下一屏 q 退出 /word 搜索word字符串 2. Linux文件权限与目录配置 输入ls -al命令列出所有的文件详细权限与属性，显示如下\n1 2 3 4 5 dr-xr-x---. 7 root root 264 Jul 2 18:49 . dr-xr-xr-x. 18 root root 237 May 16 17:35 .. drwxr-xr-x 3 root root 15 Jul 2 18:47 a drwx------ 3 root root 17 Mar 15 16:08 .ansible -rw------- 1 root root 18390 Sep 19 2018 .bash_history 3. vim文本编辑器 3.1 vim的三种模式 命令模式：不能直接编辑文件，可输入快捷键操作（删除行、复制行、移动光标等） 编辑模式：可用于编辑文本 末行模式：在末行输入命令进行操作（搜索、替换、保存、退出、高亮）\nvim打开文件命令 作用 vim filename 打开指定文件 vim +num filename 打开指定文件，将光标移到指定行 vim +/keyword filename 打开指定文件，高亮显示关键词 vim filename1 filename2 filename3 同时打开多个文件 3.2 vim编辑器常用操作 以下命令或操作中n代表具体数字，如nG代表1G、2G、36G等。\n1、光标移动命令\n操作 作用 H J K L 前 下 上 后 0 / ^ 移动到行首 $ 移动到行尾 gg 移动到文件开始位置 G 移动到文件末尾 nG 移动到指定行 n↑ / n↓ 光标上下移n行 n← / n→ 光标左右移n列 :n 移动到n行 2、复制 / 粘贴 / 删除 / 撤销操作\n操作 作用 yy 复制 nyy 复制n行 p 粘贴到光标所在行的下一行 P 粘贴到光标所在行 x 删除（剪切）光标后字符 x 删除（剪切）光标后字符 X 删除（剪切）光标前字符 dw 删除（剪切）光标后单词（delete word） d0 / d^ 删除（剪切）光标前整行（delete to 0） d$ / D 删除（剪切）光标后整行（delete to $） dd 删除（剪切）当前行 ndd 删除（剪切）当前行开始往下n行 u 撤销 ctrl + r 重做 3.3 vim末行模式（: 或 / 进入） 基本操作\n基本操作 作用 :w 保存文件 :w filename 另存文件 :q 退出 ! 强制操作（一般跟在其他命令末尾输入） :!外部命令 调用外部命令(如 :!ls) set nu / set nonu 显示 / 不显示行号 查找 / 替换\n查找 / 替换 作用 /keyword 查找关键词 N / n 切换查找结果(上一个/下一个) :nohl 取消高亮 :s/查找的关键词/替换的关键词 替换本行第一处 :s/查找的关键词/替换的关键词/g 替换本行全部内容 :%s/查找的关键词/替换的关键词 替换整个文档中每一行的第一处 :%s/查找的关键词/替换的关键词/g 替换整个文档 多文件操作\n多文件操作 作用 vim file1 [file2 ...] 同时打开多个文件 #外部命令# :files 查看当前已打开文件 %a active表示正打开的文件 # 表示上一个打开的文件 :open filename 切换打开的文件 :bn 切换到下一个文件next :bp 切换到上一个文件prev 3.4 vim分屏操作 1、打开文件并且分屏\nvim建立和关闭分屏 作用 vim -O[n] file1 [file2 ...] 垂直分n屏 #外部命令# vim -o[n] file1 [file2 ...] 水平分n屏 #外部命令# :vs [file2] / :vsp / :vsplit 垂直分屏，不加文件名则将当前文件分屏 :sv [file2] / :sp / :split 水平分屏，不加文件名则将当前文件分屏 :new [newfile] 新建水平分屏 :only 关闭除当前分屏外的其他分屏 :qa 关闭所有分屏 ctrl+w + v 垂直分屏 \u0026lt;快捷键\u0026gt; ctrl+w + s 水平分屏 \u0026lt;快捷键\u0026gt; ctrl+w + n 新建水平分屏 \u0026lt;快捷键\u0026gt; ctrl+w + o 关闭除当前分屏外的其他分屏 \u0026lt;快捷键\u0026gt; ctrl+w + c 关闭当前分屏 \u0026lt;快捷键\u0026gt; vim分屏窗口调整\nvim分屏窗口调整 作用 \u0026lt;快捷键\u0026gt; ctrl+w + l 把光标移到右边的屏中 ctrl+w + h 把光标移到左边的屏中 ctrl+w + k 把光标移到上边的屏中 ctrl+w + j 把光标移到下边的屏中 ctrl+w + w 把光标移到下一个屏中 ctrl+w + p 把光标移到上一个屏中 ctrl+w + L 向右移动分屏 ctrl+w + H 向左移动分屏 ctrl+w + J 向上移动分屏 ctrl+w + K 向下移动分屏 ctrl+w + r 向下旋转窗口 ctrl+w + R 向上旋转窗口 ctrl+w + x 当前窗口与下一个窗口对调 ctrl+w + - 减少当前窗口高度 ctrl+w + + 增加当前窗口高度 ctrl+w + \u0026lt; 增加当前窗口宽度 ctrl+w + \u0026gt; 减少当前窗口宽度 ctrl+w + = 使所有窗口恢复均等 4. 参考 vim分屏 https://coolshell.cn/articles/1679.html https://www.jianshu.com/p/52949caa7e93\ngdb调试 https://www.ibm.com/developerworks/cn/linux/sdk/gdb/index.html\nlinux 下 JDK https://www.yiibai.com/java/how-to-install-java-on-ubuntu.html\nwindows 下 JDK https://www.runoob.com/java/java-environment-setup.html#linux-install\n","date":"2020-05-14T14:53:28+08:00","permalink":"https://gitsang.github.io/p/linux-command-quick-search/","title":"Linux Command Quick Search"},{"content":"1. somaxconn 设置过小 1.1 告警信息 1 WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128. 1.2 原因分析 somaxconn 限制了接收新 TCP 连接侦听队列的大小。对于一个经常处理新连接的高负载 web服务环境来说，默认的128太小了，大多数环境这个值建议增加到 1024 或者更多\n1.3 解决方法 方法 1 1 echo 2048 \u0026gt; /proc/sys/net/core/somaxconn 方法 2 1 2 echo \u0026#34;net.core.somaxconn = 2048\u0026#34; \u0026gt;\u0026gt; /etc/sysctl.conf sysctl -p 1.4 内核参数 somaxconn 详见 https://www.jianshu.com/p/f23150649c26\n2. 持久化数据正在写入 2.1 报错信息 1 ERROR: LOADING Redis is loading the dataset in memory 2.2 原因分析 redis 持久化的数据正在重写写入内存，需要等待数据写入完成后才可正常访问\n2.3 解决方法 修改配置文件 redis.conf\n1 2 3 maxmemory 5GB maxmemory-policy allkeys-lru appendonly no 重启 redis 并 rewrite\n1 ./redis_multi rewrite all 3. overcommit_memory 被设置为 0 3.1 告警信息 1 WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add \u0026#39;vm.overcommit_memory = 1\u0026#39; to /etc/sysctl.conf and then reboot or run the command \u0026#39;sysctl vm.overcommit_memory=1\u0026#39; for this to take effect. 3.2 原因分析 vm.overcommit_memory 被设置为 0， Background save 可能因为低内存失败\nvm.overcommit_memory = 0 表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存，内存申请允许；否则，内存申请失败，并把错误返回给应用进程。 vm.overcommit_memory = 1 表示内核允许分配所有的物理内存，而不管当前的内存状态如何。 vm.overcommit_memory = 2 表示内核允许分配超过所有物理内存和交换空间总和的内存 3.3 解决方法 根据提示\n1 2 echo \u0026#34;vm.overcommit_memory = 1\u0026#34; \u0026gt; /etc/sysctl.conf reboot 或\n1 sysctl vm.overcommit_memory=1 或\n1 echo 1 \u0026gt; /proc/sys/vm/overcommit_memory 4. 透明大页导致的告警 4.1 告警信息 1 WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command \u0026#39;echo never \u0026gt; /sys/kernel/mm/transparent_hugepage/enabled\u0026#39; as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled. 4.2 原因分析 当前使用的是透明大页，可能导致redis延迟和内存使用问题。\n4.3 解决方法 1 echo never \u0026gt; /sys/kernel/mm/transparent_hugepage/enabled 并将此语句添加到 /etc/rc.local\n","date":"2020-05-14T14:53:28+08:00","permalink":"https://gitsang.github.io/p/redis-%E5%B8%B8%E8%A7%81%E6%8A%A5%E9%94%99%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/","title":"Redis 常见报错及解决方法"},{"content":"RocketMQ 的安装和快速入门可以参考官方文档： http://rocketmq.apache.org/docs/quick-start/\n主要步骤为\nunzip -\u0026gt; mvn build -\u0026gt; Start Name Server -\u0026gt; Start Broker -\u0026gt; Send \u0026amp; Receive Message -\u0026gt; Shutdown Servers\n1. build 根据官方文档解压并 build\n1 2 3 4 \u0026gt; unzip rocketmq-all-4.6.1-source-release.zip \u0026gt; cd rocketmq-all-4.6.1/ \u0026gt; mvn -Prelease-all -DskipTests clean install -U \u0026gt; cd distribution/target/apache-rocketmq 如果安装其他版本的 RocketMQ 失败建议尝试使用官方最新版的进行安装部署\n比如按照其他教程安装 rocketmq-all-4.2.0-bin-release 版本时出现 Build 错误，如果不是必须使用该版本可以使用官方最新版重新安装 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 [INFO] Error stacktraces are turned on. [INFO] Scanning for projects... [INFO] ------------------------------------------------------------------------ [INFO] BUILD FAILURE [INFO] ------------------------------------------------------------------------ [INFO] Total time: 0.109s [INFO] Finished at: Tue Feb 25 10:35:49 CST 2020 [INFO] Final Memory: 10M/483M [INFO] ------------------------------------------------------------------------ [WARNING] The requested profile \u0026#34;release-all\u0026#34; could not be activated because it does not exist. [ERROR] The goal you specified requires a project to execute but there is no POM in this directory (/root/project/rocketmq-all-4.2.0-bin-release). Please verify you invoked Maven from the correct directory. -\u0026gt; [Help 1] org.apache.maven.lifecycle.MissingProjectException: The goal you specified requires a project to execute but there is no POM in this directory (/root/project/rocketmq-all-4.2.0-bin-release). Please verify you invoked Maven from the correct directory. at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:89) at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:320) at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:156) at org.apache.maven.cli.MavenCli.execute(MavenCli.java:537) at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:196) at org.apache.maven.cli.MavenCli.main(MavenCli.java:141) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:290) at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:230) at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:414) at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:357) [ERROR] [ERROR] Re-run Maven using the -X switch to enable full debug logging. [ERROR] [ERROR] For more information about the errors and possible solutions, please read the following articles: [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MissingProjectException 如果 mvn 成功，应该会显式如下信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 [INFO] Reactor Summary: [INFO] [INFO] Apache RocketMQ 4.6.1 ............................. SUCCESS [27.086s] [INFO] rocketmq-logging 4.6.1 ............................ SUCCESS [6.473s] [INFO] rocketmq-remoting 4.6.1 ........................... SUCCESS [14.091s] [INFO] rocketmq-common 4.6.1 ............................. SUCCESS [10.506s] [INFO] rocketmq-client 4.6.1 ............................. SUCCESS [10.648s] [INFO] rocketmq-store 4.6.1 .............................. SUCCESS [7.832s] [INFO] rocketmq-srvutil 4.6.1 ............................ SUCCESS [0.474s] [INFO] rocketmq-filter 4.6.1 ............................. SUCCESS [2.033s] [INFO] rocketmq-acl 4.6.1 ................................ SUCCESS [3.983s] [INFO] rocketmq-broker 4.6.1 ............................. SUCCESS [3.226s] [INFO] rocketmq-tools 4.6.1 .............................. SUCCESS [1.945s] [INFO] rocketmq-namesrv 4.6.1 ............................ SUCCESS [0.925s] [INFO] rocketmq-logappender 4.6.1 ........................ SUCCESS [2.969s] [INFO] rocketmq-openmessaging 4.6.1 ...................... SUCCESS [2.127s] [INFO] rocketmq-example 4.6.1 ............................ SUCCESS [1.074s] [INFO] rocketmq-test 4.6.1 ............................... SUCCESS [5.010s] [INFO] rocketmq-distribution 4.6.1 ....................... SUCCESS [2:16.341s] [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 3:57.044s [INFO] Finished at: Tue Feb 25 10:44:18 CST 2020 [INFO] Final Memory: 71M/1632M [INFO] ------------------------------------------------------------------------ 2. Start 根据官方文档，需要进入 rocketmq 的 bin 目录下后台运行 mqnamesrv 和 mqbroker\n但是上一步的 cd distribution/target/apache-rocketmq 可能由于目录结构变化，rocketmq 路径会有所不同\n2020.02.25 时从官网下载的 4.6.1 版本具体路径应该为 /path/to/rocketmq-all-4.6.1-source-release/distribution/target/rocketmq-4.6.1/rocketmq-4.6.1/ 根据不同版本可能也会有不同的路径\n2.1 Start Name Server 1 2 3 \u0026gt; nohup sh bin/mqnamesrv \u0026amp; \u0026gt; tail -f ~/logs/rocketmqlogs/namesrv.log The Name Server boot success... 根据官方文档直接运行 nohup sh bin/mqnamesrv \u0026amp; 可能会在 nohup.out 或输出中出现如下错误\n1 sh: /usr/local/rocketmq/bin/runserver.sh: No such file or directory 这明显是由于环境变量配置错误导致的，runserver.sh 应该在当前目录下的 bin 里面，即本文的 /path/to/rocketmq-all-4.6.1-source-release/distribution/target/rocketmq-4.6.1/rocketmq-4.6.1/bin 目录下\n因此要为 RocketMQ 添加环境变量\n1 vim /etc/profile 打开 profile 文件新增 ROCKETMQ_HOME 和 PATH 环境变量\n1 2 3 # ROCKETMQ_HOME 填自己的 rocketmq 路径，本文配置如下 export ROCKETMQ_HOME=/root/project/rocketmq-all-4.6.1-source-release/distribution/target/rocketmq-4.6.1/rocketmq-4.6.1 export PATH=$ROCKETMQ_HOME/bin:$PATH 配置完成后使用 source /etc/profile 重新加载 profile 文件，然后再重新执行之前的步骤即可\n运行成功后，打开当前目录下的 nohup.out 能看到如下信息：\n1 2 3 Java HotSpot(TM) 64-Bit Server VM warning: Using the DefNew young collector with the CMS collector is deprecated and will likely be removed in a future release Java HotSpot(TM) 64-Bit Server VM warning: UseCMSCompactAtFullCollection is deprecated and will likely be removed in a future release. The Name Server boot success. serializeType=JSON 并且默认情况下会在 ~/logs/rocketmqlogs/ 目录下创建 namesrv.log 文件，根据官方文档 tailf 这个文件可以看到如下类似的信息：\n1 2 3 4 5 6 7 8 9 10 2020-02-25 11:16:01 INFO main - tls.client.authServer = false 2020-02-25 11:16:01 INFO main - tls.client.trustCertPath = null 2020-02-25 11:16:01 INFO main - Using OpenSSL provider 2020-02-25 11:16:02 INFO main - SSLContext created for server 2020-02-25 11:16:02 INFO main - Try to start service thread:FileWatchService started:false lastThread:null 2020-02-25 11:16:02 INFO NettyEventExecutor - NettyEventExecutor service started 2020-02-25 11:16:02 INFO FileWatchService - FileWatchService service started 2020-02-25 11:16:02 INFO main - The Name Server boot success. serializeType=JSON 2020-02-25 11:17:02 INFO NSScheduledThread1 - -------------------------------------------------------- 2020-02-25 11:17:02 INFO NSScheduledThread1 - configTable SIZE: 0 2.2 Start Broker 根据官方文档启动 Broker 服务\n1 2 3 \u0026gt; nohup sh bin/mqbroker -n localhost:9876 \u0026amp; \u0026gt; tail -f ~/logs/rocketmqlogs/broker.log The broker[%s, 172.30.30.233:10911] boot success... 与启动 Name Server 相同，运行成功后在 nohup.out 中能看到如下信息\n1 The broker[tb.novalocal, 172.17.0.1:10911] boot success. serializeType=JSON and name server is localhost:9876 broker 的启动相对较慢，可耐心等待一段时间，启动成功后 tail -f ~/logs/rocketmqlogs/broker.log 可以看到如下类似的信息\n1 2 3 4 5 6 7 8 9 10 2020-02-25 11:28:22 INFO main - The broker[tb.novalocal, 172.17.0.1:10911] boot success. serializeType=JSON and name server is localhost:9876 2020-02-25 11:28:31 INFO BrokerControllerScheduledThread1 - dispatch behind commit log 0 bytes 2020-02-25 11:28:31 INFO BrokerControllerScheduledThread1 - Slave fall behind master: 0 bytes 2020-02-25 11:28:32 INFO brokerOutApi_thread_2 - register broker[0]to name server localhost:9876 OK 2020-02-25 11:29:02 INFO brokerOutApi_thread_3 - register broker[0]to name server localhost:9876 OK 2020-02-25 11:29:21 INFO TransactionalMessageCheckService - create new topic TopicConfig [topicName=RMQ_SYS_TRANS_HALF_TOPIC, readQueueNums=1, writeQueueNums=1, perm=RW-, topicFilterType=SINGLE_TAG, topicSysFlag=0, order=false] 2020-02-25 11:29:21 INFO brokerOutApi_thread_4 - register broker[0]to name server localhost:9876 OK 2020-02-25 11:29:31 INFO BrokerControllerScheduledThread1 - dispatch behind commit log 0 bytes 2020-02-25 11:29:31 INFO BrokerControllerScheduledThread1 - Slave fall behind master: 0 bytes 2020-02-25 11:29:32 INFO brokerOutApi_thread_1 - register broker[0]to name server localhost:9876 OK 3. Send \u0026amp; Receive Messages 根据官方文档说明，在收发信息之前，我们需要告诉 clients 配置的 name servers 地址\n我们可以用官网推荐的配置环境变量来完成 name servers 地址的配置\n1 \u0026gt; export NAMESRV_ADDR=localhost:9876 接着使用 tools.sh 进行消息的收发\n1 2 3 4 \u0026gt; sh bin/tools.sh org.apache.rocketmq.example.quickstart.Producer SendResult [sendStatus=SEND_OK, msgId= ... \u0026gt; sh bin/tools.sh org.apache.rocketmq.example.quickstart.Consumer ConsumeMessageThread_%d Receive New Messages: [MessageExt... sh bin/tools.sh org.apache.rocketmq.example.quickstart.Producer 运行后出现大量\n1 SendResult [sendStatus=SEND_OK, msgId= ... 类似的信息且没有报错说明成功\nsh bin/tools.sh org.apache.rocketmq.example.quickstart.Consumer 运行后出现大量\n1 2 3 11:42:05.200 [main] DEBUG i.n.u.i.l.InternalLoggerFactory - Using SLF4J as the default logging framework Consumer Started. ConsumeMessageThread_1 Receive New Messages: 类似的信息且没有报错说明成功\n不同的版本和系统等可能输出信息会有所不同，但一般来说能收到消息就可以了，不放心可以对比一下收发的 msgId\n","date":"2020-05-14T14:53:28+08:00","permalink":"https://gitsang.github.io/p/rocketmq-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/","title":"RocketMQ 快速入门"},{"content":" 1. MVC MVC 指 Model - View - Controller\n分层式为了实现“高内聚，低耦合”，易于控制，扩展和分配资源\nModel 层一般再分为 DAO 层和 Service 层\n1.1 View 层 表示层：jsp、html 等编写，为界面的展示\nView 层和 Controller 层耦合度较高，也可以看作一个整体进行开发\n@Component\n1.2 Controller 层 控制层：接收客户端的请求，然后调用 Service 层业务逻辑，获取到数据，再传递数据给表示层展示\n@Controller\n注解控制层，告诉 SpringMVC 的 dispatcherServlet 这是一个 Controller 然后被 dispatcherServlet 的上下文所管理，并完成他的依赖注入\n@RestController\n相当于 @Controller 和 @ResponseBody 的组合注解\n@RequestMapping\n在类上使用 @RequestMapping(\u0026quot;/user\u0026quot;) 告诉 SpringMVC 该 Controller 会拦截 /user/* 路径下所有 URL\n在方法上使用 @RequestMapping(value = \u0026quot;login.do\u0026quot;, method = RequestMethod.POST) 使该方法负责处理 /usr/login.do 这个 URL 的 POST 请求\n@RequestMapping 使用 method 参数，可以使用 @PostMapping 或 @GetMapping @PutMapping @DelMapping @PatchMapping 替代\n@RequestParam / @PathVariable / @Param\n在方法的参数前绑定以上 3 种注解，负责把请求传入的参数绑定到方法中的参数上\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @Controller @RequestMapping(\u0026#34;/user\u0026#34;) public class UserController { @Autowired private UserService userService; /* 本方法负责处理 /usr/login.do 这个 URL 传入的 POST 请求 */ @RequestMapping(value = \u0026#34;login.do\u0026#34;, method = RequestMethod.POST) /* 自动序列化成 json */ @ResponseBody public ServerResponse\u0026lt;User\u0026gt; login( /* 将请求传入参数绑定到 方法的参数上 */ @RequestParam(\u0026#34;username\u0026#34;) String username, @RequestParam(\u0026#34;password\u0026#34;) String password, HttpSession session) { ServerResponse\u0026lt;User\u0026gt; response = iUserService.login(username, password); if(response.isSuccess()) { session.setAttribute(Const.CURRENT_USER, response.getData()); } return response; } } 1.3 Service 层 业务层：调用 DAO 层，实现解耦，利于通用业务的独立性和复用性\n主要负责业务模块的逻辑应用设计\n先设计 Service 接口，再设计其实现的类，接着在 Spring 的配置文件中配置其实现的关联\n这样可以直接在应用中调用 Service 接口来进行业务处理\n@Service\n注解业务层，并将其申明为一个 Bean\n1 2 3 4 5 /** * UserService 类，Bean 名为 userService */ @Service(\u0026#34;userService\u0026#34;) public class UserService {} 1.4 DAO 层 持久层：或数据访问层，实现对数据库的访问\nDAO 层的设计首先是设计 DAO 的接口，然后再 Spring 的配置文件中定义此接口的实现类\n这样可以直接在模块中调用此接口进行数据业务的处理，而不用关心接口的具体实现是哪个类\nDAO 层的数据源配置，以及有关数据库连接的参数都在 Spring 的配置文件中配置\n@Repositoy 注解数据访问层，告诉 SpringMVC 这是一个数据访问层，并将其申明为一个 Bean 1 2 3 4 5 6 /** * UserDaoImpl 类实现 UserDao 接口，Bean 名称为 userDao */ @Repository(\u0026#34;userDao\u0026#34;) public class UserDaoImpl implements UserDao { } 参考 https://blog.csdn.net/zyq11223/article/details/78187389\nhttps://blog.csdn.net/zdwzzu2006/article/details/6053006\nhttps://blog.csdn.net/gg12365gg/article/details/51345601\nhttps://blog.csdn.net/qq_39299341/article/details/79809381\nhttps://blog.csdn.net/u010412719/article/details/69710480\n","date":"2020-05-14T14:53:28+08:00","permalink":"https://gitsang.github.io/p/sprint-mvc-and-annotation/","title":"SpringMVC 及其注解"},{"content":" 1 2 qd$a\u0026lt;space\u0026gt;\u0026lt;space\u0026gt;\u0026lt;esc\u0026gt;g_ldwjq gg10000@d 1. 说明 使用 vim 自带 record 功能 q\u0026lt;?\u0026gt; 启动录制，保存在 \u0026lt;?\u0026gt; 键 q 结束录制 @\u0026lt;?\u0026gt; 调用 \u0026lt;?\u0026gt; 键录制结果 num@\u0026lt;?\u0026gt; 调用 num 次 \u0026lt;?\u0026gt; 键录制结果 在末尾 dw 删除空格 $a\u0026lt;space\u0026gt; 添加空格防止末尾无空格情况删除掉最后一个字符 $a\u0026lt;space\u0026gt;\u0026lt;space\u0026gt; 添加两个空格防止空行情况下出现错误 g_ 移动到最后一个非空字符，有些人会使用 $be $ge 等方式移动到最后一个非空字符，但大部分方式是有问题的，详见 vim如何移动到光标所在行最后一个非空字符，而不是末尾？ 最后按 j 自动下一行 ","date":"2020-05-07T20:45:49+08:00","permalink":"https://gitsang.github.io/p/delete-space-over-line-using-vim-record/","title":"Delete Space Overline Using Vim Record"},{"content":" 1 2 3 4 5 6 7 8 9 10 11 12 // 使用匿名内部类 new Thread(new Runnable() { @Override public void run() { System.out.println(\u0026#34;Hello from thread (Override)\u0026#34;); } }).start(); // 使用 lambda 表达式 new Thread( () -\u0026gt; System.out.println(\u0026#34;Hello from thread (lambda)\u0026#34;) ).start(); 1 2 3 4 5 6 7 8 9 10 11 12 // 使用匿名内部类 button.addActionListener(new ActionListener() { @Override public void actionPerformed(ActionEvent e) { System.out.println(\u0026#34;The button was clicked (Override)\u0026#34;); } }); // 使用 lambda 表达式 button.addActionListener( (e) -\u0026gt; { System.out.println(\u0026#34;The button was clicked (lambda)\u0026#34;); }); ","date":"2020-04-29T14:53:28+08:00","permalink":"https://gitsang.github.io/p/lambda/","title":"Lambda 表达式"},{"content":" 1. Configuration Annotation Proessor not found in classpath . 使用 @ConfigurationProperties 报错 2. spring boot1.5 以上版本@ConfigurationProperties 取消 location 注解，只能使用 @PropertySource 3. 但使用 @PropertySource 依然出��报错\n官方解决方案，Maven 引入依赖\n1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt; org.springframework.boot \u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt; spring-boot-configuration-processor \u0026lt;/artifactId\u0026gt; \u0026lt;optional\u0026gt; true \u0026lt;/optional\u0026gt; \u0026lt;/dependency\u0026gt; 参考：https://blog.csdn.net/w05980598/article/details/79167826\n2. java.lang.IllegalStateException: Ambiguous mapping. Cannot map \u0026lsquo;xxx\u0026rsquo; method 1 2 3 4 5 6 7 at com.xxx.springbootconfiguration.SpringbootConfigurationApplication.main (SpringbootConfigurationApplication.java:10) [classes/:na] Caused by: java.lang.IllegalStateException: Ambiguous mapping. Cannot map \u0026#39;configurationController\u0026#39; method com.xxx.springbootconfiguration.controller.configurationController#getUser() to {GET }: There is already \u0026#39;configurationController\u0026#39; bean method com.xxx.springbootconfiguration.controller.configurationController#getInfo() mapped. 2.1 原因： controller 层 @GetMapping 重复使用了两个相同的路径\n1 2 3 4 5 6 7 8 9 @GetMapping public void getInfo() { ... } @GetMapping public void getUser() { ... } 两个 @GetMapping 都没有指定路径，才会有这样一条报错（已经被 getInfo map 了）\n1 2 to {GET }: There is already \u0026#39;configurationController\u0026#39; bean method com.xxx.springbootconfiguration.controller.configurationController#getInfo() mapped. 2.2 解决方法: 为 @GetMapping 添加值，保险一点两个都加，只加一个也可以\n1 2 3 4 5 6 7 8 9 @GetMapping(\u0026#34;/info\u0026#34;) public void getInfo() { ... } @GetMapping(\u0026#34;/user\u0026#34;) public void getUser() { ... } ","date":"2020-04-29T14:53:28+08:00","permalink":"https://gitsang.github.io/p/springboot-hole/","title":"Springboot 踩坑记录"},{"content":" 1. Example 1: 匿名接口实现类 接口类： 1 2 3 4 public interface InterfaceTest { String getName(); String getAge(); } new 创建匿名内部类 或相当于创建一个匿名的接口，继承 InterfaceTest 接口，然后创建一个该接口的实现类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 package test; public class NewIterfaceDemo { public static void main(String[] args) { InterfaceTest itest = new InterfaceTest() { @Override public String getName() { return \u0026#34;Lisa\u0026#34;; } @Override public String getAge() { return \u0026#34;18\u0026#34;; } }; System.out.println(itest.getName() + itest.getAge()); } } 相当于创建了一个 InterfaceTest 接口的实现类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public class NewInterfaceTest implements InterfaceTest { @Override public String getName() { return \u0026#34;Lisa\u0026#34;; } @Override public String getAge() { return \u0026#34;18\u0026#34;; } public static void main(String[] args) { NewInterfaceTest nit = new NewInterfaceTest(); System.out.println(nit.getName() + nit.getAge()); } } 2. Example 2: 抽象类的匿名继承类 1 2 3 4 public abstract class AbsTest { abstract String getName(); abstract String getAge(); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public class AbsDemo { public static void main(String[] args) { AbsTest absTest = new AbsTest() { @Override String getName() { return \u0026#34;Gilgamesh\u0026#34;; } @Override String getAge() { return \u0026#34;25\u0026#34;; } }; System.out.println(absTest.getName() + absTest.getAge()); } } 相当于\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public class ExtAbsClass extends AbsTest{ @Override String getName() { return \u0026#34;Gilgamesh\u0026#34;; } @Override String getAge() { return \u0026#34;25\u0026#34;; } public static void main(String[] args) { ExtAbsClass extAbsClass = new ExtAbsClass(); System.out.println(extAbsClass.getName() + extAbsClass.getAge()); } } 3. Example 3: 对象匿名重写 对于非抽象得类，也可以通过 {} 重写类方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 import java.util.HashMap; import java.util.Map; public class Test { public static void main(String[] args) { Map\u0026lt;String, String\u0026gt; map = new HashMap\u0026lt;String, String\u0026gt;() { @Override public String put(String key, String value) { key = \u0026#34;key_override\u0026#34;; value = \u0026#34;value_override\u0026#34;; return super.put(key, value); } }; map.put(\u0026#34;key\u0026#34;, \u0026#34;value\u0026#34;); System.out.println(map.get(\u0026#34;key\u0026#34;)); System.out.println(map.get(\u0026#34;key_override\u0026#34;)); } } 输出结果：\n1 2 3 4 null value_override Process finished with exit code 0 也相当于创建了一个新的类继承原本非抽象类，然后重写其中的方法，但新的类匿名，且这个方法被重写了的类仅对这一个对象有效。\n4. Example 4: 为构造函数添加执行语句 在匿名类中使用 {}\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import java.util.ArrayList; import java.util.List; public class Test { public static void main(String[] args) { List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;String\u0026gt;() { { add(\u0026#34;a\u0026#34;); add(\u0026#34;b\u0026#34;); } }; System.out.println(list.size()); } } 相当于实现匿名类的构造函数，当然这种写法并不规范（因为当定义一个集合后，向集合内添加元素却没有相应的取出操作，这个添加动作就没有什么意义了）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import java.util.ArrayList; import java.util.List; public class MyArrayList\u0026lt;E\u0026gt; extends ArrayList\u0026lt;E\u0026gt; { private MyArrayList() { add(\u0026#34;a\u0026#34;); add(\u0026#34;b\u0026#34;); } @SuppressWarnings(\u0026#34;unchecked\u0026#34;) public static void main(String[] args) { List\u0026lt;String\u0026gt; list = new MyArrayList(); System.out.println(list.size()); } } 5. 参考 https://blog.csdn.net/shenhaiyushitiaoyu/article/details/84142618?utm_source=distribute.pc_relevant.none-task\n","date":"2020-04-29T14:53:28+08:00","permalink":"https://gitsang.github.io/p/anonymous-inner-class/","title":"匿名内部类"},{"content":" 1. 使用 iptables 进行端口映射12 1.1 第一步 : 打开端口映射功能 : 1.1.1 方法一 : (允许数据包转发) 1 sudo echo \u0026#39;1\u0026#39; \u0026gt; /proc/sys/net/ipv4/ip_forward 1.1.2 方法二 : 1 vim /etc/sysctl.conf 将 ;net.ipv4.ip_forward = 0 这一行的注视去掉 , 并将 0 改为 1\n修改后的结果为 :\n1 net.ipv4.ip_forward = 1 1.2 第二步 : 进行映射 : DNAT\n1 iptables -t nat -A PREROUTING -d 本机IP -p tcp --dport 本机端口 -j DNAT --to-destination 目标机IP:目标机端口 SNAT\n1 iptables -t nat -A PREROUTING -d 本机IP -p tcp --dport 本机端口 -j SNAT --to-destination 目标机IP:目标机端口 2. 参考： Linux 端口映射\u0026#160;\u0026#x21a9;\u0026#xfe0e;\niptables端口转发\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2020-03-14T14:53:28+08:00","permalink":"https://gitsang.github.io/p/using-iptables/","title":"Using Iptables"},{"content":" 1 2 export http_proxy=http://127.0.0.1:1080 export https_proxy=http://127.0.0.1:1080 1 2 export http_proxy=\u0026#34;socks5://127.0.0.1:1080\u0026#34; export https_proxy=\u0026#34;socks5://127.0.0.1:1080\u0026#34; 1 export ALL_PROXY=socks5://127.0.0.1:1080 ","date":"2020-03-14T14:53:28+08:00","permalink":"https://gitsang.github.io/p/using-proxy/","title":"Using Proxy"},{"content":" 1. yum 针对软件包操作常用命令 查看安装了哪些软件包 1 yum list installed 查找软件包 1 yum search 列出所有可安装的软件包 1 yum list 列出所有可更新的软件包 1 yum list updates 列出所有已安装的软件包 1 yum list installed 列出所有已安装但不在 Yum Repository 内的软件包 1 yum list extras 列出所指定的软件包 1 yum list 获取软件包信息 1 yum info 列出所有可更新的软件包信息 1 yum info updates 列出所有已安装的软件包信息 1 yum info installed 列出所有已安装但不在 Yum Repository 内的软件包信息 1 yum info extras 列出软件包提供哪些文件 1 yum provides 卸载软件包 1 yum remove ","date":"2020-01-14T14:53:28+08:00","permalink":"https://gitsang.github.io/p/yum-command-quick-search/","title":"Yum Command Quick Search"},{"content":" 1. Install 1.1 Get package Using git clone.\n1 git clone https://github.com/google/googletest.git Using wget to achieve tar package, you can find newest tar address at README.md.1 2\n1 2 wget https://github.com/google/googletest/archive/release-1.10.0.tar.gz tar -zxvf release-1.10.0.tar.gz 1.2 Make \u0026amp; Install Both cmake or cmake3 is ok.\nRead googletest/googletest/README.md for more infomation.\n1 2 3 4 5 6 $ cd googletest $ mkdir build $ cd build $ cmake .. $ make $ sudo make install 1.3 Attention when cmake processing 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 -- The C compiler identification is GNU 4.8.5 -- The CXX compiler identification is GNU 4.8.5 -- Check for working C compiler: /usr/bin/cc -- Check for working C compiler: /usr/bin/cc -- works -- Detecting C compiler ABI info -- Detecting C compiler ABI info - done -- Detecting C compile features -- Detecting C compile features - done -- Check for working CXX compiler: /usr/bin/c++ -- Check for working CXX compiler: /usr/bin/c++ -- works -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Detecting CXX compile features -- Detecting CXX compile features - done -- Found PythonInterp: /usr/bin/python (found version \u0026#34;2.7.5\u0026#34;) -- Looking for pthread.h -- Looking for pthread.h - found -- Looking for pthread_create -- Looking for pthread_create - not found -- Looking for pthread_create in pthreads -- Looking for pthread_create in pthreads - not found -- Looking for pthread_create in pthread -- Looking for pthread_create in pthread - found -- Found Threads: TRUE -- Configuring done -- Generating done -- Build files have been written to: /root/project/googletest-release-1.10.0/build In the above log, pthread_create is finally found in pthread, so it is not found on the way, but it should be fine.\n2. Simple Test 2.1 Testing code add.cc 1 2 3 4 5 #include \u0026lt;iostream\u0026gt; int add(int a, int b) { return a + b; } testAdd.cpp 1 2 3 4 5 6 7 8 9 10 11 12 #include \u0026lt;gtest/gtest.h\u0026gt; extern int add(int a, int b); TEST(testCase, test0) { EXPECT_EQ(add(2, 3), 5); } int main(int argc, char **argv) { testing::InitGoogleTest(\u0026amp;argc, argv); return RUN_ALL_TESTS(); } 2.2 Compile and Run 1 2 3 4 5 6 7 8 9 10 11 12 $ g++ add.cpp testAdd.cpp -lgtest -lpthread $ ./a.out [==========] Running 1 test from 1 test case. [----------] Global test environment set-up. [----------] 1 test from testCase [ RUN ] testCase.test0 [ OK ] testCase.test0 (0 ms) [----------] 1 test from testCase (0 ms total) [----------] Global test environment tear-down [==========] 1 test from 1 test case ran. (0 ms total) [ PASSED ] 1 test. -lgtest is used for linking libgtest.a\nIf using -lgtest_main, you can coding without main() function3\n3. Q \u0026amp; A 3.1 Q1: Undefined reference when linking with googletest 3.1.1 A: If you downloaded the gtest source directly and used the make install from the downloaded gtest repository it may have installed header files under /usr/local/include/gtest.\nIf you later use apt-get (yum install) to install the gtest, it installs the header files under /usr/include/gtest.\nIf the version installed from the debian package is newer, your Makefile can pick up the older header files from /usr/include and give you link errors even though you are correctly linking the new libgtest.a archive.\nThe solution is to look for /usr/local/include/gtest and /usr/include/gtest to see if they both exist. If they do then delete the older directory.\nIf /usr/include/gtest is the older directory, you may want to remove it by uninstalling the libgtest-dev package.4\n3.2 Q2: Could not find CMAKE_ROOT 1 2 3 4 5 6 7 CMake Error: Could not find CMAKE_ROOT !!! CMake has most likely not been installed correctly. Modules directory not found in /usr/local/share/cmake-3.11 cmake version 3.11.0-rc4 CMake suite maintained and supported by Kitware (kitware.com/cmake). 3.2.1 A: 1 2 3 4 5 6 $ wget https://cmake.org/files/v3.12/cmake-3.12.0-rc1.tar.gz $ tar -zxvf cmake-3.12.0-rc1.tar.gz $ cd cmake-3.12.0-rc1 $ ./bootstrap $ gmake $ gmake install 3.3 Q3: Compile error 3.3.1 A: add -std=c++11 when compile\n1 $ g++ *.cpp -lgtest -lpthread -std=c++11 4. Reference Google Testの使い方 - Qiita\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n使用 Google Test 测试框架 - Senlin\u0026rsquo;s Blog\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n第一个gtest程序 - 码农教程\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nUndefined reference when linking with googletest - Stack Overflow\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2019-12-15T14:53:28+08:00","permalink":"https://gitsang.github.io/p/googletest-quick-start/","title":"Googletest Quick Start"},{"content":" 1. 安装 curl 和 libcurl 1.1 使用包管理工具安装 linux 机器一般自带 curl 工具，如果没有可以通过 apt/yum/pkg install curl 的方式安装\n同样的，可以通过 apt/yum/pkg install libcurl 的方式安装 curl 库\n这种方式安装的好处是简单且稳定，缺点则是其版本可能较低\n1.2 源码编译方式 官网: http://curl.haxx.se/\n如需最新版可到官网获取下载地址1 2\n下载源码 1 2 3 wget http://curl.haxx.se/download/curl-7.65.1.tar.gz tar -zxf curl-7.65.1.tar.gz cd curl-7.65.1 初始化配置 一般无需设置直接使用默认配置即可，建议不要修改安装路径，否则后续还需自行添加 include 路径，若需指定安装路径，使用 --prefix 参数\n1 ./configure --prefix=/usr/local/curl 其余的配置的使用可通过 ./configure --help 查看\n建议安装之前先查看当前目录下的 README、GIT-INFO、INSTALL 文件，许多问题都能在此找到答案\n编译安装 1 2 make make install 检查版本 1 curl --version 版本信息与安装版本相符则到此步骤已经安装成功\n将 curl 命令加入环境变量（如果按照默认路径安装则无需执行此步骤） 仅对本会话起作用，若需永久生效需要在 .bash_profile、.bashrc 等文件里添加\n1 export PATH=$PATH:/usr/local/curl/bin 可能还需要将 include 目录复制到 /usr/include 下（如果按照默认路径安装则无需执行此步骤） 1 cp -r /usr/local/curl/include/curl /usr/include 当然也可以用软链接，或编译时指定 include 路径\n1 ln -s /usr/local/curl/include/curl /usr/include/curl 2. C / C++ 调用 libcurl 到 /usr/local/lib/ 或指定的安装路径，即可查看到安装好的库文件\n若要include库文件可如下编写\n1 #include \u0026lt;curl/curl.h\u0026gt; 可根据参考2中代码测试 libcurl\n在编译时要加入 -lcurl 参数，如 g++ main.cpp -o main -lcurl\n3. curl 命令 以下命令为 curl 与 localhost 通讯进行上传和下载文件3\n1 2 # curl -v -X PUT http://localhost/doc/1.txt -T 2.txt # curl -v -X GET http://localhost/doc/1.txt -o 2.txt 选项 -v 或 --verbose 为显示详细操作信息，建议刚开始使用时加上，能为调试提供很大帮助。\n其余选项的使用可以使用 curl --help 或 man curl 查看帮助信息，每个选项都有详细的说明。（中文翻译）\ncurl命令能为之后curl库的使用提供参考基础，建议在进行curl代码编写前先使用curl命令实现，有些时候的bug不是代码造成的，有可能本身curl就无法建立连接。\n4. curl 库的调用流程 libcurl主要提供了两种发送http请求的方式，分别是Easy interface方式和multi interface方式，前者是采用阻塞的方式发送单条数据，后者采用组合的方式可以一次性发送多条数据\nlibcurl传输任务流程如下（其中最重要的是3和4步）：4\n1 调用curl_global_init()初始化libcurl 2 调用curl_easy_init()得到easy interface型指针（句柄） 3 调用curl_easy_setopt()设置传输选项 4 根据curl_easy_setopt()实现回调函数 5 调用curl_easy_perform()传输数据 6 调用curl_easy_cleanup()清空句柄 7 调用curl_global_cleanup()释放内存 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 #include \u0026lt;curl/curl.h\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;iostream\u0026gt; using namespace std; int httpPutFile() { CURL* curl = NULL; CURLcode result = CURLE_OK; string url = \u0026#34;http://10.200.100.50:8080\u0026#34;; FILE* inputFile = fopen(\u0026#34;./put.txt\u0026#34;, \u0026#34;rb\u0026#34;); string outputFilename = \u0026#34;/1.txt\u0026#34;; url += outputFilename; //HttpHead struct curl_slist* headers = NULL; headers = curl_slist_append(headers, \u0026#34;endPoint:http://10.200.100.50:8080\u0026#34;); headers = curl_slist_append(headers, \u0026#34;accessKeyId:id123\u0026#34;); headers = curl_slist_append(headers, \u0026#34;secretAccessKey:key123\u0026#34;); headers = curl_slist_append(headers, \u0026#34;Authorization:auth123\u0026#34;); //Init curl_global_init(CURL_GLOBAL_ALL); curl = curl_easy_init(); //Option curl_easy_setopt(curl, CURLOPT_URL, url.c_str()); curl_easy_setopt(curl, CURLOPT_VERBOSE, 1); curl_easy_setopt(curl, CURLOPT_TIMEOUT, 2); curl_easy_setopt(curl, CURLOPT_HTTPHEADER, headers); curl_easy_setopt(curl, CURLOPT_INFILE, inputFile); //curl_easy_setopt(curl, CURLOPT_INFILESIZE, 87); curl_easy_setopt(curl, CURLOPT_PUT, 1); //curl_easy_setopt(curl, CURLOPT_CUSTOMREQUEST, \u0026#34;PUT\u0026#34;); //Perform result = curl_easy_perform(curl); //Clean curl_slist_free_all(headers); curl_easy_cleanup(curl); curl_global_cleanup(); return 0; } int httpGetFile() { CURL* curl = NULL; CURLcode result = CURLE_OK; string url = \u0026#34;http://10.200.100.50:8080\u0026#34;; FILE* outputFile = fopen(\u0026#34;./get.txt\u0026#34;, \u0026#34;wb\u0026#34;); string inputFilename = \u0026#34;/1.txt\u0026#34;; url += inputFilename; //HttpHead struct curl_slist* headers = NULL; headers = curl_slist_append(headers, \u0026#34;endPoint:http://10.200.100.50:8080\u0026#34;); headers = curl_slist_append(headers, \u0026#34;accessKeyId:id123\u0026#34;); headers = curl_slist_append(headers, \u0026#34;secretAccessKey:key123\u0026#34;); headers = curl_slist_append(headers, \u0026#34;Authorization:auth123\u0026#34;); //Init curl_global_init(CURL_GLOBAL_ALL); curl = curl_easy_init(); //Option curl_easy_setopt(curl, CURLOPT_URL, url.c_str()); curl_easy_setopt(curl, CURLOPT_VERBOSE, 1); curl_easy_setopt(curl, CURLOPT_TIMEOUT, 2); curl_easy_setopt(curl, CURLOPT_HTTPHEADER, headers); curl_easy_setopt(curl, CURLOPT_WRITEDATA, (void*)outputFile); //Perform result = curl_easy_perform(curl); //Clean curl_slist_free_all(headers); curl_easy_cleanup(curl); curl_global_cleanup(); return 0; } int main(int argc, char* argv[]) { string method = argv[1]; if(method == \u0026#34;PUT\u0026#34; || method == \u0026#34;put\u0026#34;) { httpPutFile(); }else if(method == \u0026#34;GET\u0026#34; || method == \u0026#34;get\u0026#34;) { httpGetFile(); }else { cout \u0026lt;\u0026lt; \u0026#34;Method error, please input \\\u0026#34;PUT\\\u0026#34; or \\\u0026#34;GET\\\u0026#34;.\u0026#34; \u0026lt;\u0026lt; endl; } cout \u0026lt;\u0026lt; endl; return 0; } 5. 参考 Linux CURL的安装和使用\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nlinux下编译安装libcurl(附使用示例)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nC++ 用libcurl库进行http通讯网络编程\u0026#160;\u0026#x21a9;\u0026#xfe0e;\ncurl_easy_setopt-curl库的关键函数之一\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2019-10-15T14:53:28+08:00","permalink":"https://gitsang.github.io/p/curl-quick-start/","title":"Curl 和 libcurl 快速入门"},{"content":" GDB是一个由GNU开源组织发布的、UNIX/LINUX操作系统下的、基于命令行的、功能强大的程序调试工具。 对于一名Linux下工作的c++程序员，gdb是必不可少的工具；\n1. 启动gdb 对C/C++程序的调试，需要在编译前就加上-g选项: 1 g++ -g hello.cpp -o hello 调试可执行文件: 1 gdb \u0026lt;program\u0026gt; program也就是你的执行文件，一般在当前目录下。\n调试core文件(core是程序非法执行后core dump后产生的文件): 1 2 gdb \u0026lt;program\u0026gt; \u0026lt;core dump file\u0026gt; gdb program core.11127 调试服务程序: 1 2 gdb \u0026lt;program\u0026gt; \u0026lt;PID\u0026gt; gdb hello 11127 如果你的程序是一个服务程序，那么你可以指定这个服务程序运行时的进程ID。gdb会自动attach上去，并调试他。program应该在PATH环境变量中搜索得到。\n2. gdb交互命令 启动gdb后，进入到交互模式，通过以下命令完成对程序的调试；注意高频使用的命令一般都会有缩写，熟练使用这些缩写命令能提高调试的效率；\n2.1 运行 run：简记为 r ，其作用是运行程序，当遇到断点后，程序会在断点处停止运行，等待用户输入下一步的命令。 continue （简写c ）：继续执行，到下一个断点处（或运行结束） next：（简写 n），单步跟踪程序，当遇到函数调用时，也不进入此函数体；此命令同 step 的主要区别是，step 遇到用户自定义的函数，将步进到函数中去运行，而 next 则直接调用函数，不会进入到函数体内。 step （简写s）：单步调试如果有函数调用，则进入函数；与命令n不同，n是不进入调用的函数的 until：当你厌倦了在一个循环体内单步跟踪时，这个命令可以运行程序直到退出循环体。 until+行号： 运行至某行，不仅仅用来跳出循环 finish： 运行程序，直到当前函数完成返回，并打印函数返回时的堆栈地址和返回值及参数值等信息。 call 函数(参数)：调用程序中可见的函数，并传递“参数”，如：call gdb_test(55) quit：简记为 q ，退出gdb 2.2 设置断点 break n （简写b n）:在第n行处设置断点 （可以带上代码路径和代码名称： b OAGUPDATE.cpp:578） b fn1 if a＞b：条件断点设置 break func（break缩写为b）：在函数func()的入口处设置断点，如：break cb_button delete 断点号n：删除第n个断点 disable 断点号n：暂停第n个断点 enable 断点号n：开启第n个断点 clear 行号n：清除第n行的断点 info b （info breakpoints） ：显示当前程序的断点设置情况 delete breakpoints：清除所有断点： 2.3 查看源代码 list ：简记为 l ，其作用就是列出程序的源代码，默认每次显示10行。 list 行号：将显示当前文件以“行号”为中心的前后10行代码，如：list 12 list 函数名：将显示“函数名”所在函数的源代码，如：list main list ：不带参数，将接着上一次 list 命令的，输出下边的内容。 2.4 打印表达式 print 表达式：简记为 p ，其中“表达式”可以是任何当前正在被测试程序的有效表达式，比如当前正在调试C语言的程序，那么“表达式”可以是任何C语言的有效表达式，包括数字，变量甚至是函数调用。 print a：将显示整数 a 的值 print ++a：将把 a 中的值加1,并显示出来 print name：将显示字符串 name 的值 print gdb_test(22)：将以整数22作为参数调用 gdb_test() 函数 print gdb_test(a)：将以变量 a 作为参数调用 gdb_test() 函数 display 表达式：在单步运行时将非常有用，使用display命令设置一个表达式后，它将在每次单步进行指令后，紧接着输出被设置的表达式及值。如： display a watch 表达式：设置一个监视点，一旦被监视的“表达式”的值改变，gdb将强行终止正在被调试的程序。如： watch a whatis ：查询变量或函数 info function： 查询函数 扩展info locals： 显示当前堆栈页的所有变量 2.5 查询运行信息 where/bt ：当前运行的堆栈列表； bt backtrace 显示当前调用堆栈 up/down 改变堆栈显示的深度 set args 参数:指定运行时的参数 show args：查看设置好的参数 info program： 来查看程序的是否在运行，进程号，被暂停的原因。 2.6 分割窗口 layout：用于分割窗口，可以一边查看代码，一边测试： layout src：显示源代码窗口 layout asm：显示反汇编窗口 layout regs：显示源代码/反汇编和CPU寄存器窗口 layout split：显示源代码和反汇编窗口 Ctrl + L：刷新窗口 2.7 注解 交互模式下直接回车的作用是重复上一指令，对于单步调试非常方便； 3. 更强大的工具cgdb cgdb可以看作gdb的界面增强版,用来替代gdb的 gdb -tui。cgdb主要功能是在调试时进行代码的同步显示，这无疑增加了调试的方便性，提高了调试效率。界面类似vi，符合unix/linux下开发人员习惯;如果熟悉gdb和vi，几乎可以立即使用cgdb。\n4. 参考 ","date":"2019-10-09T14:53:28+08:00","permalink":"https://gitsang.github.io/p/gdb-quick-start/","title":"GDB 快速入门"},{"content":" 1. 回调函数简介 回调函数就是那些自己写的，但是不是自己来调，而是给别人来调用的函数。\n消息响应函数就可以看成是回调函数，因为是让系统在合适的时候去调用。这不过消息响应函数就是为了处理消息的，所以就拿出来单做一类了。其实本质上就是回调函数。\n比如按键事件，其实是个消息，你的函数比按键事件更早存在，所以你要将这个函数做为回调函数提交给系统， 然后系统在接收到按键事件后，再调用你的函数\n但是回调函数不是只有消息响应函数一种，比如在内核编程中，驱动程序就要提供一些回调函数，当一个设备的数据读写完成后，让系统调用这些回调函数来执行一些后续工作。回调函数赋予程序员这样一种能力，让自己编写的代码能够跳出正常的程序控制流，适应具体的运行环境在正确的时间执行。\n2. 回调和调用的关系 2.1 调用 调用就是用户传出参数让函数进行处理，或让函数执行某个动作 如以下操作就是调用，用户需要传入函数要求的参数，函数会返回一个传入参数中的最大值\n1 2 3 4 5 6 7 8 9 int mymax(int a, int b) { // 定义函数 return a \u0026gt; b ? a : b; } int main() { int a = 10; int b = 20; mymax(a, b); // 调用函数 } 2.2 回调 2.2.1 注册回调函数 回调就是用户编写函数对系统传入的参数进行处理，或在系统发出信号时执行某个操作，如：1 2\n1 2 3 4 5 6 7 8 9 int mymax(int a, int b) { // 定义回调函数 return a \u0026gt; b ? a : b; } int main() { system_operation sysop; sysop.max = mymax; // 注册回调函数 return 0; } 此时mymax并未由用户传入参数，而是等待系统传入。\n上述代码中system_operation为虚构的结构体，结构体内声明了一个空的max函数，如果系统直接调用max函数不会执行任何内容。\n需要用户将自己编写的函数注册到max函数上sysop.max = mymax;，注册成功后系统在调用到max函数时，就相当于调用了用户的mymax函数。注册回调意思就是把用户函数关联到系统函数\n2.2.2 回调函数作为参数 还有另一种形式的回调，是回调函数作为参数，如：\n1 2 3 4 5 6 7 8 9 10 11 12 #include \u0026#34;otherfunc.h\u0026#34; static size_t mymax_callback(int a, int b, int \u0026amp;max) { max = a \u0026lt; b ? a : b; // 我就是要返回最小值给你 return 0; } int main() { //函数原型 int othfunc_max(void* callbackfunction); othfunc_max(mymax_callback); return 0; } 此时a, b, \u0026amp;max都是系统传入的参数，至于传的是什么此时并不需要关心，只需要关心怎么处理a, b, \u0026amp;max这三个参数就行，一般来说回调函数需要哪些参数，参数的作用等都会在系统的说明文档或头文件注释中给出，写回调时候根据文档写出符合需求的回调函数就行了。（当然只要你开心，只要把格式写对，功能不符合需求也行，手动狗头）\n用户在调用othfunc_max时，只需传入对应的回调函数名称，系统会将a, b, \u0026amp;max传给mymax_callback函数，函数只给\u0026amp;max赋上a和b的最大值（其实是最小值），并未将max值返回（即使返回也不是返回给用户，用户能收到的仅仅是othfunc_max()的返回值）。3 4\n3. 参考 C++中回调函数(CallBack)的使用\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nC++ 回调函数理解 - clirus\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n【C++基础之八】函数指针和回调函数 - 偶尔e网事\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n回调函数中的参数列表是规定好的么 - TianYongwei\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2019-10-09T14:53:28+08:00","permalink":"https://gitsang.github.io/p/call-and-callback/","title":"调用和回调函数"},{"content":" 1. 使用typedef定义结构体 typedef用来定义新的数据类型，通常typedef与结构体的定义配合使用。使用typedef的目的使结构体的表达更加简练（所以说typedef语句并不是必须使用的）。 1 2 3 4\n1.1 定义一个名字为TreeNode的结构体类型（现在并没有定义结构体变量，并不占用内存空间）： 1 2 3 4 5 6 struct TreeNode { int Element; struct TreeNode* LeftChild; struct TreeNode* RightChild; }; 1.2 为结构体起一个别名Node，这时Node就等价于struct TreeNode 1 typedef struct TreeNode Node; 结构体的定义和typedef语句可以连在一起写：\n1 2 3 4 5 6 typedef struct TreeNode { int Element; struct TreeNode* LeftChild; struct TreeNode* RightChild; }Node; 注意不要与“定义结构体类型的同时定义结构体类型变量”混淆：\n1.3 使用typedef关键字定义结构体类型，定义结构体类型的同时定义结构体类型变量 1 2 3 4 5 6 7 8 9 10 11 12 13 typedef struct student { int age; int height; }std; //std相当于struct student struct student { int age; int height; }std1,std2; //定义了student数据类型的结构体和std1、std2结构体变量 2. 使用typedef定义结构体指针 2.1 定义一个名为TreeNode的结构体，和指向该结构体类型的指针PtrToTreeNode（不使用typedef）： 1 2 3 4 5 6 7 8 struct TreeNode { int Element; struct TreeNode* LeftChild; struct TreeNode* RightChild; }; struct TreeNode *PtrToTreeNode； //定义指针 2.2 使用typedef关键字用一个单词Node代替struct TreeNode，并定义指向该结构体类型的指针PtrToTreeNode： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 struct TreeNode { int Element; struct TreeNode* LeftChild; struct TreeNode* RightChild; }; typedef struct TreeNode Node; //用Node代替struct TreeNode Node *PtrToTreeNode; //定义指针 /* 或可不定义别名直接定义结构体指针： * typedef struct TreeNode* PtrToTreeNode * 若使用智能指针： * typedef std::shared_ptr\u0026lt;TreeNode\u0026gt; PtrToTreeNode */ 2.3 将结构体的定义和typedef连在一起写，再次缩短代码： 1 2 3 4 5 6 7 typedef struct TreeNode { int Element; struct TreeNode* LeftChild; struct TreeNode* RightChild; }Node; //定义结构体并用Node代替struct TreeNode Node *PtrToTreeNode; //定义指针 2.4 还可以继续缩短代码，直接定义了指向结构体类型的指针，但是这种写法没有为结构体起一个别名。 1 2 3 4 5 6 typedef struct TreeNode { int Element; struct TreeNode* LeftChild; struct TreeNode* RightChild; } *PtrToTreeNode; //直接定义指针 在定义结构体时，省略struct后面的结构体名也是可以的，但是由于没有名字，操作（如定义结构体变量）只能在定义的同时进行\n3. 参考 typedef关键字与结构体、结构体指针的定义 - 一路洒满阳光XD\u0026#160;\u0026#x21a9;\u0026#xfe0e;\ntypedef struct和指针 - CN_L4EX\u0026#160;\u0026#x21a9;\u0026#xfe0e;\ntypedef函数指针用法 - qll125596718\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n关于typedef的用法总结 - csyisong\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2019-10-09T14:53:28+08:00","permalink":"https://gitsang.github.io/p/struct-define/","title":"结构体的定义方式"},{"content":" 1. 指针和引用 1.1 指针和引用概述 1.1.1 指针 对于char* ptr，ptr为指向char的指针，即char*类型的变量ptr保存的是一个char对象的地址，而char可加限定c词const、volatile等。（char可换为其他类型）\n如下所示，p中存储的是c的地址，c中存储的是‘A\u0026rsquo;字符\n1 2 char c = \u0026#39;A\u0026#39;; char* p = \u0026amp;c; 通过*可取p所指向的内容，通过\u0026amp;可取p的地址，即：\n*p == c的内容 == 'A' p == c的地址 == \u0026amp;c \u0026amp;p == p的地址 1.1.2 引用 引用相当于一个对象的别名，主要用于函数参数和返回值类型。int\u0026amp;表示对int类型的引用（int可换为其他类型）\n1 2 3 4 5 6 int i = 1; int\u0026amp; r = i;\t// r指向了i的空间，此时对i和r的操作将是相同的 i = 2; cout \u0026lt;\u0026lt; r \u0026lt;\u0026lt; endl;\t// 输出 2 r = 3; cout \u0026lt;\u0026lt; i \u0026lt;\u0026lt; endl;\t// 输出 3 可以认为引用就是将 i 和 r 相关联（绑定）了，使得 i 和 r 代表了相同的一块空间\n1.1.3 引用与指针的区别 引用一旦指向某一对象就不可更改： 如上面程序，引用后的 r 就和普通的整形变量没有什么区别（若不考虑 i 的存在，完全可以把int i = 1; int\u0026amp; r = i;当成int r = 1;来看待）。引用即是将两个变量进行了绑定，而指针仅仅是存储了指向内存的地址，所以通过引用名（如r）可以直接访问指向的内存，而通过指针名（如p）却只能访问到地址，要通过（如*p）才能访问到地址所指的内存1\n对引用的操作将与所指对象同步，而不是像操作指针一样会改变指针的指向：\n如引用的++操作将直接使得指向内容+1，而指针的++会让指针指向下一个地址。如int i = 1; int\u0026amp; r = i; int* p = \u0026amp;r;此时 r 和 p 都指向了 i 所在的空间，但其意义是完全不同的，p是开辟了一个内存来存储 i 的地址，而 r 就是 i\n引用不可以为空，但指针可以为空： 正因如此指针在使用前都需要进行判空操作，而引用变量若不进行初始化甚至无法通过编译\n虽说引用和指针有许多区别，但两者在本质上是相同的，可以根据汇编代码看出：\n1 2 3 4 5 6 //引用int\u0026amp; ref = i; 8048727: 8d 44 24 1c\tlea 0x1c(%esp), %eax\t// esp寄存器里的变量i的地址传给eax 804872b: 89 44 24 18\tmov %eax, 0x18(%esp)\t// 将寄存器eax中的内容（i的地址）传给寄存器中的变量ref //指针int* p = \u0026amp;i; 8048777: 8d 44 24 1c lea 0x1c(%esp), %eax\t// esp寄存器里的变量i的地址传给eax 804877b: 89 44 24 10 mov %eax, 0x10(%esp) // 将寄存器eax中的内容（i的地址）传给寄存器中的变量p 引用和指针在汇编上的实现是完全相同的，即是说引用的本质其实就是指针，只是比指针更加安全。\n1.1.4 const关键字 引用和const指针是不是几乎是相同的呢？引用的本质其实就是指针，只是在指针上增加了一些规则，使得它更加安全。实际上，若不考虑赋空值，那么：\n引用 type\u0026amp; x 等于 const指针 const type* x const引用 const type\u0026amp; x 等于 指向const的const指针 const type* const x 1.2 值传递、指针传递、引用传递 1.2.1 值传递 值传递是形参对实参的拷贝，即将实参赋值到了形参上，改变形参的值并不会影响外部实参的值。从被调用函数的角度来说，值传递是单向的，参数的值只能传入，不能传出。当函数内部需要修改参数，并且不希望这个改变影响调用者时，采用值传递。2\n1.2.2 指针传递 形参为指向实参地址的指针，当对形参的指向操作时，就相当于对实参本身进行的操作，但对于形参的操作并不会改变实参的值（改变形参存储的地址不会改变实参的指向），因为指针传递的本质也是值的传递（将指针变量存储的地址复制给形参的变量）\n1.2.3 引用传递 形参相当于是实参的“别名”，对形参的操作其实就是对实参的操作，在引用传递过程中，被调函数的形式参数虽然也作为局部变量在栈中开辟了内存空间，但是这时存放的是由主调函数放进来的实参变量的地址。被调函数对形参的任何操作都被处理成间接寻址，即通过栈中存放的地址访问主调函数中的实参变量。正因为如此，被调函数对形参做的任何操作都影响了主调函数中的实参变量。\n2. 参考 C++中引用和指针的区别\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nC++ 值传递、指针传递、引用传递详解 - Geek_Ling\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2019-10-09T14:53:28+08:00","permalink":"https://gitsang.github.io/p/pointer-value-quote/","title":"指针、值和引用"},{"content":"一、icon 属性名 类型 默认值 说明 type String icon类型，有效值：success, success_no_circle, info, warn, waiting, cancel, download, search, clear size Number 23 icon的大小，单位px color Color icon的颜色，同css的color 二、text space 有效值：\n值 说明 ensp 中文字符空格一半大小 emsp 中文字符空格大小 nbsp 根据字体设置的空格大小 Tips decode可以解析的有 \u0026amp;nbsp; \u0026amp;lt; \u0026amp;gt; \u0026amp;amp; \u0026amp;apos; \u0026amp;ensp; \u0026amp;emsp; 各个操作系统的空格标准并不一致。 \u0026lt;text/\u0026gt; 组件内只支持 嵌套。 除了文本节点以外的其他节点都无法长按选中。 三、progress 可以通过以下实例了解进度条属性\n1 2 3 4 \u0026lt;progress percent=\u0026#34;20\u0026#34; show-info /\u0026gt; \u0026lt;progress percent=\u0026#34;40\u0026#34; stroke-width=\u0026#34;12\u0026#34; /\u0026gt; \u0026lt;progress percent=\u0026#34;60\u0026#34; color=\u0026#34;pink\u0026#34; /\u0026gt; \u0026lt;progress percent=\u0026#34;80\u0026#34; active /\u0026gt; ","date":"2018-02-11T20:17:57+08:00","permalink":"https://gitsang.github.io/p/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F-4-%E7%BB%84%E4%BB%B6-%E5%9F%BA%E7%A1%80%E5%86%85%E5%AE%B9icontextprogress/","title":"[微信小程序 - 4] 组件-基础内容（icon、text、progress）"},{"content":"一、scroll-view 1、基本设置 首先是参考的开发文档网址 https://mp.weixin.qq.com/debug/wxadoc/dev/framework/view/wxml/\n新建一个wxml文件，添加scroll-view组件，组件中添加“绿、红、黄、蓝”四种颜色的view组件（view组件较为简单，与html中div类似，此处省略，可参考官方开发文档中对view组件的说明）\n需要注意的是在这里只是添加了每个view组件的id和class，还需要再wxss文件中添加其样式\n这里设置scroll-view组件为竖向滚动，使用竖向滚动时，需要给\u0026lt;scroll-view/\u0026gt;一个固定高度，通过 WXSS 设置 height为250px\n1 2 3 4 5 6 \u0026lt;scroll-view style=\u0026#34;height:250px\u0026#34; scroll-y=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;view id=\u0026#34;green\u0026#34; class=\u0026#34;scroll-view-item bc_green\u0026#34;\u0026gt;\u0026lt;/view\u0026gt; \u0026lt;view id=\u0026#34;red\u0026#34; class=\u0026#34;scroll-view-item bc_red\u0026#34;\u0026gt;\u0026lt;/view\u0026gt; \u0026lt;view id=\u0026#34;yellow\u0026#34; class=\u0026#34;scroll-view-item bc_yellow\u0026#34;\u0026gt;\u0026lt;/view\u0026gt; \u0026lt;view id=\u0026#34;blue\u0026#34; class=\u0026#34;scroll-view-item bc_blue\u0026#34;\u0026gt;\u0026lt;/view\u0026gt; \u0026lt;/scroll-view\u0026gt; 以下是wxss中对样式的设置，.scroll-view-item 对4个view组件同时设置高度为200px，.bc_green 等分别设置每个组件不同的背景颜色。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 .scroll-view-item { height: 200px; } .bc_green { background-color: green; } .bc_red { background-color: red; } .bc_yellow { background-color: yellow; } .bc_blue { background-color: blue; } 2、滚动响应事件 以下分别说明bindscrolltoupper（滚动到顶部/左边触发）、bindscrolltolower（滚动到底部/右边触发）、 bindscroll（滚动时触发）三个事件响应\n将wxml文件改写为如下\n1 2 3 4 5 6 7 \u0026lt;scroll-view style=\u0026#34;height:250px\u0026#34; scroll-y=\u0026#34;true\u0026#34; bindscrolltoupper=\u0026#34;upper\u0026#34; bindscrolltolower=\u0026#34;lower\u0026#34; bindscroll=\u0026#34;scroll\u0026#34; \u0026gt; \u0026lt;view id=\u0026#34;green\u0026#34; class=\u0026#34;scroll-view-item bc_green\u0026#34;\u0026gt;\u0026lt;/view\u0026gt; \u0026lt;view id=\u0026#34;red\u0026#34; class=\u0026#34;scroll-view-item bc_red\u0026#34;\u0026gt;\u0026lt;/view\u0026gt; \u0026lt;view id=\u0026#34;yellow\u0026#34; class=\u0026#34;scroll-view-item bc_yellow\u0026#34;\u0026gt;\u0026lt;/view\u0026gt; \u0026lt;view id=\u0026#34;blue\u0026#34; class=\u0026#34;scroll-view-item bc_blue\u0026#34;\u0026gt;\u0026lt;/view\u0026gt; \u0026lt;/scroll-view\u0026gt; 为bindscrolltoupper、bindscrolltolower、bindscroll属性添加名为“upper、lower、scroll”的function 在.js文件中添加响应\n1 2 3 4 5 6 7 8 9 10 11 Page({ upper: function (event) { console.log(\u0026#34;to top now\u0026#34;); }, lower: function (event) { console.log(\u0026#34;to low now\u0026#34;); }, scroll: function (event) { console.log(\u0026#34;scrolling now\u0026#34;); } }) 滚动时就能看到Console窗口中显示出log内容\n3、scroll-into-view 与 scroll-top scroll-into-view属性，值应为某子元素id（id不能以数字开头）。设置哪个方向可滚动，则在哪个方向滚动到该元素 scroll-top属性，值为竖向滚动条滚动到的位置\n为scroll-view组件添加scroll-into-view与scroll-top属性，并添加两个button。\n1 2 3 4 5 6 7 8 \u0026lt;scroll-view style=\u0026#34;height:250px\u0026#34; scroll-y=\u0026#34;true\u0026#34; scroll-into-view=\u0026#34;{{toView}}\u0026#34; scroll-top=\u0026#34;{{scrollTop}}\u0026#34;\u0026gt; ... \u0026lt;/scroll-view\u0026gt; \u0026lt;view\u0026gt; \u0026lt;button bindtap=\u0026#34;tap\u0026#34;\u0026gt;click me to scroll into view\u0026lt;/button\u0026gt; \u0026lt;button bindtap=\u0026#34;tapMove\u0026#34;\u0026gt;click me to scroll\u0026lt;/button\u0026gt; \u0026lt;/view\u0026gt; 在.js中添加点击function——tap和tapMove data中定义toView初始值为'red' ，滚动条开始与200px的位置\n其中tap: function (e) {} 判断当前toView 值与order[i] 值是否匹配，相同则将order[i + 1] 的值赋给toView ，即每次点击都将下一个颜色id传给scroll-into-view 属性。\ntapMove: function (e) {} 将scrollTop 值自加10，即滚动条位置增加10。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 var order = [\u0026#39;red\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;red\u0026#39;] Page({ data: { toView: \u0026#39;red\u0026#39;, scrollTop: 200 }, tap: function (e) { for (var i = 0; i \u0026lt; order.length; ++i) { if (order[i] === this.data.toView) { this.setData({ toView: order[i + 1] }) break } } }, tapMove: function (e) { this.setData({ scrollTop: this.data.scrollTop + 10 }) } }) 二、swiper 以下代码简单设置了swiper的几个基本属性\n属性 作用 默认值 indicator-dots 是否显示面板指示点 false autoplay 是否自动切换 false current 当前所在滑块的 index 0 interval 自动切换时间间隔 5000 duration 滑动动画时长 500 1 2 3 4 5 6 \u0026lt;swiper indicator-dots=\u0026#34;true\u0026#34; autoplay=\u0026#34;true\u0026#34; current=\u0026#39;1\u0026#39; interval=\u0026#39;1000\u0026#39; duration=\u0026#39;100\u0026#39; bindchange=\u0026#39;change\u0026#39;\u0026gt; \u0026lt;swiper-item\u0026gt;\u0026lt;view class=\u0026#34;item bc_green\u0026#34;\u0026gt;green\u0026lt;/view\u0026gt;\u0026lt;/swiper-item\u0026gt; \u0026lt;swiper-item\u0026gt;\u0026lt;view class=\u0026#34;item bc_red\u0026#34;\u0026gt;red\u0026lt;/view\u0026gt;\u0026lt;/swiper-item\u0026gt; \u0026lt;swiper-item\u0026gt;\u0026lt;view class=\u0026#34;item bc_yellow\u0026#34;\u0026gt;yellow\u0026lt;/view\u0026gt;\u0026lt;/swiper-item\u0026gt; \u0026lt;swiper-item\u0026gt;\u0026lt;view class=\u0026#34;item bc_blue\u0026#34;\u0026gt;blue\u0026lt;/view\u0026gt;\u0026lt;/swiper-item\u0026gt; \u0026lt;/swiper\u0026gt; 1 2 3 4 5 Page({ change:function(a) { console.log(a) } }) 以下简单介绍swiper的wxss配置\n以上wxml中\u0026lt;swiper-item\u0026gt; 组件仅可放置在\u0026lt;swiper/\u0026gt;组件中，宽高自动设置为100%。\n这里的100%为占满整个swiper，但值得注意的是，实际上若不设置height属性，其显示范围仅仅为文字范围，这里可以为swiper添加一个边框border 属性来验证，同时可以验证，滑动时是整个swiper进行滑动，而不是其中的item滑动。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 swiper { height: 200px; } swiper-item { border: 3px solid black; } .item { height: 50%; width: 50%; font-size: 48px; color: #fff; } .bc_green { background-color: green; } .bc_red { background-color: red; } .bc_yellow { background-color: yellow; } .bc_blue { background-color: blue; } 一些bug和注意事项： 1.02版本中若用以上方法添加border会将view挤出屏幕，而不是覆盖在view上。 swiper组件中，虽然autoplay组件默认值为false，并且其值为布尔类型，但是在1.02版本中只要写上了autoplay属性其值均为true，即使你\u0026lt;swiper autoplay='a'\u0026gt; 这样写，swiper仍然会自动播放。 ","date":"2018-02-11T20:14:57+08:00","permalink":"https://gitsang.github.io/p/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F-3-%E7%BB%84%E4%BB%B6-%E8%A7%86%E5%9B%BE%E5%AE%B9%E5%99%A8scrollview%E5%92%8Cswiper/","title":"[微信小程序 - 3] 组件-视图容器（ScrollView和Swiper）"},{"content":"一、组件与数据绑定 https://mp.weixin.qq.com/debug/wxadoc/dev/component/text.html\n1、text组件与button组件 1 2 3 \u0026lt;text\u0026gt;text组件文本\u0026lt;/text\u0026gt; \u0026lt;button type=\u0026#34;normal\u0026#34;\u0026gt;normal button\u0026lt;/button\u0026gt; \u0026lt;button type=\u0026#34;primary\u0026#34;\u0026gt; primary button \u0026lt;/button\u0026gt; 这里 button 标签内 type 属性用于设置按钮风格\n2、数据绑定 数据名用 {{}} 可对其内容在 .js 文件中进行绑定\n1 \u0026lt;text\u0026gt;{{bindText_1}}\u0026lt;/text\u0026gt; 1 2 3 4 5 Page({ data: { bindText_1:\u0026#34;这是.js中绑定的数据文本\u0026#34; }, }) 二、button的点击响应 下例通过 bindtap 属性对 button 点击事件进行响应\n单击按钮后其显示文字改变\n1 \u0026lt;button type=\u0026#34;primary\u0026#34; bindtap=\u0026#34;btnclick\u0026#34;\u0026gt; {{btnText}} \u0026lt;/button\u0026gt; 1 2 3 4 5 6 7 8 9 Page({ data:{ btnText:\u0026#34;default btn text\u0026#34; }, btnclick: function () { console.log(\u0026#34;btnclick: function\u0026#34;); this.setData({btnText:\u0026#34;set new btn text\u0026#34;}); } }) 三、条件渲染 下例点击按钮后改变条件值从而改变文本\n1 2 3 \u0026lt;button bindtap=\u0026#34;btnclick\u0026#34;\u0026gt;button\u0026lt;/button\u0026gt; \u0026lt;text wx:if=\u0026#34;{{condition}}\u0026#34;\u0026gt;满足条件\u0026lt;/text\u0026gt; \u0026lt;text wx:else\u0026gt;不满足条件\u0026lt;/text\u0026gt; 1 2 3 4 5 6 7 8 9 10 11 12 Page({ data:{ condition:true }, btnclick: function () { var condition = this.data.condition; //这里condition需要在函数内先进行定义 //data中的condition不能直接拿来使用 console.log(condition); this.setData({condition:!condition}); } }) 四、列表渲染 在组件上使用 wx:for 控制属性绑定一个数组，即可使用数组中各项的数据重复渲染该组件。\n1 2 3 \u0026lt;view wx:for=\u0026#34;{{array}}\u0026#34;\u0026gt; {{index}} ------ {{item.message}} \u0026lt;/view\u0026gt; 默认数组的当前项的下标变量名默认为 index，数组当前项的变量名默认为 item\n1 2 3 4 5 6 7 8 9 Page({ data: { array: [{ message: \u0026#39;第0个文本\u0026#39;, }, { message: \u0026#39;第一个文本\u0026#39; }] } }) 运行结果：\n1 2 0 ------ 第0个文本 1 ------ 第一个文本 item.message即为array数组中的message变量（array.message）\n上述结果与一下运行结果相同\n1 2 3 4 5 6 7 Page({ data: { array: [ \u0026#39;第0个文本\u0026#39;, \u0026#39;第一个文本\u0026#39; ] } }) 使用 wx:for-item 可以指定数组当前元素的变量名，\n使用 wx:for-index 可以指定数组当前下标的变量名：\n1 2 3 \u0026lt;view wx:for=\u0026#34;{{array}}\u0026#34; wx:for-index=\u0026#34;idx\u0026#34; wx:for-item=\u0026#34;itemName\u0026#34;\u0026gt; {{idx}}: {{itemName.message}} \u0026lt;/view\u0026gt; 五、页面引用 1、include include 可以将目标文件除了 \u0026lt;template/\u0026gt; \u0026lt;wxs/\u0026gt; 外的整个代码引入，相当于是拷贝到 include 位置，如：\n1 2 3 \u0026lt;!-- pages/demo/demo.wxml --\u0026gt; \u0026lt;include src=\u0026#34;../template/header.wxml\u0026#34;/\u0026gt; \u0026lt;view\u0026gt; body \u0026lt;/view\u0026gt; 1 2 \u0026lt;!-- pages/template/header.wxml --\u0026gt; \u0026lt;view\u0026gt; header \u0026lt;/view\u0026gt; 2、template 下例 import 了 footer.wxml 使用其中名为 footer2 的模板\n1 2 3 4 5 \u0026lt;!-- pages/demo/demo.wxml --\u0026gt; \u0026lt;!--此处对footer.wxml引入，还未分配模板--\u0026gt; \u0026lt;import src=\u0026#34;../template/footer.wxml\u0026#34;/\u0026gt; \u0026lt;!--此处决定模板的使用，同时能对模板为定义的数据进行定义--\u0026gt; \u0026lt;template is=\u0026#34;footer2\u0026#34; data=\u0026#34;{{text: \u0026#39;footer template\u0026#39;}}\u0026#34;/\u0026gt; 1 2 3 4 5 6 7 8 \u0026lt;!-- pages/template/footer.wxml --\u0026gt; \u0026lt;template name=\u0026#34;footer1\u0026#34;\u0026gt; \u0026lt;text\u0026gt;{{text}} 1\u0026lt;/text\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;template name=\u0026#34;footer2\u0026#34;\u0026gt; \u0026lt;text\u0026gt;{{text}} 2\u0026lt;/text\u0026gt; \u0026lt;/template\u0026gt; 3、import 的作用域 import 有作用域的概念，即只会 import 目标文件中定义的 template，而不会 import 目标文件 import 的 template。\n如：C import B，B import A，在C中可以使用B定义的template，在B中可以使用A定义的template，但是C不能使用A定义的template。\n","date":"2018-02-11T20:02:03+08:00","permalink":"https://gitsang.github.io/p/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F-2-%E6%A1%86%E6%9E%B6-%E8%A7%86%E5%9B%BE%E5%B1%82-wxml%E6%95%B0%E6%8D%AE%E7%BB%91%E5%AE%9A%E6%B8%B2%E6%9F%93%E5%BC%95%E7%94%A8/","title":"[微信小程序 - 2] 框架 视图层 WXML（数据绑定、渲染、引用）"},{"content":"小程序的前期准备工作可在开发者文档查询，此处掠过\n一、代码构成 微信小程序基本文件由“页面文件（pages）”和“app文件（.js .json .wxss）”构成\n1、JSON配置 1 2 3 4 5 6 7 8 9 10 11 12 { \u0026#34;pages\u0026#34;:[ \u0026#34;pages/index/index\u0026#34;, \u0026#34;pages/logs/logs\u0026#34; ], \u0026#34;window\u0026#34;:{ \u0026#34;backgroundTextStyle\u0026#34;:\u0026#34;light\u0026#34;, \u0026#34;navigationBarBackgroundColor\u0026#34;: \u0026#34;#fff\u0026#34;, \u0026#34;navigationBarTitleText\u0026#34;: \u0026#34;WeChat\u0026#34;, \u0026#34;navigationBarTextStyle\u0026#34;:\u0026#34;black\u0026#34; } } pages字段：用于对页面目录的注册（每个建立的页面都应在pages字段进行注册）\nwindow字段：用于对小程序页面风格进行配置\n2、WXML及WXSS配置 wxml 和 wxss 与 html 和 css 类似，但是 wxml 新增了以写常用组件的标签，并且新增了以写类似 wx:if 这样的属性。\n二、wxml中使用换行 在标签中可以使用 \\n 进行换行，但若不使用标签则 \\n 不进行换行。\n1 2 normal text\\n123\u0026lt;!--这里的\\n不会换行--\u0026gt; \u0026lt;text\u0026gt;\\ntag text\u0026lt;/text\u0026gt; 运行结果：\n1 2 normal text 123 tag text 参考 微信小程序开发者文档 微信小程序 软谋教育课程-腾讯课堂 ","date":"2018-02-11T19:53:57+08:00","permalink":"https://gitsang.github.io/p/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F-1-%E5%9F%BA%E6%9C%AC%E6%9E%84%E6%88%90%E5%8F%8A%E9%85%8D%E7%BD%AE/","title":"[微信小程序 - 1] 基本构成及配置"}]